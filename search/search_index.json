{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf33 Dendron","text":"<p>Dendron is a library for building artificial intelligence applications using behavior trees and large language models. </p> <p>In the last few years, behavior trees have become popular in game AI development and robotics. This has happened because behavior trees make it easy to compose simple behaviors (pieces of code) into collections of complex behaviors. Behavior trees also naturally enable a high degree of code modularity and reusability that is beneficial for building AI systems that interact with the world in complex ways. On the other hand, large language models appear to be very powerful, but are not easily composable, either with other language models or classical software components. By making it easy to build behavior trees that integrate large language models, Dendron gives you the ability to easily build, use, and reuse sophisticated artificial intelligence programs.</p> <p>Info</p> <p>Never worked with behavior trees? We define them from scratch in Tutorial 1. Or you can find a more academic introduction in the arXiv paper that introduces Dendron: Behavior Trees Enable Structured Programming of Language Model Agents. </p>"},{"location":"#installation","title":"Installation","text":"<p>You can use <code>pip</code> to install Dendron. For installation instructions, click here.</p>"},{"location":"#the-tutorial","title":"The Tutorial","text":"<p>For a tutorial overview of the library, click here. In the tutorial, you will use Dendron to build a chat agent that:</p> <ol> <li>Performs speech recognition from a microphone using a transformer-based ASR model.</li> <li>Handles chat template formatting for a quantized LLM.</li> <li>Generates speech from text using a transformer-based TTS model. </li> <li>Intelligently segments the chat output using rule-based AI to prevent overwhelming the TTS model.</li> <li>Uses another language model to classify user input to determine when it is socially appropriate for the language model to end the conversation.</li> </ol> <p>The resulting behavior tree uses four different LLMs in five different ways, but can still be run on a single RTX 3090.</p>"},{"location":"#api-reference","title":"API Reference","text":"<p>For an API reference, see the menu to the left on this page.</p>"},{"location":"#the-paper","title":"The Paper","text":"<p>If you use Dendron in academic research, please cite the paper:</p> <pre><code>@misc{kelley2024behavior,\n      title={Behavior Trees Enable Structured Programming of Language Model Agents}, \n      author={Richard Kelley},\n      year={2024},\n      eprint={2404.07439},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}\n</code></pre>"},{"location":"0_tutorial_single_node/","title":"0. Building a Chat System with Dendron: A Single Node","text":"<p>The real power of behavior trees comes from their ability to organize collections of behaviors that interact in complex ways, but to get started using a language model as quickly as possible let's build a tree with a single language model <code>TreeNode</code> that we can chat with. We'll have to manage the chat state ourselves, but in part 2 we'll see how to make a more complex tree handle that state for us.</p> <p>If you find this tutorial too verbose and you just want to get the code, you can find the notebook for this part here.</p>"},{"location":"0_tutorial_single_node/#causal-language-models-in-dendron","title":"Causal Language Models in Dendron","text":"<p>We start by importing <code>dendron</code>, and then we import two classes that we can use to define a language model node:</p> <pre><code>import dendron\nfrom dendron.actions.causal_lm_action import CausalLMActionConfig, CausalLMAction\n</code></pre> <p>A <code>CausalLMAction</code> is an action node that maintains a neural network and executes that network whenever it receives a tick from its parent node in the tree. Recall from the tutorial introduction that the leaf nodes of a behavior tree are the nodes that actually \"do stuff:\" either they test predicates (condition nodes) or they perform tasks (action nodes). In this case, we want a behavior that takes in a chat history, runs an autoregressive language model on that history, and then prints the next reply from the model. The language model capabilities of Dendron are currently based on the Hugging Face \ud83e\udd17 Transformers library, and <code>CausalLMAction</code> is the Dendron class that wraps Transformers' ability to load and run autoregressive models. The <code>CausalLMActionConfig</code> is a supporting dataclass that lets you specify options such as which model to download from the Hugging Face Hub, whether or not to quantize that model, how inputs are communicated to the model, how much text to generate, and so on. If you're curious about all of the options, look at the documentation for the config.</p> <p>Next we specify a configuration for our node:</p> <pre><code>chat_behavior_cfg = CausalLMActionConfig(load_in_4bit=True,\n                                         max_new_tokens=128,\n                                         do_sample=True,\n                                         top_p=0.95,\n                                         use_flash_attn_2=True,\n                                         model_name='openchat/openchat_3.5')\n</code></pre> <p>Warning</p> <p>If you haven't installed flash attention, you will need to set <code>use_flash_attn_2 = False</code> in this and all of the other model configs of the tutorial.</p> <p>There are few points to note about this configuration. First, we specify that we want to load our model using 4-bit quantization. This means that we use less precision for each model weight, which leads to lower memory consumption. This is critical for running larger models on smaller GPUs. The <code>openchat_3.5</code> model we are using has billions of parameters, so it would be impossible to run without this quantization. Next, we specify that we are using Flash Attention 2. This makes inference substantially faster, but unfortunately isn't supported on older GPUs. The parameters <code>do_sample</code> and <code>top_p</code> specify a sampling strategy known as \"nucleus sampling.\" You can read more about sampling strategies and approaches to generating text with language models here.</p> <p>Tip</p> <p>If you find that <code>openchat_3.5</code> is too big for you to run with its 7 billion parameters, there are smaller models you can explore that should work even on GPUs with less VRAM. Two that might be worth trying are <code>microsoft/phi-1_5</code> which has 1.3 billion parameters and <code>google/gemma-2b</code> which has 2 billion parameters. You can switch to these other models by changing the <code>model_name</code> parameter above. But note that to use <code>google/gemma-2b</code> you do have to agree to Google's terms first or else you'll get an error when you try to download the weights.</p> <p>Next we create our node and our tree:</p> <pre><code>chat_node = CausalLMAction('chat_node', chat_behavior_cfg)\ntree = dendron.BehaviorTree(\"chat_tree\", chat_node)\n</code></pre> <p>The first arguments to <code>CausalLMAction</code> and <code>BehaviorTree</code> are names. These can be anything you'd like and are useful for debugging and logging. We initialize the <code>chat_node</code> using the configuration we just created, and then we pass the resulting node to the <code>BehaviorTree</code> constructor as the second argument. In general, we initialize <code>BehaviorTree</code> instances by specifying a name and a root node. In this case, the root of the tree is the entire tree. </p> <p>Warning</p> <p>Running the <code>CasaulLMAction</code> constructor will automatically download the weights of the model you name in the config, unless you set <code>auto_load</code> to <code>False</code> in your <code>CausalLMActionConfig</code>. Remember that these models with their billions of parameters can take time and space to download and store.</p> <p>You can visualize the behavior tree that results from the above as follows:</p> <p> <p>Not much to admire quite yet; it would be just as easy to use the \ud83e\udd17 Transformers library directly for a simple use case like this. But let's keep going and see what we can build on this foundation.</p>"},{"location":"0_tutorial_single_node/#input-and-output-processing","title":"Input and Output Processing","text":"<p>Next we need to decide how we want to manage the state of the chat. This ends up being a little annoying no matter what libraries you use, because every model has its own \"chat template\" for converting a structured chat history into a sequence of tokens. Here's an example chat using the format that <code>openchat_3.5</code> prefers:</p> <pre><code>chat = [\n    {\"role\": \"GPT4 Correct User\", \"content\": \"Hello, how are you?\"},\n    {\"role\" : \"GPT4 Correct Assistant\", \"content\" : \"I am well. How are you?\"}\n]\n</code></pre> <p>This is the format in which we'll track the chat state, so we'll need a way to convert between this form and a simple string that can be tokenized and passed to our model. This kind of transformation is common enough that Dendron lets you define custom input processors and output processors to implement the required transformations during every tick operation. It turns out that the tokenizer for <code>openchat_3.5</code> has built-in functionality to convert chat objects into strings, so we can write a simple input processor to perform that conversion:</p> <pre><code>def chat_to_str(self, chat):\n    return self.tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n\ntree.root.set_input_processor(chat_to_str)\n</code></pre> <p>We don't want to perform tokenization quite yet (that is done inside of <code>CausalLMAction</code>'s <code>tick</code> function), but we do want to add a generation prompt, which is a hint to the model that it should generate text in the persona of the assistant. If you don't do this, some models may generate text as if they were the user, which can be entertaining but is probably not what you're looking for.</p> <p>In general, input processors for <code>CausalLMAction</code> should take <code>self</code> and a single argument that is a model input, and should return a single string output.</p> <p>Warning</p> <p>Input and output processors (and the pre- and post-tick functions we'll meet later on) are added to the class as if they were originally part of the class definition. Keep this in mind if you are using a custom <code>TreeNode</code> class to maintain some private information, since added functions will have access to that information just as any other member function would. </p> <p>Converting from text strings to chat history is a bit more complicated:</p> <pre><code>def str_to_chat(self, str):\n    key = \"GPT4 Correct Assistant:\"\n    idx = str.rfind(key)\n    response = str[idx+len(key):]\n    chat = self.blackboard[self.input_key]\n    chat.append({\"role\" : \"GPT4 Correct Assistant\", \"content\" : response})\n    return chat\n\ntree.root.set_output_processor(str_to_chat)\n</code></pre> <p>During a <code>tick</code>, the model generates a sequence of integer tokens that are decoded back into a string. Here's an example of the decoded model output if we were to start with the <code>chat</code> list as above and have the human type \"I am excited!\" as the first response:</p> <pre><code>GPT4 Correct Gpt4 Correct User: Hello, how are you? GPT4 Correct Gpt4 Correct Assistant: I am well. How are you? GPT4 Correct User: I am excited! GPT4 Correct Assistant: That's great to hear! It's always nice to be excited about something. Is there anything specific that has you feeling this way?|\n</code></pre> <p>In order to continue the chat, we have to grab the agent's most recent reply and add it as the <code>\"content\"</code> value of a correctly formatted dictionary at the end of the list. That is precisely what the <code>str_to_chat</code> function does. In general, output processors for <code>CausalLMAction</code> should convert the decoded string output of a language model into whatever structured format is being used to track inputs (in this case the \"list of dictionaries\" format). </p> <p>With input and output processors in mind, we can visualize the flow of control inside the typical <code>tick</code> function as follows:</p> <p> <p>The output processor returns the chat history it constructs back to the <code>tick</code> function, which then writes that history to the behavior tree's blackboard.</p>"},{"location":"0_tutorial_single_node/#blackboards","title":"Blackboards","text":"<p>You probably noticed that <code>str_to_chat</code> makes reference to member variables called <code>self.blackboard</code> and <code>self.input_key</code>. One of the defining concepts of behavior trees is that nodes only communicate directly in two ways:</p> <ol> <li>Parents <code>tick</code> their children.</li> <li>Children reply to their parents by returning a <code>NodeStatus</code>. This status can be <code>SUCCESS</code>, <code>FAILURE</code>, or <code>RUNNING</code>.</li> </ol> <p>These rules imply that some other mechanism is required if nodes need to share any other kind of information up or down the tree. The way that this is handled is via a <code>Blackboard</code> object. Every <code>BehaviorTree</code> has an associated <code>Blackboard</code>, and every <code>TreeNode</code> in the tree has access to that blackboard. You can think of a <code>Blackboard</code> as an in-memory key-value store that is shared by all of the nodes in a behavior tree. Keys are generally strings, but values can be any object that you can put into a Python <code>dict</code>. In the case of <code>CausalLMAction</code>, one of the optional arguments to <code>CausalLMActionConfig</code> is <code>input_key</code>, which specifies the key in the blackboard that will hold the prompt that the model should consume on the next <code>tick</code>. The value for <code>input_key</code> defaults to <code>\"in\"</code>, which is fine as long as you only have one language model in your tree. Otherwise you should choose a sensible name for your <code>input_key</code> (and probably for your <code>output_key</code> as well; see the the documentation for CausalLMActionConfig for additional details).</p>"},{"location":"0_tutorial_single_node/#the-chat-loop","title":"The Chat Loop","text":"<p>Our tree is all set up now, so all we have to do is set up a loop to chat with our agent:</p> <pre><code>while True:\n    input_str = input(\"Input: \")\n    chat.append({\"role\": \"GPT4 Correct User\", \"content\" : input_str})\n    tree.blackboard[\"in\"] = chat\n\n    tree.tick_once()\n\n    print(\"Output: \", tree.blackboard[\"out\"][-1][\"content\"])\n    if \"Goodbye\" in tree.blackboard[\"out\"][-1][\"content\"]:\n        break\n</code></pre> <p>We loop forever, first getting a line of text from the standard input, then appending it to the <code>chat</code> list, and then writing the resulting list to <code>tree</code>'s <code>Blackboard</code> instance. Once the <code>Blackboard</code> is set up with the most recent human input, we call the tree's <code>tick_once</code> function, which works recursively: the tree ticks its root node, and then (in general) the root node propagates that tick down the tree according to the logic implemented by the tree's structure. In this instance there's only one node in the tree, so it gets ticked and that's it.</p> <p>The <code>tick</code> function of the <code>CausalLMAction</code> node performs the following steps in order:</p> <ol> <li>Retrieve a prompt from the node's <code>blackboard</code>, using the <code>input_key</code>.</li> <li>Apply the input processor, if one exists.</li> <li>Tokenize the prompt text.</li> <li>Generate new tokens based on the prompt.</li> <li>Decode the model output into a text string.</li> <li>Apply the output processor, if one exists,</li> <li>Write the result back to the <code>blackboard</code>, using the <code>output_key</code>.</li> </ol> <p>As a result of this sequence of operations, when the <code>tick_once</code> call returns we can access the model's most recent output by getting the value stored at <code>tree.blackboard[\"out\"][-1]</code>. We can then use the <code>\"content\"</code> key to get the string that the model produced. This is what we print before checking if we should <code>break</code> out of the loop: rather than continue forever, we examine the contents of the model's output string, and if the substring <code>\"Goodbye\"</code> appears then we <code>break</code> out of the loop, concluding the conversation.</p> <p>If you want to see the chat history, you can examine the blackboard at a single key:</p> <pre><code>print(tree.blackboard[\"out\"])\n</code></pre> <p>or you can print the entire blackboard in tabular form:</p> <pre><code>print(tree.blackboard)\n</code></pre> <p>There are some options for controlling how the blackboard prints. Depending on your needs you may find <code>Blackboard.set_print_len</code> helpful. See the <code>Blackboard</code> documentation for more information.</p>"},{"location":"0_tutorial_single_node/#conclusion","title":"Conclusion","text":"<p>If you followed the steps above, you should now have a model you can chat with! It's a little rough around the edges and doesn't really show off the power of behavior trees, so in the next part we'll make a slightly more complex tree and add in the ability for our agent to speak out loud using a neural network TTS node that we'll write from scratch.</p>"},{"location":"1_tutorial_seq/","title":"1. Building a Chat System with Dendron: Thinking and Talking","text":"<p>In the Part 0, we created a simple Dendron behavior tree with a single <code>CausalLMAction</code> node and used that tree to implement a chat loop. In this part of the tutorial, we will expand the capabilities of our agent by giving it the power of speech. This will require us to use Dendron's control flow capabilities, since we'll only want our agent to speak when it has something new to say. </p> <p>Tip</p> <p>Current SOTA text-to-speech (TTS) models appear to be a bit on the slow side, at least on consumer cards like the single 3090 I'm developing with. If you want an agent that can talk but find the latency of neural TTS unbearable, try replacing the <code>TTSAction</code> we implement below with an action that uses an old-fashioned TTS system like espeak on Linux. I found that the <code>pyttsx3</code> library was useful in this regard.</p> <p>If you find this tutorial too verbose and you just want to get the code, you can find the notebook for this part here.</p>"},{"location":"1_tutorial_seq/#imports-and-bark-tts","title":"Imports and Bark TTS","text":"<p>We'll start out by importing the libraries we need to implement TTS, beginning of course with Dendron:</p> <pre><code>import dendron\nfrom dendron.actions.causal_lm_action import CausalLMActionConfig, CausalLMAction\n</code></pre> <p>We import <code>CausalLMAction</code> as in Part 0 to create a chat node. We are going to create a custom <code>dendron.ActionNode</code> to implement our TTS capability, so next we import the components we need specifically for speech generation:</p> <p>Tip</p> <p>Before you run this next block, you will need to pip install <code>optimum</code> and <code>sounddevice</code> if you have not already done so.</p> <pre><code>import torch\nfrom transformers import BarkModel, BarkProcessor\nfrom optimum.bettertransformer import BetterTransformer\nimport sounddevice as sd\n</code></pre> <p>We are going to be using the bark-small model for our text to speech capability. The combination of the quantized <code>openchat_3.5</code> model and <code>bark-small</code> uses about 4.7GB of VRAM on my GPU.</p>"},{"location":"1_tutorial_seq/#creating-a-custom-dendron-action-node","title":"Creating a Custom Dendron Action Node","text":"<p>We want to create an action node that generates some speech and actually says it. We'll show the whole node and then walk through the parts:</p> <pre><code>class TTSAction(dendron.ActionNode):\n    def __init__(self, name):\n        super().__init__(name)\n        self.processor = BarkProcessor.from_pretrained(\"suno/bark-small\")\n        self.model = BarkModel.from_pretrained(\"suno/bark-small\").to(\"cuda\")\n        self.model = BetterTransformer.transform(self.model, keep_original_model=False)\n        self.model.enable_cpu_offload()\n\n    def tick(self):\n        try:\n            input_text = self.blackboard[\"speech_in\"]\n            inputs = self.processor(text=input_text, voice_preset=\"v2/en_speaker_9\", return_tensors=\"pt\").to(\"cuda\")\n            self.blackboard[\"speech_out\"] = self.model.generate(**inputs).cpu().numpy()\n        except Exception as e:\n            print(\"Speech generation exception: \", e)\n            return dendron.NodeStatus.FAILURE\n\n        return dendron.NodeStatus.SUCCESS\n</code></pre> <p>We can declare a new action node type by inheriting from <code>dendron.ActionNode</code>, which we do here. The parent class constructor requires us to specify a name for our node, so we take <code>name</code> as a parameter and forward that up to the parent in <code>super().__init__(name)</code>. Then we initialize our model. Instead of a tokenizer we have a <code>BarkProcessor</code> that achieves the same effect. We initialize a processor from the Hugging Face Hub, and then we initialize our model and send it to the GPU. The next two steps (lines 6 and 7) are optional optimizations.</p> <p>The only member function we need to define to implement a Dendron node is <code>tick(self)</code>. In general, a <code>tick</code> function should take no inputs and must return a <code>NodeStatus</code>. In our case, we <code>try</code> to get some input text from <code>self.blackboard</code>, run it through the processor, call our TTS model's <code>generate</code> function, and write the output back to <code>self.blackboard</code>. If all goes well, we return <code>NodeStatus.SUCCESS</code>. If there's an exception, we print it out and then return <code>NodeStatus.FAILURE</code>. This is representative of the general flow of a <code>tick</code> function. </p> <p>There are some interesting details, such as the <code>voice_preset</code> option in the <code>processor</code> call. If you want to experiment with other voices (or other languages), you can see a list of voice options here.</p>"},{"location":"1_tutorial_seq/#pre-and-post-tick-functions","title":"Pre- and Post-Tick Functions","text":"<p>The call to <code>generate</code> on line 13 above will generate the audio data we want to play, but won't in fact play a sound. To do that, we need to use the <code>sounddevice</code> library that we imported above. If our <code>TTSAction</code> class had a member function that used <code>sounddevice</code> then we'd be all set. You might imagine a function like <code>play_speech</code> that can play the sound data directly from memory (on Ubuntu at least):</p> <pre><code>def play_speech(self):\n    sd.play(self.blackboard[\"speech_out\"][0], self.model.generation_config.sample_rate)\n    sd.wait()\n</code></pre> <p>After the <code>tick</code> function has returned, the audio data is stored in the blackboard and the <code>play_speech</code> function above could play it correctly. We just need a way to ensure that <code>play_speech</code> is called immediately after the <code>tick</code> function returns. It often happens that we want to execute code for its side effects immediately surrounding a <code>tick</code> call, and Dendron supports this with \"pre-tick functions\" and \"post-tick functions.\" These are functions that get added as members of our node classes that are guaranteed to be called before and after a <code>tick</code>. Each <code>TreeNode</code> maintains a list of pre-tick and post-tick functions, and calls them in the order they are added. To see how this works, we first instantiate our node and then add our <code>play_speech</code> post-tick function to the node: </p> <pre><code>speech_node = TTSAction(\"speech_node\")\nspeech_node.add_post_tick(play_speech)\n</code></pre> <p>Now that we've introduced pre- and post-tick functions into the mix, we can see that a more accurate depiction of a <code>tick</code> call looks something like the following:</p> <p> <p>(It's an implementation detail, but these operations all take place inside of a method called <code>execute_tick</code> that is responsible for the sequence of operations in the figure above. You will never need to override <code>execute_tick</code> in your own node classes as long as you implement a reasonable <code>tick</code> operation and use pre- and post-tick functions correctly.)</p> <p>With this, our <code>TTSAction</code> node is ready to go. It just needs something to say, so next we create a chat node.</p>"},{"location":"1_tutorial_seq/#a-chat-node","title":"A Chat Node","text":"<p>To create our chat node, we will follow almost exactly the same steps as in the previous part. We'll start by creating a <code>CausalLMActionConfig</code> and then we'll use that configuration to instantiate a <code>CausalLMAction</code>. Then we'll define our input and output processor functions to translate between strings and the structured format that <code>openchat_3.5</code> expects:</p> <pre><code>chat_behavior_cfg = CausalLMActionConfig(load_in_4bit=True,\n                                         max_new_tokens=128,\n                                         do_sample=True,\n                                         top_p=0.95,\n                                         use_flash_attn_2=True,\n                                         model_name='openchat/openchat_3.5')\n\nchat_node = CausalLMAction('chat_node', chat_behavior_cfg)\n\ndef chat_to_str(self, chat):\n    return self.tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n\ndef str_to_chat(self, str):\n    key = \"GPT4 Correct Assistant:\"\n    idx = str.rfind(key)\n    response = str[idx+len(key):]\n    chat = self.blackboard[self.input_key]\n    chat.append({\"role\" : \"GPT4 Correct Assistant\", \"content\" : response})\n    return chat\n\nchat_node.set_input_processor(chat_to_str)\nchat_node.set_output_processor(str_to_chat)\n</code></pre> <p>So far this is identical to our previous chat system. But now we need to connect the output of our <code>chat_node</code> with the input of our <code>speech_node</code>. Having them communicate this information directly would violate the design constraint of behavior trees, so instead we'll have them communicate via their shared blackboard. Setting a blackboard is a side effecting operation, and post-tick functions are generally a good place to perform node operations that are partly or entirely used for their side effects, so we'll define a function <code>set_next_speech</code> and add it as a post-tick function for <code>chat_node</code>:</p> <pre><code>def set_next_speech(self):\n    text_output = self.blackboard[\"out\"][-1][\"content\"]\n    self.blackboard[\"speech_in\"] = \" \" + text_output\n\nchat_node.add_post_tick(set_next_speech)\n</code></pre> <p>Now our <code>chat_node</code> and our <code>speech_node</code> are completed. We just need to combine them into a single composite operation in a behavior tree.</p>"},{"location":"1_tutorial_seq/#composing-nodes-with-sequence","title":"Composing Nodes with <code>Sequence</code>","text":"<p>In our new chat loop, we want our agent to read our input, generate a response with <code>chat_node</code>, and generate audio using <code>speech_node</code>. This implies a sequential ordering to the <code>tick</code> operation for our tree. We can compose two or more nodes in sequence using a control node. Dendron provides two types of control nodes: <code>Fallback</code> and <code>Sequence</code>. We'll talk about <code>Fallback</code> in the next part. A <code>Sequence</code> node keeps a list of children, and ticks them in order until either:</p> <ul> <li>One of the children returns <code>NodeStatus.FAILURE</code>, in which case the <code>Sequence</code> node fails, or</li> <li>All of the children return <code>NodeStatus.SUCCESS</code>, in which case the <code>Sequence</code> node succeeds.</li> </ul> <p>We can compose our two nodes with a <code>Sequence</code> object and create a tree from the result as follows:</p> <pre><code>root_node = dendron.controls.Sequence(\"think_then_talk\", [\n    chat_node,\n    speech_node\n])\n\ntree = dendron.BehaviorTree(\"talker_tree\", root_node)\n</code></pre> <p>Both <code>Sequence</code> and <code>Fallback</code> reside in <code>dendron.controls</code>. A control node is like an action node in that its first argument is a string name. But the second argument to a control node is a list of children. The children are <code>tick</code>ed in the order they are given in the constructor. You can also add children dynamically to a control node after it is constructed. See the <code>ControlNode</code> documentation for details.</p> <p>At this point our tree is ready for use. We can visually represent the tree as follows:</p> <p> <p>The <code>Sequence</code> node is represented by a rightward pointing arrow; this is standard in much of the behavior tree literature. The children of a control node should be read from left to right to understand the sequencing. The dark circle indicates the root. In this case calling the <code>tick</code> function will send a tick signal to the <code>think_then_talk</code> node first. This node will in turn first tick <code>chat_node</code>, and if <code>chat_node</code> returns <code>NodeStatus.SUCCESS</code> then <code>think_then_talk</code> will subsequently tick <code>speech_node</code>. This is precisely the behavior we wanted, and how we set up the flow of data through <code>tree.blackboard</code>.</p> <p>Tip</p> <p>This is the first time we have had to connect two nodes via a blackboard. It can be very helpful to think about blackboard state and <code>tick</code> operations in terms of pre-conditions and post-conditions. For each <code>TreeNode</code> that needs to communicate with other nodes, ask what state it requires from the blackboard to run its <code>tick</code> operation (pre-conditions) and what state it ensures will hold in the blackboard after its <code>tick</code> operation completes (post-conditions). I have found it helpful to \"work backwards\" from the end of a tree's tick logic to the beginning.</p>"},{"location":"1_tutorial_seq/#the-chat-loop","title":"The Chat Loop","text":"<p>Our agent is now ready to talk to us. Since we're still managing the chat state outside of our behavior tree, you'll find that the logic is quite similar to the previous part:</p> <pre><code>chat = []\n\nwhile True:\n    input_str = input(\"Input: \")\n    chat.append({\"role\": \"GPT4 Correct User\", \"content\" : input_str})\n    tree.blackboard[\"in\"] = chat\n    tree.tick_once()\n    print(\"Output: \", tree.blackboard[\"out\"][-1][\"content\"])\n    if \"Goodbye\" in tree.blackboard[\"out\"][-1][\"content\"]:\n        break\n</code></pre> <p>If you've gotten to this point, congratulations! You have built a local chat agent that can talk to you. Not quite C-3PO, but I'd say pretty remarkable nonetheless.</p>"},{"location":"1_tutorial_seq/#conclusion","title":"Conclusion","text":"<p>If you run our agent now, you'll find that you can type your end of the chat, but the agent speaks! Amazing. But if you play with this agent long enough, you'll find that its TTS capabilities are ... sometimes mixed. This appears to be common among neural TTS systems: they struggle with long outputs. If you play with the model long enough, you'll find that even with a limit on its output <code>chat_node</code> often generates strings that <code>speech_node</code> cannot speak. We'll see one way to (mostly) solve this problem in part 3. But before we do that, we need to learn a powerful pattern in behavior tree design, which we'll introduce in the next part by moving the chat management logic into our behavior tree.</p>"},{"location":"2_tutorial_implicit_seq/","title":"2. Building a Chat System with Dendron: Managing Chat State","text":"<p>In the Part 1 we saw how to get two <code>CausalLMAction</code> nodes to work together to generate speech in a chat loop. To do that, we <code>tick</code>ed the nodes in order using a <code>Sequence</code> control node. In this part we'll see how to move our chat state management into our tree, which we'll find ultimately increases the flexibility of our agent.  </p> <p>If you find this tutorial too verbose and you just want to get the code, you can find the notebook for this part here.</p>"},{"location":"2_tutorial_implicit_seq/#imports-and-a-text-input-node","title":"Imports and a Text Input Node","text":"<p>As before, we begin by importing the code we need:</p> <pre><code>import dendron\nfrom dendron.actions.causal_lm_action import CausalLMActionConfig, CausalLMAction\nfrom dendron.controls import Sequence, Fallback\nfrom dendron import NodeStatus\n\nimport torch\nfrom transformers import BarkModel, BarkProcessor\nfrom optimum.bettertransformer import BetterTransformer\nimport time\nimport sounddevice as sd\n</code></pre> <p>In addition to importing <code>dendron</code> and our <code>CausalLMAction</code> node, we're going to explicitly import <code>Sequence</code> and <code>Fallback</code> from <code>dendron.controls</code>, and <code>NodeStatus</code> from <code>dendron</code>. As our trees get larger and we have more custom components, you'll find that these imports make the code a bit more concise.</p> <p>Our goal is to handle the entirety of the chat loop inside of our behavior tree. We will need some new logic to do that, but before we get there we'll need to move human text input into the tree as well. We can implement this with an <code>ActionNode</code> as follows:</p> <pre><code>class GetTextInput(dendron.ActionNode):\n    \"\"\"\n    PRE: None\n    POST: \n        blackboard[latest_human_input_key] = input\n        blackboard[\"in\"] = chat\n    \"\"\"\n    def __init__(self, latest_human_input_key = \"latest_human_input\"):\n        super().__init__(\"get_text_input\")\n        self.latest_human_input_key = latest_human_input_key\n\n    def tick(self):\n        self.blackboard[self.latest_human_input_key] = input(\"Human: \")\n\n        chat = self.blackboard[\"chat_history\"]\n        chat.append({\"role\": \"GPT4 Correct User\", \"content\" : self.blackboard[self.latest_human_input_key]})\n        self.blackboard[\"in\"] = chat\n\n        return NodeStatus.SUCCESS\n</code></pre> <p>Here you can see that I have explicitly written out the pre- and post-conditions for the blackboard state as a design aid. When ticked, a <code>GetTextInput</code> node gets a string input from the human, and writes it to the blackboard at whatever key is specified in the constructor. The node then updates the chat history that it is maintaining before returning <code>NodeStatus.SUCCESS</code>. </p>"},{"location":"2_tutorial_implicit_seq/#implicit-sequences-for-behavior-tree-design","title":"Implicit Sequences for Behavior Tree Design","text":"<p>You might think that at this point we could just put a <code>GetTextInput</code> node at the front of our sequence from the last part and we would be done. You might be able to make that work (try it!), but we're going to do something a little different and explore a behavior tree design pattern that often leads to much more flexible reactive agents. The pattern is \"implicit sequences,\" and it uses <code>Fallback</code> nodes to implement a sequence of behaviors. A <code>Fallback</code> node is a control node, so it maintains a list of children that it ticks in succession. But in contrast with the <code>Sequence</code> node that we described in the last part, a <code>Fallback</code> node ticks its children in order until:</p> <ul> <li>One of the children returns <code>NodeStatus.SUCCESS</code>, in which case the <code>Fallback</code> node succeeds, or</li> <li>All of the children return <code>NodeStatus.FAILURE</code>, in which case the <code>Fallback</code> node fails.</li> </ul> <p>You can compare this with the description of <code>Sequence</code> nodes to see that <code>Fallback</code> and <code>Sequence</code> are \"conjugate\" or \"dual\" to each other in some sense. Intuitively, a <code>Fallback</code> node is \"trying\" its children in order from left to right until one of them works. So one way you can think of <code>Fallback</code> is that it provides a mechanism to implement contingent behaviors in the presence of failure. But failure should be understood very broadly in the context of behavior trees: often in this context <code>SUCCESS</code> and <code>FAILURE</code> are taken as synonyms for <code>True</code> and <code>False</code>, so that failure doesn't necessarily represent an exceptional or even adverse state in a behavior tree. </p> <p>In an implicit sequence, instead of executing a sequence of tasks \"A -&gt; B -&gt; C\", we attach a predicate to each task that returns <code>True</code> if and only if it is currently appropriate to execute that task. We then query these predicates in reverse order, which looks something like:</p> <ul> <li>Is C ready to execute? If so do C. Otherwise keep going.</li> <li>Is B ready to execute? If so do B. Otherwise keep going.</li> <li>Is A ready to execute? If so do A. Otherwise give up.</li> </ul> <p>If the tasks are related to each other, so that doing A makes it so that B becomes ready and doing B makes C become ready, then this evaluation strategy implements the same ordering as a direct sequence. In a static world, an implicit sequence is identical to a regular sequence. But if your agent is in a dynamically varying world then we can query an implicit sequence in a tight loop to make our agent react to changing conditions driven by external forces. This property is one of the reasons that implicit sequences and behavior trees have become popular in game development and robotics. </p> <p>Info</p> <p>For more details on the theory behind implicit sequences, see the wonderful textbook Behavior Trees in Robotics and AI: An Introduction by Michele Colledanchise and Petter Ogren.</p> <p>We can use an implicit sequence to manage our chat state. We'll have three tasks. Anthropomorphizing a bit (too much?), we'll call them \"speaking,\" \"thinking,\" and \"listening.\" The listening is implemented by our <code>GetTextInput</code> node above, so next we'll show how combining speaking and thinking in an implicit sequence will lead to a better agent.</p>"},{"location":"2_tutorial_implicit_seq/#the-speech-sequence","title":"The Speech Sequence","text":"<p>To see how we can use the implicit sequence concept in our design, take a moment to think about how you engage in conversation with other humans. You likely don't just start talking at arbitrary points in time. Instead, you probably (explicitly or implicitly) ask yourself \"is now a good time to talk?\" and then open your mouth precisely when your answer to that question is \"yes.\" We can model this in a behavior tree with a <code>Sequence</code> node that first ticks a <code>ConditionNode</code> that queries if now is a good time to speak, followed by our old friend <code>speech_node</code>:</p> <p> <p>In this configuration, our <code>more_to_say?</code> condition node is effectively acting as a \"guardrail\" that only allows <code>speech_node</code> to <code>tick</code> when the agent actually has something to say. What determines if the agent has something to say? We'll track this with the blackboard (the image in the <code>more_to_say?</code> node above is a blackboard with squiggles on it):</p> <pre><code>class MoreToSay(dendron.ConditionNode):\n    def __init__(self, speech_input_key=\"speech_in\"):\n        super().__init__(\"more_to_say\")\n        self.speech_input_key = speech_input_key\n\n    def tick(self):\n        if self.blackboard[self.speech_input_key] != []:\n            return dendron.NodeStatus.SUCCESS\n        else:\n            return dendron.NodeStatus.FAILURE\n</code></pre> <p>From the code above, you can see that we're going to keep track of a blackboard entry that tells us if there is any text that needs to be spoken. It might seem a little odd that we are comparing the value at that entry to an empty list, since you might think that the entry should be a string. But it will turn out to be more convenient to work with a list of strings for reasons we'll see in the next part of the tutorial.</p> <p>To complete the speech sequence, we'll repeat the <code>TTSAction</code> code here:</p> <pre><code>class TTSAction(dendron.ActionNode):\n    def __init__(self, name):\n        super().__init__(name)\n        self.processor = BarkProcessor.from_pretrained(\"suno/bark-small\")\n        self.model = BarkModel.from_pretrained(\"suno/bark-small\").to(\"cuda\")\n        self.model = BetterTransformer.transform(self.model, keep_original_model=False)\n        self.model.enable_cpu_offload()\n\n    def tick(self):\n        try:\n            input_text = self.blackboard[\"speech_in\"].pop()\n            inputs = self.processor(text=input_text, voice_preset=\"v2/en_speaker_9\", return_tensors=\"pt\").to(\"cuda\")\n            self.blackboard[\"speech_out\"] = self.model.generate(**inputs).cpu().numpy()\n        except Exception as e:\n            print(\"Speech generation exception: \", e)\n            return dendron.NodeStatus.FAILURE\n\n        return dendron.NodeStatus.SUCCESS\n\ndef play_speech(self):\n    sd.play(self.blackboard[\"speech_out\"][0], self.model.generation_config.sample_rate)\n</code></pre> <p>This is almost identical to the <code>TTSAction</code> from the previous part of the tutorial, except that on line 11 we are <code>pop()</code>ing the input text from the blackboard entry. This relates again to our use of a list, the utility of which will become clear later on. For now, we can create an instance of these two classes and create a speech sequence:</p> <pre><code>speech_node = TTSAction(\"speech_node\")\nspeech_node.add_post_tick(play_speech)\n\nspeech_seq = Sequence(\"speech_seq\", [\n    MoreToSay(),\n    speech_node\n])\n</code></pre>"},{"location":"2_tutorial_implicit_seq/#the-thought-sequence","title":"The Thought Sequence","text":"<p>Next we want to implement a \"thinking\" sequence similar to the speech sequence we described in the previous section. The general outline will be similar: first we ask if it's time to think, and then if it is we'll run a <code>chat_node</code> to generate some text to speak. First the <code>TimeToThink</code> condition node:</p> <pre><code>class TimeToThink(dendron.ConditionNode):\n    \"\"\"\n    PRE:\n        blackboard[human_input_key] should be set\n    POST:\n    \"\"\"\n    def __init__(self, human_input_key = \"latest_human_input\"):\n        super().__init__(\"time_to_think\")\n        self.human_input_key = human_input_key\n        self.last_human_input = \"\"\n\n    def tick(self):\n        human_input = self.blackboard[self.human_input_key]\n        if self.last_human_input == human_input:\n            status = NodeStatus.FAILURE\n        else:\n            status = NodeStatus.SUCCESS\n\n        self.last_human_input = human_input\n        return status\n</code></pre> <p>Here, our node checks the blackboard to see the current human input. That is compared against the last input the node has seen. If they are the same, the node fails (and we will move on to get a new input from the human). If they are not the same then we succeed and continue to tick the <code>chat_node</code>. </p> <p>Our <code>chat_node</code> is identical to previous versions:</p> <pre><code>chat_behavior_cfg = CausalLMActionConfig(load_in_4bit=True,\n                                         max_new_tokens=128,\n                                         do_sample=True,\n                                         top_p=0.95,\n                                         use_flash_attn_2=True,\n                                         model_name='openchat/openchat_3.5')\n\nchat_node = CausalLMAction('chat_node', chat_behavior_cfg)\n\ndef chat_to_str(self, chat):\n    return self.tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n\ndef str_to_chat(self, str):\n    key = \"GPT4 Correct Assistant:\"\n    idx = str.rfind(key)\n    response = str[idx+len(key):]\n    chat = self.blackboard[self.input_key]\n    chat.append({\"role\" : \"GPT4 Correct Assistant\", \"content\" : response})\n    return chat\n\ndef set_next_speech(self):\n    text_output = self.blackboard[\"out\"][-1][\"content\"]\n    self.blackboard[\"speech_in\"].append(text_output)\n\nchat_node.set_input_processor(chat_to_str)\nchat_node.set_output_processor(str_to_chat)\nchat_node.add_post_tick(set_next_speech)\n</code></pre> <p>Tip</p> <p>If the logic connecting <code>TimeToThink</code> with <code>chat_node</code> is not clear, you may find it helpful to enable logging. You can do this for a tree by calling <code>tree.enable_logging()</code>. By default this will print logging information to the screen, but you can direct that output to file by calling <code>tree.set_log_filename(file)</code>. You can switch back to printing by calling <code>tree.set_log_filename(None)</code> and you can turn logging off by calling <code>tree.disable_logging()</code>.</p> <p>With all of the above set up, we can create our <code>thought_seq</code> object:</p> <pre><code>thought_seq = Sequence(\"thought_seq\", [\n    TimeToThink(),\n    chat_node\n])\n</code></pre>"},{"location":"2_tutorial_implicit_seq/#the-completed-tree","title":"The Completed Tree","text":"<p>All that remains is to compose our sequence nodes into an implicit sequence via a <code>Fallback</code>, set up our blackboard, and start chatting. The tree composition looks like this:</p> <pre><code>root_node = Fallback(\"conversation_turn\", [\n    speech_seq,\n    thought_seq,                \n    GetTextInput()\n])\ntree = dendron.BehaviorTree(\"talker_tree\", root_node)\n</code></pre> <p>The resulting tree looks like the following (<code>Fallback</code> nodes are typically denoted by question marks):</p> <p> <p>Then all we have to do is initialize the blackboard and we can start our chat loop:</p> <pre><code>tree.blackboard[\"chat_history\"] = []\ntree.blackboard[\"speech_in\"] = []\ntree.blackboard[\"latest_human_input\"] = \"\"\n\nwhile True:\n    tree.tick_once()\n</code></pre> <p>You should again be able to type to your program and have it reply with speech. You'll need to manually terminate your program since we don't have a check for <code>\"Goodbye\"</code> any more. </p>"},{"location":"2_tutorial_implicit_seq/#conclusion","title":"Conclusion","text":"<p>We now have moved all of the management of chat state into our behavior tree. This may feel like a lot of work to get back to where we were at the end of Part 1, but in the next part we'll see how managing the chat state inside the tree allows us to add another language model that will analyze the human's input to decide whether or not it would be appropriate to end the conversation.</p>"},{"location":"3_tutorial_llm_conditional/","title":"3. Building a Chat System with Dendron: Learning How to Say Goodbye","text":"<p>In Part 2 we saw how to manage the state of a chat inside of a behavior tree, but we lost the ability to determine when the user wants to end the conversation. Even so, if you played with the models from Parts 0 or 1, you may have noticed that a simple search for the string <code>\"Goodbye\"</code> doesn't necessarily lead to a reliable indicator that the conversation is over: even if you say goodbye to your agent, it may not reply in kind, or it may not say the exact word you're searching for. We could try to add complexity to our exact search, but what we really want is to look at whatever the human has said most recently and answer the question \"Is the human trying to end the conversation?\" This is precisely the sort of thing that language models are supposed to be good at, and Dendron provides a specific class (<code>CompletionCondition</code>) that uses a language model to score a list of possible answers to a question, returning the most likely answer given the model and some programmer-specified context. In this part we'll show how to add a <code>CompletionCondition</code> to our tree to end the conversation with a bit more intelligence than our previous trees. We'll also add a rule-based AI node for intelligently splitting long strings into shorter ones to improve TTS quality.</p> <p>If you find this tutorial too verbose and you just want to get the code, you can find the notebook for this part here.</p>"},{"location":"3_tutorial_llm_conditional/#imports-and-initial-setup","title":"Imports and Initial Setup","text":"<p>We start as always with our imports:</p> <pre><code>import dendron\nfrom dendron.actions.causal_lm_action import CausalLMActionConfig, CausalLMAction\nfrom dendron.conditions.completion_condition import CompletionConditionConfig, CompletionCondition\nfrom dendron.controls import Sequence, Fallback\nfrom dendron import NodeStatus\n\nimport torch\nfrom transformers import BarkModel, BarkProcessor\nfrom optimum.bettertransformer import BetterTransformer\n\nfrom spacy.lang.en import English \n\nimport time\nimport numpy as np\nimport sounddevice as sd\n</code></pre> <p>Most of this should be familiar from the previous parts, but a few points of interest do stand out. First, we import both <code>CompletionConditionConfig</code> and <code>CompletionCondition</code>. The import of a config class serves as a hint that <code>CompletionCondition</code> uses a model from Transformers. Secondly, we are now importing spaCy. You may need to <code>pip</code> install it. If you haven't used it before, spaCy is a great library for handling certain tasks related to natural language processing. We'll be using the library to perform some simple rule-based string splitting into sentences.</p> <p>Next up we repeat the definitions of the action and condition nodes from Part 2:</p> <pre><code>class MoreToSay(dendron.ConditionNode):\n    def __init__(self, speech_input_key=\"speech_in\"):\n        super().__init__(\"more_to_say\")\n        self.speech_input_key = speech_input_key\n\n    def tick(self):\n        if self.blackboard[self.speech_input_key] != []:\n            self.blackboard[\"turn_done\"] = False\n            return dendron.NodeStatus.SUCCESS\n        else:\n            self.blackboard[\"turn_done\"] = True\n            return dendron.NodeStatus.FAILURE\n\nclass TimeToThink(dendron.ConditionNode):\n    \"\"\"\n    PRE:\n        blackboard[human_input_key] should be set\n    POST:\n    \"\"\"\n    def __init__(self, human_input_key = \"latest_human_input\"):\n        super().__init__(\"time_to_think\")\n        self.human_input_key = human_input_key\n        self.last_human_input = None\n\n    def tick(self):\n        human_input = self.blackboard[self.human_input_key]\n        if self.last_human_input is not None and human_input != self.last_human_input:\n            status = NodeStatus.SUCCESS\n        else:\n            status = NodeStatus.FAILURE\n\n        self.last_human_input = human_input\n        return status\n\nclass GetTextInput(dendron.ActionNode):\n    \"\"\"\n    PRE: None\n    POST: \n        blackboard[latest_human_input_key] = input\n        blackboard[\"in\"] = chat\n    \"\"\"\n    def __init__(self, latest_human_input_key = \"latest_human_input\"):\n        super().__init__(\"get_text_input\")\n        self.latest_human_input_key = latest_human_input_key\n\n    def tick(self):        \n        self.blackboard[self.latest_human_input_key] = input(\"Human: \")\n\n        chat = self.blackboard[\"chat_history\"]\n        chat.append({\"role\": \"GPT4 Correct User\", \"content\" : self.blackboard[self.latest_human_input_key]})\n        self.blackboard[\"in\"] = chat\n\n        return NodeStatus.SUCCESS\n</code></pre> <p>All of this is similar to the previous part, except you might notice that in <code>TimeToThink</code> we initialize <code>self.last_human_input = None</code>. This is entirely artificial, but below it will give us a chance to show how to pre-register key-value pairs with our blackboard.</p>"},{"location":"3_tutorial_llm_conditional/#ttsaction-and-sentence-splitting","title":"<code>TTSAction</code> and Sentence Splitting","text":"<p>Next we define our <code>TTSAction</code> and <code>play_speech</code> function:</p> <pre><code>class TTSAction(dendron.ActionNode):\n    def __init__(self, name):\n        super().__init__(name)\n        self.processor = BarkProcessor.from_pretrained(\"suno/bark-small\", torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\")\n        self.model = BarkModel.from_pretrained(\"suno/bark-small\").to(\"cuda\")\n        self.model = self.model.to_bettertransformer() \n        self.model.enable_cpu_offload()\n\n    def tick(self):\n        try:\n            input_text = self.blackboard[\"speech_in\"]\n            inputs = self.processor(text=input_text, voice_preset=\"v2/en_speaker_9\", return_tensors=\"pt\").to(\"cuda\")\n            self.blackboard[\"speech_out\"] = self.model.generate(**inputs, do_sample = True, fine_temperature = 0.4, coarse_temperature = 0.8).cpu().numpy()\n            self.blackboard[\"speech_in\"] = []\n        except Exception as e:\n            print(\"Speech generation exception: \", e)\n            return dendron.NodeStatus.FAILURE\n\n        return dendron.NodeStatus.SUCCESS\n\ndef play_speech(self):\n    num_utterances = self.blackboard[\"speech_out\"].shape[0]\n\n    for i in range(num_utterances):\n        sd.play(self.blackboard[\"speech_out\"][i,:], self.model.generation_config.sample_rate)\n        sd.wait()\n</code></pre> <p>The class includes a few added bells and whistles, but should be mostly familiar by now. The <code>play_speech</code> function is very different, since it appears that we are now processing a series of utterances to speak. To understand why we do this, let's talk about sentence splitting.</p>"},{"location":"3_tutorial_llm_conditional/#sentence-splitting","title":"Sentence Splitting","text":"<p>In Part 1, we mentioned that current neural TTS models often struggle with longer utterances. This is something that seems to affect all models, but is particlarly pronounced for smaller models (if you have heard any haunting sounds or screeching from <code>\"bark-small\"</code> you might consider trying the bigger <code>\"bark\"</code>). It turns out you can somewhat mitigate the problem by splitting large utterances into shorter ones. You could do this solely based on string length, but then you're likely to break coherent statements into fragments, which will be spoken in weird ways. It would be best if we could split long strings at natural pause points, like sentence boundaries.</p> <p>Here we show a simple strategy for doing this using rule-based AI. You could certainly do better with a learning-based approach, but what we'll do here is quick, easy, and often good enough. The capability we're after is provided by spaCy, which we'll wrap in an <code>ActionNode</code>:</p> <pre><code>class SentenceSplitter(dendron.ActionNode):\n    def __init__(self, in_key=\"speech_in\"):\n        super().__init__(\"sentence_splitter\")\n        self.in_key = in_key\n        self.splitter = English()\n        self.splitter.add_pipe(\"sentencizer\")\n\n    def tick(self):\n        latest_text = self.blackboard[self.in_key].pop()\n        if len(latest_text) &gt; 64:\n            sentences = self.splitter(latest_text).sents\n            for s in sentences:\n                s_prime = str(s).strip()\n                if len(s_prime) &gt; 0:\n                    self.blackboard[self.in_key].append(s_prime)\n        else:\n            self.blackboard[self.in_key].append(latest_text)\n        return NodeStatus.SUCCESS\n</code></pre> <p>In the constructor, we initialize a spaCy pipeline to perform tokenization at the sentence level. In the <code>tick</code> function we use that pipeline to split longer strings into sentences, strip the sentences of whitespace, and add them back to the appropriate slot in the blackboard.</p>"},{"location":"3_tutorial_llm_conditional/#defining-a-single-turn-in-the-conversation","title":"Defining a Single Turn in the Conversation","text":"<p>As in Part 2, we will define a turn in the chat as consisting of speaking, thinking, and listening. Since most of the details are the same as in previous tutorials, we show all of the code while our commentary focuses primarily on differences from previous parts of the tutorial.</p>"},{"location":"3_tutorial_llm_conditional/#the-speech-sequence","title":"The Speech Sequence","text":"<p>With the <code>TTSAction</code> defined as above, we can define a <code>speech_node</code> and <code>speech_seq</code> as in Part 2:</p> <pre><code>speech_node = TTSAction(\"speech_node\")\nspeech_node.add_post_tick(play_speech)\n\nspeech_seq = Sequence(\"speech_seq\", [\n    MoreToSay(),\n    speech_node\n])\n</code></pre>"},{"location":"3_tutorial_llm_conditional/#the-thought-sequence","title":"The Thought Sequence","text":"<p>To define our thought sequence, we just need to repeat our code from Part 2:</p> <pre><code>chat_behavior_cfg = CausalLMActionConfig(load_in_4bit=True,\n                                         max_new_tokens=128,\n                                         do_sample=True,\n                                         top_p=0.95,\n                                         use_flash_attn_2=True,\n                                         model_name='openchat/openchat_3.5')\n\nchat_node = CausalLMAction('chat_node', chat_behavior_cfg)\n\ndef chat_to_str(self, chat):\n    return self.tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n\ndef str_to_chat(self, str):\n    key = \"GPT4 Correct Assistant:\"\n    idx = str.rfind(key)\n    response = str[idx+len(key):]\n    chat = self.blackboard[self.input_key]\n    chat.append({\"role\" : \"GPT4 Correct Assistant\", \"content\" : response})\n    return chat\n\ndef set_next_speech(self):\n    text_output = self.blackboard[\"out\"][-1][\"content\"]\n    self.blackboard[\"speech_in\"].append(text_output)\n\nchat_node.set_input_processor(chat_to_str)\nchat_node.set_output_processor(str_to_chat)\nchat_node.add_post_tick(set_next_speech)\n\nthought_seq = Sequence(\"thought_seq\", [\n    TimeToThink(),\n    chat_node,\n    SentenceSplitter()\n])\n</code></pre> <p>Aside from a bit of blackboard gymnastics, this should mostly be familiar from the previous parts of the tutorial. Notice that we are adding a <code>SentenceSplitter</code> node to the end of our thought sequence, so that if the <code>chat_node</code> generates a string that is too long to speak we can split it immediately before our <code>TTSAction</code> has a chance to run.</p> <p>Once we have defined <code>thought_seq</code>, we have enough to define a single turn in a conversation:</p> <pre><code>conversation_turn = Fallback(\"conversation_turn\", [\n    speech_seq,\n    thought_seq,\n    GetTextInput()\n])\n</code></pre> <p>This should look familiar as the root node from Part 2 of the tutorial. We still haven't implemented a way to break out of the chat loop, so lets build a \"farewell classifier\" using a <code>CompletionCondition</code> node.</p>"},{"location":"3_tutorial_llm_conditional/#completioncondition-for-classifying-strings","title":"<code>CompletionCondition</code> for Classifying Strings","text":"<p>A <code>CompletionCondition</code> node is, as the name suggests, a condition node that returns <code>SUCCESS</code> or <code>FAILURE</code> based on the output of an autoregressive language model. Although we mostly use language models to generate text these days, it's important to remember that language models are probability models, so in addition to generating text by sampling we can also evaluate the conditional probability of any string given any other string (as long as the combination fits inside the model's context window). This opens the door to the following strategy for evaluating a logical condition using a language model:</p> <ol> <li>Write down a prompt that includes a statement and a question with a closed set of possible answers. Include a placeholder where possible answers could go.</li> <li>Write down the possible answers in a list.</li> <li>Generate a batch for the model consisting of all the possible completions of answers to questions.</li> <li>Run the model on the batch to get a probability for each question-answer pair.</li> <li>Select the answer with the highest probability relative to the other answers.</li> <li>Determine if this answer corresponds to <code>SUCCESS</code> or <code>FAILURE</code> depending on the nature of the problem.</li> </ol> <p>The <code>CompletionCondition</code> implements precisely this strategy (with some nuance due to how the Transformers library implements probability calculations). Let's look at the code and then we can talk about its parts:</p> <pre><code>farewell_classifier_cfg = CompletionConditionConfig(\n    input_key = \"farewell_test_in\",\n    load_in_4bit=True,\n    model_name='mlabonne/Monarch-7B',\n    use_flash_attn_2=True\n)\n\nfarewell_classification_node = CompletionCondition(\"farewell_classifier\", farewell_classifier_cfg)\n\ndef farewell_success_fn(completion):\n    \"\"\"\n    Return SUCCESS if the conversation is done.\n    \"\"\"\n    if completion == \"yes\":\n        return NodeStatus.SUCCESS\n    else:\n        return NodeStatus.FAILURE\n\ndef farewell_pretick(self):\n    last_input = self.blackboard[\"latest_human_input\"]\n    chat = [{\"role\": \"user\", \"content\": f\"\"\"The last thing the human said was \"{last_input}\". Is the user saying Goodbye?\"\"\"}]\n    self.blackboard[self.input_key] = self.tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n\nfarewell_classification_node.add_pre_tick(farewell_pretick)\n\ndef farewell_posttick(self):\n    if self.status == NodeStatus.SUCCESS:\n        self.blackboard[\"all_done\"] = True\n\nfarewell_classification_node.add_post_tick(farewell_posttick)\n</code></pre> <p>This is a big block of code, but if you've followed the tutorial up to this point you have everything you need to understand what's going on. First we create a config object that specifies the model to use, the input key for the blackboard, and some optimization flags. Then we create our <code>farewell_classification_node</code> using that configuration. Then we define a <code>farewell_success_fn</code>, a <code>farewell_pretick</code> function, and a <code>farewell_posttick</code> function. The pre- and post-tick functions are responsible for handling state management and format conversion. The model we're using requires some formatting similar to <code>openchat_3.5</code>, so we put that processing in <code>farewell_pretick</code>. (We could do this in an input processor, but using a pre-tick function works just as well.) The post-tick function is solely responsible for deciding if the blackboard should be updated to set the <code>\"all_done\"</code> flag to <code>True</code>.</p> <p>Even without saying what exactly <code>farewell_success_fn</code> does, you can probably read these three functions and make a guess at how they fit together. In the pre-tick we set up a \"yes-no\" question asking if the user is saying goodbye. The <code>farewell_success_fn</code> takes a completion (it will turn out to be the highest scoring completion) and if it is \"yes\" then it returns <code>SUCCESS</code>. This is status returned as the node's status, and the post-tick function checks that status and updates the blackboard if the status is <code>SUCCESS</code>. In this way, the <code>CompletionCondition</code> node implements a kind of classifier over text strings. </p> <p>You might be wondering how the completions are passed to the node. If you guessed \"via the blackboard,\" then you're right! You can scroll down to see how the blackboard is set up once we create a <code>BehaviorTree</code> instance, or you can look at the documentation for <code>CompletionCondition</code>.</p> <p>Lastly, we implement an action node responsible for saying goodbye. We could just end the conversation as we have before, but since we're already in the process of adding intelligence to our system, we may as well have the node speak goodbye:</p> <pre><code>class SayGoodbye(dendron.ActionNode):\n    def __init__(self):\n        super().__init__(\"say_goodbye\")\n\n    def tick(self):\n        if self.blackboard[\"all_done\"]:\n            self.blackboard[\"speech_in\"].append(\"Goodbye!\")\n            return NodeStatus.SUCCESS\n</code></pre> <p>All this node does is check if the <code>\"all_done\"</code> flag is set, and if so we add a \"Goodbye!\" to the <code>\"speech_in\"</code> slot in the blackboard.</p> <p>At this point we can build our farewell classifier using a <code>Sequence</code>:</p> <pre><code>goodbye_test = Sequence(\"goodbye_test\", [\n    farewell_classification_node,\n    SayGoodbye(), \n    speech_node\n])\n</code></pre> <p>In addition to the <code>farewell_classification_node</code> we defined above, the other noteworthy thing about this snippet is that we are reusing our <code>speech_node</code>. This is perfectly valid as long as your nodes control their state and side effects. Language models (and neural networks in general) are pure functions except possibly for the randomness introduced by sampling, but even with sampling it turns out that this kind of model reuse is viable for our application, and saves a bunch of GPU VRAM.</p>"},{"location":"3_tutorial_llm_conditional/#building-the-tree","title":"Building the Tree","text":"<p>Now that we have defined all of the components we need, we can build our tree:</p> <pre><code>root_node = Fallback(\"converse\", [\n    goodbye_test,\n    conversation_turn,\n])\n\ntree = dendron.BehaviorTree(\"chat_tree\", root_node)\n</code></pre> <p>This results in a tree that looks like the following:</p> <p> <p>Once our tree is set up, we just need to initialize our blackboard and start our chat loop:</p> <pre><code>tree.blackboard[\"chat_history\"] = []\ntree.blackboard[\"speech_in\"] = []\n\ntree.blackboard.register_entry(dendron.blackboard.BlackboardEntryMetadata(\n    key = \"latest_human_input\",\n    description = \"The last thing the human said.\",\n    type_constructor = str\n))\ntree.blackboard[\"latest_human_input\"] = None\n\ntree.blackboard[\"completions_in\"] = [\"yes\", \"no\"]\ntree.blackboard[\"success_fn\"] = farewell_success_fn\ntree.blackboard[\"all_done\"] = False\n</code></pre> <p>Almost all of this should be clear by now, except for how we set up the key <code>\"latest_human_input\"</code>. For that key, we register the entry with our blackboard before setting a value. Registering an entry with a blackboard allows us to specify a description for the entry, and more importantly lets us specify a type for the value. Here, if we were to just assign <code>None</code> to the value without registering the value first, we would eventually run into type errors when we tried to use the value. </p> <p>Also of note we specify <code>\"completions_in\"</code> and <code>\"success_fn\"</code> for the <code>CompletionCondition</code> we defined above. Because we pass these and the input prefix to the node via the blackboard, we can change the question, possible answers, and success criterion for a <code>CompletionCondition</code> dynamically at runtime.</p>"},{"location":"3_tutorial_llm_conditional/#the-chat-loop","title":"The Chat Loop","text":"<p>We are now in a position to run our chat loop:</p> <pre><code>while not tree.blackboard[\"all_done\"]:\n    tree.tick_once()\n</code></pre> <p>Instead of looping forever, we loop until the blackboard slot for <code>\"all_done\"</code> returns <code>True</code>. We <code>tick</code> as fast as we can, which works just fine for a chat application. If we were running this code on a robot though, we would probably run our chat loop at some fixed frequency, such as 20 or 50Hz.</p>"},{"location":"3_tutorial_llm_conditional/#conclusion","title":"Conclusion","text":"<p>You now have an agent that can detect when you are trying to say goodbye and respond appropriately. The agent uses three language models and a rule-based AI system to perform its work, and this runs in about 14GB on a single RTX 3090! For the last part of this tutorial, we'll extend our system just a little bit more to add speech recognition on top of the tree we've built in this part. Then you'll have a local chat agent that can literally speak and listen to you.</p>"},{"location":"4_supporting_code/","title":"Supporting Definitions for Tutorial 1, Part 4","text":"<p>As mentioned in Part 4, I move the node definitions for that part into a separate file named <code>dendron_tutorial_1.py</code>, and import that file rather than repeat all of the old class and function definitions. The contents of that file are as follows:</p> <pre><code>import dendron\nfrom dendron.actions.causal_lm_action import CausalLMActionConfig, CausalLMAction\nfrom dendron.conditions.completion_condition import CompletionConditionConfig, CompletionCondition\nfrom dendron.controls import Sequence, Fallback\nfrom dendron import NodeStatus\n\nimport torch\n\nfrom transformers import BarkModel, BarkProcessor\nfrom optimum.bettertransformer import BetterTransformer\nfrom spacy.lang.en import English \nimport time\nimport numpy as np\nimport sounddevice as sd\n\nclass MoreToSay(dendron.ConditionNode):\n    def __init__(self, speech_input_key=\"speech_in\"):\n        super().__init__(\"more_to_say\")\n        self.speech_input_key = speech_input_key\n\n    def tick(self):\n        if self.blackboard[self.speech_input_key] != []:\n            return dendron.NodeStatus.SUCCESS\n        else:\n            return dendron.NodeStatus.FAILURE\n\nclass TimeToThink(dendron.ConditionNode):\n    \"\"\"\n    PRE:\n        blackboard[human_input_key] should be set\n    POST:\n    \"\"\"\n    def __init__(self, human_input_key = \"latest_human_input\"):\n        super().__init__(\"time_to_think\")\n        self.human_input_key = human_input_key\n        self.last_human_input = None\n\n    def tick(self):\n        human_input = self.blackboard[self.human_input_key]\n        if self.last_human_input is not None and human_input != self.last_human_input:\n            status = NodeStatus.SUCCESS\n        else:\n            status = NodeStatus.FAILURE\n\n        self.last_human_input = human_input\n        return status\n\nclass TTSAction(dendron.ActionNode):\n    def __init__(self, name):\n        super().__init__(name)\n        self.processor = BarkProcessor.from_pretrained(\"suno/bark-small\", torch_dtype=torch.bfloat16, attn_implementation=\"flash_attention_2\")\n        self.model = BarkModel.from_pretrained(\"suno/bark-small\").to(\"cuda\")\n        self.model = self.model.to_bettertransformer() #BetterTransformer.transform(self.model, keep_original_model=False)\n        self.model.enable_cpu_offload()\n\n    def tick(self):\n        try:\n            input_text = self.blackboard[\"speech_in\"]\n            inputs = self.processor(text=input_text, voice_preset=\"v2/en_speaker_9\", return_tensors=\"pt\").to(\"cuda\")\n            self.blackboard[\"speech_out\"] = self.model.generate(**inputs, do_sample = True, fine_temperature = 0.4, coarse_temperature = 0.8).cpu().numpy()\n            self.blackboard[\"speech_in\"] = []\n        except Exception as e:\n            print(\"Speech generation exception: \", e)\n            return dendron.NodeStatus.FAILURE\n\n        return dendron.NodeStatus.SUCCESS\n\ndef play_speech(self):\n    num_utterances = self.blackboard[\"speech_out\"].shape[0]\n\n    for i in range(num_utterances):\n        sd.play(self.blackboard[\"speech_out\"][i,:], self.model.generation_config.sample_rate)\n        sd.wait()\n\nclass SentenceSplitter(dendron.ActionNode):\n    def __init__(self, in_key=\"speech_in\"):\n        super().__init__(\"sentence_splitter\")\n        self.in_key = in_key\n        self.splitter = English()\n        self.splitter.add_pipe(\"sentencizer\")\n\n    def tick(self):\n        latest_text = self.blackboard[self.in_key].pop()\n        if len(latest_text) &gt; 64:\n            sentences = self.splitter(latest_text).sents\n            for s in sentences:\n                s_prime = str(s).strip()\n                if len(s_prime) &gt; 0:\n                    self.blackboard[self.in_key].append(s_prime)\n        else:\n            self.blackboard[self.in_key].append(latest_text)\n        return NodeStatus.SUCCESS\n\nclass SayGoodbye(dendron.ActionNode):\n    def __init__(self):\n        super().__init__(\"say_goodbye\")\n\n    def tick(self):\n        if self.blackboard[\"all_done\"]:\n            self.blackboard[\"speech_in\"].append(\"Goodbye!\")\n            return NodeStatus.SUCCESS\n\ndef chat_to_str(self, chat):\n    return self.tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n\ndef str_to_chat(self, str):\n    key = \"GPT4 Correct Assistant:\"\n    idx = str.rfind(key)\n    response = str[idx+len(key):]\n    chat = self.blackboard[self.input_key]\n    chat.append({\"role\" : \"GPT4 Correct Assistant\", \"content\" : response})\n    return chat\n\ndef set_next_speech(self):\n    text_output = self.blackboard[\"out\"][-1][\"content\"]\n    self.blackboard[\"speech_in\"].append(text_output)\n\ndef farewell_success_fn(completion):\n    \"\"\"\n    Return SUCCESS if the conversation is done.\n    \"\"\"\n    if completion == \"yes\":\n        return NodeStatus.SUCCESS\n    else:\n        return NodeStatus.FAILURE\n\ndef farewell_pretick(self):\n    last_input = self.blackboard[\"latest_human_input\"]\n    chat = [{\"role\": \"user\", \"content\": f\"\"\"The last thing the human said was \"{last_input}\". Is the user saying Goodbye?\"\"\"}]\n    self.blackboard[self.input_key] = self.tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n\ndef farewell_posttick(self):\n    if self.status == NodeStatus.SUCCESS:\n        self.blackboard[\"all_done\"] = True\n</code></pre>"},{"location":"4_tutorial_tts_asr_chat/","title":"4. Building a Chat Agent with Dendron: Chat with TTS and ASR","text":"<p>In Part 3 we learned how to add <code>CompletionCondition</code> nodes to our behavior tree, enabling our agent to analyze the human's inputs and terminate the conversation when appropriate. In this last part of the tutorial, we will make a small change in the code to use automatic speech recognition (ASR) to allow spoken human inputs to our agent instead of text. </p> <p>If you find this tutorial too verbose and you just want to get the code, you can find the notebook for this part here.</p>"},{"location":"4_tutorial_tts_asr_chat/#simplifying-imports","title":"Simplifying Imports","text":"<p>Unlike the previous parts of this tutorial, we're going to start this part by showing you the tree you're going to build before we write any code:</p> <p> <p>If you've worked through Part 3, just about all of this tree should look familiar. In fact, the only difference between this tree and the one from Part 3 is that we have replaced the <code>get_text_input</code> node with a new <code>get_voice_input</code> node. The rest of the tree is identical to the previous one, and we can reuse all of the definitions we have already given. To that end, I have created a separate file named <code>dendron_tutorial_1.py</code> into which I have placed all of the class definitions we'll need for this part. You can see the contents of that file here. With the old definitions tucked away in a supporting file, we can start building the final tree of this tutorial with a much smaller set of imports:</p> <pre><code>from dendron_tutorial_1 import *\n\nfrom whisper_mic import WhisperMic\n</code></pre>"},{"location":"4_tutorial_tts_asr_chat/#getting-voice-inputs-with-whisper-mic","title":"Getting Voice Inputs with Whisper Mic","text":"<p>We want an easy way to get access to the microphone, and the <code>whisper_mic</code> package provides exactly that. Once installed, you can import a single Python object <code>WhisperMic</code> that accesses your microphone and performs ASR.</p> <p>Info</p> <p>Whisper is a neural net released by OpenAI to perform speech recognition. It is quite good, but the package that OpenAI released focuses on supporting file-based transcription. The Whisper Mic project makes it possible to transcribe speech directly from a microphone. You can install Whisper mic by running <code>pip install whisper-mic</code>.</p> <p>Once we have access to a microphone and speech recognition, we need to wrap those capabilities into a custom Dendron node. The basic structure should be familiar by now:</p> <pre><code>class GetVoiceInput(dendron.ActionNode):\n    def __init__(self, latest_human_input_key = \"latest_human_input\"):\n        super().__init__(\"get_voice_input\")\n        self.latest_human_input_key = latest_human_input_key\n        self.mic = WhisperMic()\n\n    def tick(self):\n        t = np.arange(8000) / 16000\n        t = t.reshape(-1, 1)\n        beep = 0.2 * np.sin(2 * np.pi * 440 * t)\n        sd.play(beep, 16000)\n\n        self.blackboard[self.latest_human_input_key] = self.mic.listen()\n\n        chat = self.blackboard[\"chat_history\"]\n        chat.append({\"role\": \"GPT4 Correct User\", \"content\" : self.blackboard[self.latest_human_input_key]})\n        self.blackboard[\"in\"] = chat\n\n        return NodeStatus.SUCCESS        \n</code></pre> <p>In the <code>GetVoiceInput</code> constructor we initialize a <code>WhisperMic</code> object and keep track of the latest human input, just as in the previous part. The tick function can be understood in two parts:</p> <ol> <li>Generate a beep to indicate when the human should speak.</li> <li>Listen to the microphone and transcribe any human speech that is heard.</li> </ol> <p>Lines 8-11 in <code>tick</code> play a beep for half a second (a satisfying 440Hz A note). We then use our <code>WhisperMic</code> object's <code>listen</code> member function, which returns transcribed text as a string. That string is then written to the blackboard. We go ahead and also update our chat object inside this <code>tick</code> and then return <code>SUCCESS</code>.</p> <p>That's all there is to it. Obviously there's a lot of complexity hidden inside that <code>self.mic.listen()</code> call, since the library is creating an abstraction over both your hardware and the ASR process, but if all you need is a quick way to get transcribed speech from a mic, it's hard to beat line 13 above. Even better, <code>GetVoiceInput</code> is the only class we need to define. All that's left is to put the tree together.</p>"},{"location":"4_tutorial_tts_asr_chat/#building-the-nodes-of-the-tree","title":"Building the Nodes of the Tree","text":"<p>Defining our tree nodes follows exactly the same process as in previous parts of this tutorial. Rather than rehash all of that, I'll show the code that we already know works, rearranged a bit since we've moved definitions into a separate file:</p> <pre><code>speech_node = TTSAction(\"speech_node\")\nspeech_node.add_post_tick(play_speech)\n\nchat_behavior_cfg = CausalLMActionConfig(load_in_4bit=True,\n                                         max_new_tokens=128,\n                                         do_sample=True,\n                                         top_p=0.95,\n                                         use_flash_attn_2=True,\n                                         model_name='openchat/openchat_3.5')\n\nchat_node = CausalLMAction('chat_node', chat_behavior_cfg)\n\nchat_node.set_input_processor(chat_to_str)\nchat_node.set_output_processor(str_to_chat)\nchat_node.add_post_tick(set_next_speech)\n\nfarewell_classifier_cfg = CompletionConditionConfig(\n    input_key = \"farewell_test_in\",\n    load_in_4bit=True,\n    model_name='mlabonne/Monarch-7B',\n    use_flash_attn_2=True\n)\n\nfarewell_classification_node = CompletionCondition(\"farewell_classifier\", farewell_classifier_cfg)\nfarewell_classification_node.add_pre_tick(farewell_pretick)\nfarewell_classification_node.add_post_tick(farewell_posttick)\n</code></pre> <p>Here we are defining the leaf nodes that rely on neural networks, following the steps in our previous tutorials. There are going to be a few nodes that we don't store into variables before insertion into the tree; those all rely on classes that we import from our definition file.</p>"},{"location":"4_tutorial_tts_asr_chat/#building-the-tree","title":"Building the Tree","text":"<p>Once our leaf nodes are defined we can build the tree. Here's the code:</p> <pre><code>speech_seq = Sequence(\"speech_seq\", [\n    MoreToSay(),\n    speech_node\n])\n\nthought_seq = Sequence(\"thought_seq\", [\n    TimeToThink(),\n    chat_node,\n    SentenceSplitter()\n])\n\ngoodbye_test = Sequence(\"goodbye_test\", [\n    farewell_classification_node,\n    SayGoodbye(), \n    speech_node\n])\n\nconversation_turn = Fallback(\"conversation_turn\", [\n    speech_seq,\n    thought_seq,\n    GetVoiceInput()\n])\n\nroot_node = Fallback(\"converse\", [\n    goodbye_test,\n    conversation_turn,\n])\n\ntree = dendron.BehaviorTree(\"chat_tree\", root_node)\n</code></pre> <p>We are following roughly the same sequence of steps as in previous parts of the tutorial, but here it should be clearer that we are building the tree from the leaves up. This is a good way to develop complex behavior trees: start with leaves for individual behaviors, combine them into subtrees, and then recursively combine the subtrees until you get a tree that does what you want. The only new thing we introduce is the use of <code>GetVoiceInput()</code> on line 21 in place of <code>GetTextInput()</code> from the previous parts of the tutorial. With that small change, you have enhanced your behavior tree into an agent that listens instead of reading. All that remains is to initialize the state of the tree and talk to it.</p>"},{"location":"4_tutorial_tts_asr_chat/#setting-up-the-blackboard","title":"Setting Up the Blackboard","text":"<p>State initialization is handled via the blackboard:</p> <pre><code>tree.blackboard[\"chat_history\"] = []\ntree.blackboard[\"speech_in\"] = []\n\ntree.blackboard.register_entry(dendron.blackboard.BlackboardEntryMetadata(\n    key = \"latest_human_input\",\n    description = \"The last thing the human said.\",\n    type_constructor = str\n))\ntree.blackboard[\"latest_human_input\"] = None\n\ntree.blackboard[\"completions_in\"] = [\"yes\", \"no\"]\ntree.blackboard[\"success_fn\"] = farewell_success_fn\ntree.blackboard[\"all_done\"] = False\n</code></pre> <p>Nothing new here, just repeating what we've done in previous parts to get our blackboard set up.</p>"},{"location":"4_tutorial_tts_asr_chat/#running-the-chat-loop","title":"Running the Chat Loop","text":"<p>Last but not least, we can now run our chat loop:</p> <pre><code>while not tree.blackboard[\"all_done\"]:\n    tree.tick_once()\n</code></pre> <p>Of course make sure you have a microphone turned on, or the system will just sit waiting to hear some speech. As soon as you run the loop you will hear a short beep - this is the indication that it's your turn to speak. Start talking, and when you finish you'll experience a short delay (a few seconds) and then the agent will respond. Once you're done, you can tell the agent \"goodbye\" or \"farewell\" or \"peace out\" (that last one should work just fine) and the conversation will end. </p>"},{"location":"4_tutorial_tts_asr_chat/#conclusion","title":"Conclusion","text":"<p>And so we come to the end of Tutorial 1. With consumer-grade hardware, you can carry on in conversation with your computer as long as you want. Admittedly, that probably won't be very long with this particular agent. In just a few minutes of playing with it, you can probably find a lot of rough edges. Some of these are fundamental, but many of them could be improved with a more sophisticated tree design. For example, if you forget to turn on your microphone until after you instantiate <code>GetVoiceInput</code>, the system will \"listen,\" but will never hear you. It would be better for your tree to check for the microphone every few seconds. More annoying, the TTS is a little slow. If you're not very patient it can be hard to wait for answers or know when the agent is done speaking. You might try other models, or go with a completely non-neural TTS solution. That would be as easy as swapping out the <code>TTSAction</code> we have been using for one that is just slightly different. You could also try adding in <code>print</code> statements to show the output of the <code>chat_node</code> before it gets sent to the <code>TTSAction</code>. </p> <p>At this point, you know enough about Dendron to start building applications of your own. We haven't talked about all of the different node types, but with the language model nodes we have introduced you can do quite a bit. In future tutorials we'll talk about \"decorator nodes\", Denron's support for GUI-based tree design, and Dendron's multimodal LM capabilities. If you can't wait for that last one, check out the API reference for <code>ImageLMAction</code> or the example notebook in the dendron repository. In the meantime, happy hacking!</p>"},{"location":"install/","title":"Installation","text":"<p>Installing dendron should be as easy as running the following <code>pip</code> command:</p> <pre><code>pip install dendron\n</code></pre> <p>If you want to install from source for testing or contributing, you can activate your development environment, <code>git clone</code> the dendron repository, cd into it, and run</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"theory/","title":"An Argument for the Necessity of Behavior Trees for LLM Systems","text":"<p>We want to use LLMs and VLMs to build complex systems from simpler parts. Every sufficiently powerful formalism for building complex systems out of simpler parts has three mechanisms for achieving that goal: primitive elements, means of combination, and means of abstraction. The behavior tree formalism is no different. In our case, we have  </p> <p>All sufficiently powerful formal systems have three common </p> <p>A language model  is a conditional probability distribution: given a sequence of tokens  from a vocabulary ,</p> <ol> <li>LMs as CPDs</li> <li>LMs as Context-&gt;Context mappings</li> <li>Two issues with ad hoc solutions   a. Semantics vs. Syntax: Contexts are syntactic objects   b. Compositionality is unclear</li> </ol>"},{"location":"tutorial_intro/","title":"Building a Local Chat Agent with Dendron","text":"<p>Dendron is a Python library for building applications using behavior trees to structure and coordinate the execution of one or more large transformer-based neural network models. I'm going to assume that you have some idea of what transformer-based neural nets are, and in this introductory tutorial I'll show you how to use behavior trees to do \"structured programming\" with those models. So that we are all starting from a similar place, let's begin by giving a high-level description of how behavior trees work before we dive into implementing one using Dendron.</p>"},{"location":"tutorial_intro/#a-quick-overview-of-behavior-trees","title":"A Quick Overview of Behavior Trees","text":"<p>A behavior is a discrete unit of action performed in the world. If this definition feels ambiguous, that's because it is: in some applications an individual behavior is a coarse thing; in others a very fine unit of execution. Examples of behaviors are <code>transcribe a segment of audio data into English language text</code> or <code>Look at this image and output the string \"yes\" if it contains a puppy</code> or <code>generate a string of text based on the given chat history</code>. You'll need to understand your individual problem and solution spaces to decide what the natural behaviors are in your case. To solve most problems requires more than one behavior: a sequence of actions, or perhaps an attempt at multiple possible actions until one succeeds, or something still more complicated. Once you have multiple behaviors, you have to decide how to structure their interactions. A behavior tree is a particular framework for thinking about how behaviors should interact.</p> <p>In a behavior tree, we represent a collection of behaviors as a tree, in which individual behaviors are the leaf nodes and the interior nodes of the tree contain the logic that coordinates the behaviors. To make the tree do something, we tick the root node. The root then propagates that tick down the tree. Each node in the tree knows what to do when it is ticked. Once a node is done performing the actions associated with its tick operation, it returns a status back to its parent: either <code>SUCCESS</code> or <code>FAILURE</code>, or less commonly <code>RUNNING</code> to indicate that the node is still going. The tick signal flows through the tree according to the logic implemented by the tree's interior nodes.</p> <p>An example of a behavior tree (in fact, the behavior tree that you will have built by the end of this tutorial) can be seen below. You can click to zoom the image:</p> <p> <p>This tree implements a chat agent that listens to a human via a microphone, transcribes the audio using a transformer-based speech recognition model, generates responses to the human via a large language model that has been tuned for chat, and replies using text-to-speech via a third transformer-based model. Using still another model, the tree also analyzes the human's input and determines, based on the human's words, if it is time for the agent to say goodbye and end the chat. </p> <p>Note</p> <p>If you are reading the tree from left to right and thinking that it looks a little backwards, good! Read on: you'll see why it is arranged that way in Part 2 of the tutorial. The tree and its notation will be fully explained by the end of Part 4 of the tutorial.</p>"},{"location":"tutorial_intro/#getting-started-and-moving-forward","title":"Getting Started and Moving Forward","text":"<p>I'm going to assume that you have installed Dendron and its requirements. If you haven't yet, run</p> <pre><code>pip install dendron\n</code></pre> <p>in your Python environment, or check out this link for details.</p> <p>Once you have Dendron installed, you can move on to building a behavior tree with a single node.</p>"},{"location":"api/action_node/","title":"ActionNode","text":""},{"location":"api/action_node/#dendron.action_node.ActionNode","title":"<code>dendron.action_node.ActionNode</code>","text":"<p>             Bases: <code>TreeNode</code></p> <p>An action node encapsulates the notion of a self-contained action or behavior. The bulk of the observable actions of a behavior tree are due to the action nodes.</p> <p><code>ActionNode</code>s are one of the two kinds of leaf nodes in a Behavior Tree - the other being the <code>ConditionNode</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required Source code in <code>src/dendron/action_node.py</code> <pre><code>class ActionNode(TreeNode):\n    \"\"\"\n    An action node encapsulates the notion of a self-contained action\n    or behavior. The bulk of the observable actions of a behavior tree\n    are due to the action nodes.\n\n    `ActionNode`s are one of the two kinds of leaf nodes in a Behavior\n    Tree - the other being the `ConditionNode`.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n    \"\"\"\n\n    def __init__(self, name) -&gt; None:\n        super().__init__(name)\n\n    def set_logger(self, new_logger) -&gt; None:\n        \"\"\"\n        Set the logger for this node.\n        \"\"\"\n        self.logger = new_logger\n\n    def set_log_level(self, new_level) -&gt; None:\n        \"\"\"\n        Set the log level for this node.\n        \"\"\"\n        self.log_level = new_level\n\n    def node_type(self) -&gt; NodeType:\n        \"\"\"\n        Get the type of this node.\n\n        Returns:\n            `NodeType`: The type (`ACTION`).\n        \"\"\"\n        return NodeType.ACTION\n\n    def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n        \"\"\"\n        Search for a node by its name.\n\n        Args:\n            name (`str`):\n                The name of the node we are looking for.\n\n        Returns:\n            `Optional[TreeNode]`: Either a node with the given name,\n            or None.\n        \"\"\"\n        if self.name == name:\n            return self\n        else:\n            return None\n\n    def pretty_repr(self, depth = 0) -&gt; str:\n        \"\"\"\n        Return a string representation of this node at the given depth.\n\n        Args:\n            depth (`int`):\n                The depth of this node in a surrounding tree.\n\n        Returns:\n            `str`: The indented string representation.\n        \"\"\"\n        tabs = '\\t'*depth\n        repr = f\"{tabs}Action {self.name}\"\n        return repr\n</code></pre>"},{"location":"api/action_node/#dendron.action_node.ActionNode.set_logger","title":"<code>set_logger(new_logger)</code>","text":"<p>Set the logger for this node.</p> Source code in <code>src/dendron/action_node.py</code> <pre><code>def set_logger(self, new_logger) -&gt; None:\n    \"\"\"\n    Set the logger for this node.\n    \"\"\"\n    self.logger = new_logger\n</code></pre>"},{"location":"api/action_node/#dendron.action_node.ActionNode.set_log_level","title":"<code>set_log_level(new_level)</code>","text":"<p>Set the log level for this node.</p> Source code in <code>src/dendron/action_node.py</code> <pre><code>def set_log_level(self, new_level) -&gt; None:\n    \"\"\"\n    Set the log level for this node.\n    \"\"\"\n    self.log_level = new_level\n</code></pre>"},{"location":"api/action_node/#dendron.action_node.ActionNode.node_type","title":"<code>node_type()</code>","text":"<p>Get the type of this node.</p> <p>Returns:</p> Type Description <code>NodeType</code> <p><code>NodeType</code>: The type (<code>ACTION</code>).</p> Source code in <code>src/dendron/action_node.py</code> <pre><code>def node_type(self) -&gt; NodeType:\n    \"\"\"\n    Get the type of this node.\n\n    Returns:\n        `NodeType`: The type (`ACTION`).\n    \"\"\"\n    return NodeType.ACTION\n</code></pre>"},{"location":"api/action_node/#dendron.action_node.ActionNode.get_node_by_name","title":"<code>get_node_by_name(name)</code>","text":"<p>Search for a node by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The name of the node we are looking for.</p> required <p>Returns:</p> Type Description <code>Optional[TreeNode]</code> <p><code>Optional[TreeNode]</code>: Either a node with the given name,</p> <code>Optional[TreeNode]</code> <p>or None.</p> Source code in <code>src/dendron/action_node.py</code> <pre><code>def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n    \"\"\"\n    Search for a node by its name.\n\n    Args:\n        name (`str`):\n            The name of the node we are looking for.\n\n    Returns:\n        `Optional[TreeNode]`: Either a node with the given name,\n        or None.\n    \"\"\"\n    if self.name == name:\n        return self\n    else:\n        return None\n</code></pre>"},{"location":"api/basic_types/","title":"Basic Types","text":""},{"location":"api/basic_types/#dendron.basic_types.NodeType","title":"<code>dendron.basic_types.NodeType</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Enum containing the types of nodes allowed in the behavior tree framework. Some of these are experimental.</p> Source code in <code>src/dendron/basic_types.py</code> <pre><code>class NodeType(Enum):\n    \"\"\"\n    Enum containing the types of nodes allowed in the behavior tree\n    framework. Some of these are experimental.\n    \"\"\"\n    UNDEFINED = 0\n    ACTION = 1\n    CONDITION = 2\n    CONTROL = 3\n    DECORATOR = 4\n    GOAL = 5\n    CONJUNCTION = 6\n    DISJUNCTION = 7\n    SUBTREE = 8\n</code></pre>"},{"location":"api/basic_types/#dendron.basic_types.NodeStatus","title":"<code>dendron.basic_types.NodeStatus</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Enum containing the allowable return values from node <code>tick</code>  functions.</p> Source code in <code>src/dendron/basic_types.py</code> <pre><code>class NodeStatus(Enum):\n    \"\"\"\n    Enum containing the allowable return values from node `tick` \n    functions.\n    \"\"\"\n    IDLE = 0\n    RUNNING = 1\n    SUCCESS = 2\n    FAILURE = 3\n    SKIPPED = 4\n</code></pre>"},{"location":"api/basic_types/#dendron.basic_types.Quantization","title":"<code>dendron.basic_types.Quantization</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Enum representing currently allowable quantization levels for neural models. <code>TwoBit</code> is currently aspirational.</p> Source code in <code>src/dendron/basic_types.py</code> <pre><code>class Quantization(Enum):\n    \"\"\"\n    Enum representing currently allowable quantization levels for\n    neural models. `TwoBit` is currently aspirational.\n    \"\"\"\n    NoQuantization = 0, \n    TwoBit = 2,\n    FourBit = 4,\n    EightBit = 8,\n</code></pre>"},{"location":"api/behavior_tree/","title":"BehaviorTree","text":""},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree","title":"<code>dendron.behavior_tree.BehaviorTree</code>","text":"<p>A <code>BehaviorTree</code> instance is a container for the nodes that make up a behavior tree. This object is responsible for maintaining a root node of the tree, a blackboard that is shared among the nodes of the tree, and a thread pool for asynchronous action nodes. </p> <p>Parameters:</p> Name Type Description Default <code>tree_name</code> <code>`str`</code> <p>The given name of this tree.</p> required <code>root_node</code> <code>`dendron.tree_node.TreeNode`</code> <p>The root node of this tree.</p> required <code>bb</code> <code>`dendron.blackboard.Blackboard`</code> <p>An optional pre-initialized blackboard to use in this tree.</p> <code>None</code> <code>num_workers</code> <code>`int`</code> <p>An optional number of workings to initialize the thread pool with.</p> <code>4</code> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>class BehaviorTree:\n    \"\"\"\n    A `BehaviorTree` instance is a container for the nodes that make\n    up a behavior tree. This object is responsible for maintaining a\n    root node of the tree, a blackboard that is shared among the nodes\n    of the tree, and a thread pool for asynchronous action nodes. \n\n    Args:\n        tree_name (`str`):\n            The given name of this tree.\n        root_node (`dendron.tree_node.TreeNode`):\n            The root node of this tree.\n        bb (`dendron.blackboard.Blackboard`):\n            An optional pre-initialized blackboard to use in this tree.\n        num_workers (`int`):\n            An optional number of workings to initialize the thread pool\n            with.\n    \"\"\"\n    def __init__(self, tree_name : str, root_node : TreeNode, bb : Blackboard = None, num_workers=4) -&gt; None:\n        self.tree_name = tree_name\n        self.root = root_node\n\n        if bb is None:\n            self.blackboard = Blackboard()\n        else:\n            self.blackboard = bb\n\n        self.root.set_blackboard(self.blackboard)\n        self.root.set_tree(self)\n\n        self.num_workers = num_workers\n        self.logger = None\n        self.log_file_name = None\n\n        self.executor = futures.ThreadPoolExecutor(max_workers=num_workers)\n\n    def __getstate__(self):\n        state = self.__dict__.copy()\n        del state['executor']\n        return state\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        self.executor = futures.ThreadPoolExecutor(max_workers=self.num_workers)\n\n    def __del__(self):\n        self.disable_logging()\n\n    def enable_logging(self) -&gt; None:\n        \"\"\"\n        Turn on logging for every node in this tree. By default,\n        each `tick()` call in every node results in a logging event.\n        \"\"\"\n        if self.logger is None:\n            self.logger = logging.getLogger(self.tree_name)\n            self.logger.setLevel(logging.DEBUG)\n            handler = logging.StreamHandler()\n            handler.setLevel(logging.DEBUG)\n            formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n            handler.setFormatter(formatter)\n            self.logger.addHandler(handler)\n            self.root.set_logger(self.logger)\n\n    def disable_logging(self) -&gt; None:\n        \"\"\"\n        Turn logging off. \n        \"\"\"\n        if self.logger is not None:\n            for h in self.logger.handlers:\n                h.close()\n                self.logger.removeHandler(h)\n        self.logger = None\n        self.log_file_name = None\n        # TODO set root logger to None? \n\n    def set_log_level(self, log_level) -&gt; None:\n        \"\"\"\n        Set the log level for the tree. This is a no-op if logging\n        is not enabled.\n        \"\"\"\n        level_to_set = None\n        if type(log_level) == str:\n            lvl = log_level.upper()\n            match lvl:\n                case \"DEBUG\":\n                    level_to_set = logging.DEBUG\n                case \"INFO\":\n                    level_to_set = logging.INFO\n                case \"WARNING\":\n                    level_to_set = logging.WARNING\n                case \"ERROR\":\n                    level_to_set = logging.ERROR\n                case \"CRITICAL\":\n                    level_to_set = logging.CRITICAL\n        elif type(log_level) == int:\n            level_to_set = log_level\n        else:\n            raise TypeError(\"log_level must be either int or str\")\n\n        if self.logger is not None:\n            self.logger.setLevel(level_to_set)\n            for h in self.logger.handlers:\n                h.setLevel(level_to_set)\n            self.root.set_log_level(level_to_set)\n\n    def set_log_filename(self, filename : Optional[str]) -&gt; None:\n        \"\"\"\n        If we want to log to a file instead of the command line, we use\n        this method to set a a file name. \n\n        Alternatively, if we are logging to a file and want to log to a\n        stream instead, we can call this method with the filename set to\n        `None`.\n\n        Args:\n            filename (`Optional[str]`):\n                If `None`, log to a stream. If a `filename`, log to a file\n                with that name.\n        \"\"\"\n        if self.logger is not None:\n            for h in self.logger.handlers:\n                h.close()\n                self.logger.removeHandler(h)\n\n            log_level = self.logger.level\n            f = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")            \n\n            if filename is None:\n                handler = logging.StreamHandler()\n                handler.setLevel(log_level)\n                handler.setFormatter(f)\n                self.logger.addHandler(handler)\n            else:\n                handler = logging.FileHandler(filename)\n                handler.setLevel(log_level)\n                handler.setFormatter(f)\n                self.logger.addHandler(handler)                \n\n    def set_root(self, new_root : TreeNode) -&gt; None:\n        \"\"\"\n        Set the root of the tree to a new node.\n\n        Args:\n            new_root (`dendron.tree_node.TreeNode`):\n                The new root node.\n        \"\"\"\n        self.root = new_root\n        new_root.set_tree(self)\n\n    def status(self) -&gt; NodeStatus:\n        \"\"\"\n        Return the current status of this tree. The status of a tree\n        is the current status of the root node of hte tree.\n\n        Returns:\n            `NodeStatus`: The status of the tree's root.\n        \"\"\"\n        return self.root.get_status()\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Instruct the root of the tree to `reset()`.\n        \"\"\"\n        self.root.reset()\n\n    def halt_tree(self) -&gt; None:\n        \"\"\"\n        Instruct the root of the tree to `halt()`.\n        \"\"\"\n        self.root.halt_node()\n\n    # TODO consider deprecating\n    def blackboard_get(self, key) -&gt; Any:\n        return self.blackboard[key]\n\n    # TODO consider deprecating\n    def blackboard_set(self, key, value) -&gt; None:\n        self.blackboard[key] = value\n\n    def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n        \"\"\"\n        Search for a node by its name. Forwards the call to the current\n        root node.\n\n        Args:\n            name (`str`):\n                The name of the node we are looking for.\n\n        Returns:\n            `Optional[TreeNode]`: Either a node with the given name,\n            or None.\n        \"\"\"\n        if self.root:\n            return self.root.get_node_by_name(name)\n        else:\n            return None\n\n    def tick_once(self) -&gt; NodeStatus:\n        \"\"\"\n        Instruct the root of the tree to execute its `tick()` function.\n\n        This is the primary interface to run a `BehaviorTree`.\n\n        Returns:\n            `NodeStatus`: The status returned by the root.\n        \"\"\"\n        return self.root.execute_tick()\n\n    def tick_while_running(self) -&gt; NodeStatus:\n        \"\"\"\n        Repeatedly `tick()` the behavior tree as long as the status\n        returned by the root is `RUNNING`. \n\n        At present, this is only possible if the tree contains one or\n        more asynchronous nodes.\n\n        Returns:\n            `NodeStatus`: The status ultimately returned by the root.\n        \"\"\"\n        status = self.root.execute_tick()\n        while status == NodeStatus.RUNNING:\n            status = self.root.execute_tick()\n        return status\n\n    def pretty_print(self) -&gt; None:\n        \"\"\"\n        Print an indented version of this tree to the command line. \n        Indentation shows structure.\n        \"\"\"\n        print(self.root.pretty_repr())\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.disable_logging","title":"<code>disable_logging()</code>","text":"<p>Turn logging off.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def disable_logging(self) -&gt; None:\n    \"\"\"\n    Turn logging off. \n    \"\"\"\n    if self.logger is not None:\n        for h in self.logger.handlers:\n            h.close()\n            self.logger.removeHandler(h)\n    self.logger = None\n    self.log_file_name = None\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.enable_logging","title":"<code>enable_logging()</code>","text":"<p>Turn on logging for every node in this tree. By default, each <code>tick()</code> call in every node results in a logging event.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def enable_logging(self) -&gt; None:\n    \"\"\"\n    Turn on logging for every node in this tree. By default,\n    each `tick()` call in every node results in a logging event.\n    \"\"\"\n    if self.logger is None:\n        self.logger = logging.getLogger(self.tree_name)\n        self.logger.setLevel(logging.DEBUG)\n        handler = logging.StreamHandler()\n        handler.setLevel(logging.DEBUG)\n        formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n        handler.setFormatter(formatter)\n        self.logger.addHandler(handler)\n        self.root.set_logger(self.logger)\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.get_node_by_name","title":"<code>get_node_by_name(name)</code>","text":"<p>Search for a node by its name. Forwards the call to the current root node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The name of the node we are looking for.</p> required <p>Returns:</p> Type Description <code>Optional[TreeNode]</code> <p><code>Optional[TreeNode]</code>: Either a node with the given name,</p> <code>Optional[TreeNode]</code> <p>or None.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n    \"\"\"\n    Search for a node by its name. Forwards the call to the current\n    root node.\n\n    Args:\n        name (`str`):\n            The name of the node we are looking for.\n\n    Returns:\n        `Optional[TreeNode]`: Either a node with the given name,\n        or None.\n    \"\"\"\n    if self.root:\n        return self.root.get_node_by_name(name)\n    else:\n        return None\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.halt_tree","title":"<code>halt_tree()</code>","text":"<p>Instruct the root of the tree to <code>halt()</code>.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def halt_tree(self) -&gt; None:\n    \"\"\"\n    Instruct the root of the tree to `halt()`.\n    \"\"\"\n    self.root.halt_node()\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.pretty_print","title":"<code>pretty_print()</code>","text":"<p>Print an indented version of this tree to the command line.  Indentation shows structure.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def pretty_print(self) -&gt; None:\n    \"\"\"\n    Print an indented version of this tree to the command line. \n    Indentation shows structure.\n    \"\"\"\n    print(self.root.pretty_repr())\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.reset","title":"<code>reset()</code>","text":"<p>Instruct the root of the tree to <code>reset()</code>.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Instruct the root of the tree to `reset()`.\n    \"\"\"\n    self.root.reset()\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.set_log_filename","title":"<code>set_log_filename(filename)</code>","text":"<p>If we want to log to a file instead of the command line, we use this method to set a a file name. </p> <p>Alternatively, if we are logging to a file and want to log to a stream instead, we can call this method with the filename set to <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>`Optional[str]`</code> <p>If <code>None</code>, log to a stream. If a <code>filename</code>, log to a file with that name.</p> required Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def set_log_filename(self, filename : Optional[str]) -&gt; None:\n    \"\"\"\n    If we want to log to a file instead of the command line, we use\n    this method to set a a file name. \n\n    Alternatively, if we are logging to a file and want to log to a\n    stream instead, we can call this method with the filename set to\n    `None`.\n\n    Args:\n        filename (`Optional[str]`):\n            If `None`, log to a stream. If a `filename`, log to a file\n            with that name.\n    \"\"\"\n    if self.logger is not None:\n        for h in self.logger.handlers:\n            h.close()\n            self.logger.removeHandler(h)\n\n        log_level = self.logger.level\n        f = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")            \n\n        if filename is None:\n            handler = logging.StreamHandler()\n            handler.setLevel(log_level)\n            handler.setFormatter(f)\n            self.logger.addHandler(handler)\n        else:\n            handler = logging.FileHandler(filename)\n            handler.setLevel(log_level)\n            handler.setFormatter(f)\n            self.logger.addHandler(handler)                \n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.set_log_level","title":"<code>set_log_level(log_level)</code>","text":"<p>Set the log level for the tree. This is a no-op if logging is not enabled.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def set_log_level(self, log_level) -&gt; None:\n    \"\"\"\n    Set the log level for the tree. This is a no-op if logging\n    is not enabled.\n    \"\"\"\n    level_to_set = None\n    if type(log_level) == str:\n        lvl = log_level.upper()\n        match lvl:\n            case \"DEBUG\":\n                level_to_set = logging.DEBUG\n            case \"INFO\":\n                level_to_set = logging.INFO\n            case \"WARNING\":\n                level_to_set = logging.WARNING\n            case \"ERROR\":\n                level_to_set = logging.ERROR\n            case \"CRITICAL\":\n                level_to_set = logging.CRITICAL\n    elif type(log_level) == int:\n        level_to_set = log_level\n    else:\n        raise TypeError(\"log_level must be either int or str\")\n\n    if self.logger is not None:\n        self.logger.setLevel(level_to_set)\n        for h in self.logger.handlers:\n            h.setLevel(level_to_set)\n        self.root.set_log_level(level_to_set)\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.set_root","title":"<code>set_root(new_root)</code>","text":"<p>Set the root of the tree to a new node.</p> <p>Parameters:</p> Name Type Description Default <code>new_root</code> <code>`dendron.tree_node.TreeNode`</code> <p>The new root node.</p> required Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def set_root(self, new_root : TreeNode) -&gt; None:\n    \"\"\"\n    Set the root of the tree to a new node.\n\n    Args:\n        new_root (`dendron.tree_node.TreeNode`):\n            The new root node.\n    \"\"\"\n    self.root = new_root\n    new_root.set_tree(self)\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.status","title":"<code>status()</code>","text":"<p>Return the current status of this tree. The status of a tree is the current status of the root node of hte tree.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>NodeStatus</code>: The status of the tree's root.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def status(self) -&gt; NodeStatus:\n    \"\"\"\n    Return the current status of this tree. The status of a tree\n    is the current status of the root node of hte tree.\n\n    Returns:\n        `NodeStatus`: The status of the tree's root.\n    \"\"\"\n    return self.root.get_status()\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.tick_once","title":"<code>tick_once()</code>","text":"<p>Instruct the root of the tree to execute its <code>tick()</code> function.</p> <p>This is the primary interface to run a <code>BehaviorTree</code>.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>NodeStatus</code>: The status returned by the root.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def tick_once(self) -&gt; NodeStatus:\n    \"\"\"\n    Instruct the root of the tree to execute its `tick()` function.\n\n    This is the primary interface to run a `BehaviorTree`.\n\n    Returns:\n        `NodeStatus`: The status returned by the root.\n    \"\"\"\n    return self.root.execute_tick()\n</code></pre>"},{"location":"api/behavior_tree/#dendron.behavior_tree.BehaviorTree.tick_while_running","title":"<code>tick_while_running()</code>","text":"<p>Repeatedly <code>tick()</code> the behavior tree as long as the status returned by the root is <code>RUNNING</code>. </p> <p>At present, this is only possible if the tree contains one or more asynchronous nodes.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>NodeStatus</code>: The status ultimately returned by the root.</p> Source code in <code>src/dendron/behavior_tree.py</code> <pre><code>def tick_while_running(self) -&gt; NodeStatus:\n    \"\"\"\n    Repeatedly `tick()` the behavior tree as long as the status\n    returned by the root is `RUNNING`. \n\n    At present, this is only possible if the tree contains one or\n    more asynchronous nodes.\n\n    Returns:\n        `NodeStatus`: The status ultimately returned by the root.\n    \"\"\"\n    status = self.root.execute_tick()\n    while status == NodeStatus.RUNNING:\n        status = self.root.execute_tick()\n    return status\n</code></pre>"},{"location":"api/behavior_tree_factory/","title":"BehaviorTreeFactory","text":""},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory","title":"<code>dendron.behavior_tree_factory.BehaviorTreeFactory</code>","text":"<p>A factory for behavior trees. This allows the registration of new node types and the generation of <code>BehaviorTree</code>s from XML files.</p> <p>A factory maintains state that allows node repetition and subtree  insertion to be automatically handled.</p> Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>class BehaviorTreeFactory:\n    \"\"\"\n    A factory for behavior trees. This allows the registration of new\n    node types and the generation of `BehaviorTree`s from XML files.\n\n    A factory maintains state that allows node repetition and subtree \n    insertion to be automatically handled.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self.registry = {}\n        self.node_counts = {}\n        self.node_types = {}\n        self.functors = {}\n        self.neural_configs = {}\n\n        self.registry[\"Fallback\"] = Fallback\n        self.registry[\"Sequence\"] = Sequence\n        self.registry[\"Inverter\"] = Inverter\n        self.registry[\"AlwaysSuccess\"] = AlwaysSuccess\n        self.registry[\"AlwaysFailure\"] = AlwaysFailure\n        self.registry[\"AsyncAction\"] = AsyncAction\n        self.registry[\"CausalLMAction\"] = CausalLMAction\n        self.registry[\"ImageLMAction\"] = ImageLMAction\n        self.registry[\"PipelineAction\"] = PipelineAction\n\n        # We replace SubTree nodes with the subtree root, so \n        # we use None as a placeholder here. \n        self.registry[\"SubTree\"] = None \n\n        self.node_counts[\"Fallback\"] = 0\n        self.node_counts[\"Sequence\"] = 0\n        self.node_counts[\"Inverter\"] = 0\n        self.node_counts[\"AlwaysSuccess\"] = 0\n        self.node_counts[\"AlwaysFailure\"] = 0\n        self.node_counts[\"AsyncAction\"] = 0\n        self.node_counts[\"CausalLMAction\"] = 0\n        self.node_counts[\"ImageLMAction\"] = 0\n        self.node_counts[\"PipelineAction\"] = 0\n\n        self.node_types[\"Fallback\"] = NodeType.CONTROL\n        self.node_types[\"Sequence\"] = NodeType.CONTROL\n        self.node_types[\"Inverter\"] = NodeType.DECORATOR\n        self.node_types[\"AlwaysSuccess\"] = NodeType.ACTION\n        self.node_types[\"AlwaysFailure\"] = NodeType.ACTION\n        self.node_types[\"AsyncAction\"] = NodeType.ACTION\n        self.node_types[\"CausalLMAction\"] = NodeType.ACTION\n        self.node_types[\"ImageLMAction\"] = NodeType.ACTION\n        self.node_types[\"PipelineAction\"] = NodeType.ACTION\n\n        self.node_types[\"SubTree\"] = NodeType.SUBTREE\n\n        self.current_blackboard = None\n        self.tree_nodes_model = None\n        self.behavior_trees = {}\n\n    def register_neural_config(self, name, cfg) -&gt; None:\n        \"\"\"\n        Register a configuration object for a neural network\n        based node.\n\n        Args:\n            name (str):\n                The name of the configuration object. This should match\n                the name used in Groot.\n            cfg:\n                The configuration object. At present, one of `CausalLMActionConfig`,\n                `ImageLMActionConfig`, `PipelineActionConfig`, or `CompletionConditionConfig`.\n        \"\"\"\n        self.neural_configs[name] = cfg\n\n    def register_action_type(self, name, action) -&gt; None:\n        \"\"\"\n        Register a new type of action node.\n\n        Args:\n            name (str):\n                The name of the new action node type.\n            action:\n                The constructor (class name) of the new node type.\n        \"\"\"\n        self.registry[name] = action \n        self.node_counts[name] = 0\n        self.node_types[name] = NodeType.ACTION\n\n    def register_condition_type(self, name, condition) -&gt; None:\n        \"\"\"\n        Register a new type of condition node.\n\n        Args:\n            name (str):\n                The name of the new condition type.\n            condition:\n                The constructor (class name) of the new node type.\n        \"\"\"\n        self.registry[name] = condition\n        self.node_counts[name] = 0\n        self.node_types[name] = NodeType.CONDITION\n\n    def register_decorator_type(self, name, decorator) -&gt; None:\n        \"\"\"\n        Register a new type of decorator node.\n\n        Args:\n            name (str):\n                The name of the new decorator type.\n            decorator:\n                The constructor (class name) of the new node type.\n        \"\"\"\n        self.registry[name] = decorator\n        self.node_counts[name] = 0\n        self.node_types[name] = NodeType.DECORATOR\n\n    def register_simple_action(self, name, action_function) -&gt; None:\n        \"\"\"\n        Register a new simple action. Allows the specification of an\n        action and a callback in one step.\n\n        Args:\n            name (str):\n                The name of the new simple action node type.\n            action_function (Callable):\n                A callback to execute each time this node is ticked.\n        \"\"\"\n        self.registry[name] = SimpleAction\n        self.functors[name] = action_function\n        self.node_counts[name] = 0\n        self.node_types[name] = NodeType.ACTION\n\n    def register_simple_condition(self, name, condition_function) -&gt; None:\n        \"\"\"\n        Register a new simple condition. Allows the specification of\n        a condition and a callback in one step.\n\n        Args:\n            name (str):\n                The name of the simple condition node type.\n            condition_function (Callable):\n                A callback to execute each time this node is ticked.\n        \"\"\"\n        self.registry[name] = SimpleCondition\n        self.functors[name] = condition_function\n        self.node_counts[name] = 0\n        self.node_types[name] = NodeType.CONDITION\n\n    def create_from_groot(self, xml_filename : str) -&gt; BehaviorTree:\n        \"\"\"\n        Create a `BehaviorTree` instance from an XML file generated by the \n        open-source Groot2 program.\n\n        Args:\n            xml_filename (`str`):\n                The name of the file containing the XML.\n\n        Returns:\n            `BehaviorTree`: A behavior tree that instantiates the structure \n            described in the XML file.\n        \"\"\"\n        self.current_blackboard = Blackboard()\n\n        xml_tree = ET.parse(xml_filename)\n        xml_root = xml_tree.getroot()\n\n        if not \"BTCPP_format\" in xml_root.attrib:\n            raise RuntimeError(\"XML missing BTCPP_format\")\n        if xml_root.attrib[\"BTCPP_format\"] != \"4\":\n            raise RuntimeError(\"BTCPP_format must be 4\")\n\n        has_main_tree = \"main_tree_to_execute\" in xml_root.attrib\n        main_tree_name = None\n        if has_main_tree:\n            main_tree_name = xml_root.attrib[\"main_tree_to_execute\"]\n\n        tree_nodes_xml = None\n        behavior_tree_xml = []\n        main_tree = None\n        for child in xml_root:\n            if child.tag == \"TreeNodesModel\":\n                tree_nodes_xml = child\n            elif child.tag == \"BehaviorTree\":\n                if \"ID\" in child.attrib and child.attrib[\"ID\"] == main_tree_name:\n                    main_tree = child\n                else:\n                    behavior_tree_xml.append(child)\n\n        # load TreeNodesModel\n        for child in tree_nodes_xml:\n            match child.tag:\n                case \"Action\":\n                    self.node_types[child.attrib[\"ID\"]] = NodeType.ACTION\n                case \"Condition\":\n                    self.node_types[child.attrib[\"ID\"]] = NodeType.CONDITION\n                case \"Control\":\n                    self.node_types[child.attrib[\"ID\"]] = NodeType.CONTROL\n                case \"Decorator\":\n                    self.node_types[child.attrib[\"ID\"]] = NodeType.DECORATOR\n\n        if not has_main_tree and len(behavior_tree_xml) &gt; 1:\n            raise RuntimeError(\"Multiple behavior trees but no main tree.\")\n\n        if main_tree is None and len(behavior_tree_xml) == 1:\n            main_tree = behavior_tree_xml[0]\n\n        # load each behavior tree\n        ## convert the other trees\n        parse_order = get_parse_order(xml_root)\n        for tree_name in parse_order:\n            if tree_name == main_tree_name:\n                continue\n            tree = None\n            for child in xml_root:\n                if child.tag != \"BehaviorTree\":\n                    continue\n                child_name = child.attrib[\"ID\"]\n                if child_name != tree_name:\n                    continue\n                else:\n                    tree = self.parse_behavior_tree_groot(child_name, child)\n                    self.behavior_trees[tree_name] = tree\n\n        # parse the main tree last\n        main_tree = self.parse_behavior_tree_groot(main_tree.attrib[\"ID\"], main_tree)\n        self.behavior_trees[main_tree_name] = main_tree\n\n        return main_tree\n\n    def parse_behavior_tree_groot(self, tree_name, xml_node) -&gt; BehaviorTree:\n        tree_type = self.node_types[xml_node[0].tag]\n        root_node = None\n        match tree_type:\n            case NodeType.ACTION:\n                root_node = self.parse_action_node_groot(xml_node[0])\n            case NodeType.CONDITION:\n                root_node = self.parse_condition_node_groot(xml_node[0])\n            case NodeType.CONTROL:\n                root_node = self.parse_control_node_groot(xml_node[0])\n            case NodeType.DECORATOR:\n                root_node = self.parse_decorator_node_groot(xml_node[0])\n            case NodeType.SUBTREE:\n                root_node = self.parse_subtree_node_groot(xml_node[0])\n\n        bt = BehaviorTree(tree_name, root_node)\n        return bt\n\n    def parse_action_node_groot(self, xml_node) -&gt; ActionNode:\n        tag = xml_node.tag\n        if not tag in self.registry:\n            raise KeyError(f\"Undefined action {tag}.\")\n\n        node_id = self.node_counts[tag]\n        node_name = tag + \"_\" + str(node_id)\n\n        if self.registry[tag] == SimpleAction:\n            f = self.functors[tag]\n            new_node = self.registry[tag](node_name, f)\n        else:\n            new_node = self.registry[tag](node_name)\n\n        self.node_counts[tag] += 1\n\n        if xml_node.attrib:\n            for key in xml_node.attrib:\n                self.current_blackboard[key] = xml_node.attrib[key]\n\n        return new_node\n\n    def parse_condition_node_groot(self, xml_node) -&gt; ConditionNode:\n        tag = xml_node.tag\n        if not tag in self.registry:\n            raise KeyError(f\"Undefined condition {tag}.\")\n\n        node_id = self.node_counts[tag]\n        node_name = tag + \"_\" + str(node_id)\n\n        if self.registry[tag] == SimpleCondition:\n            f = self.functors[tag]\n            new_node = self.registry[tag](node_name, f)\n        else:\n            new_node = self.registry[tag](node_name)\n\n        self.node_counts[tag] += 1\n\n        if xml_node.attrib:\n            for key in xml_node.attrib:\n                self.current_blackboard[key] = xml_node.attrib[key]\n\n        return new_node\n\n    def parse_control_node_groot(self, xml_node) -&gt; ControlNode:\n        tag = xml_node.tag\n        if not tag in self.registry:\n            raise KeyError(f\"Undefined control {tag}.\")\n\n        node_id = self.node_counts[tag]\n        node_name = tag + \"_\" + str(node_id)\n\n        self.node_counts[tag] += 1\n\n        if xml_node.attrib:\n            for key in xml_node.attrib:\n                self.current_blackboard[key] = xml_node.attrib[key]\n\n        # parse children\n        child_nodes = []\n        for child_xml in xml_node:\n            if not child_xml.tag in self.registry:\n                raise RuntimeError(f\"Unregistered node {child_xml.tag}\")\n\n            match self.node_types[child_xml.tag]:\n                case NodeType.ACTION:\n                    child_node = self.parse_action_node_groot(child_xml)\n                case NodeType.CONDITION:\n                    child_node = self.parse_condition_node_groot(child_xml)\n                case NodeType.CONTROL:\n                    child_node = self.parse_control_node_groot(child_xml)\n                case NodeType.DECORATOR:\n                    child_node = self.parse_decorator_node_groot(child_xml)\n                case NodeType.SUBTREE:\n                    child_node = self.parse_subtree_node_groot(child_xml)\n\n            child_nodes.append(child_node)\n\n        new_node = self.registry[tag](node_name, child_nodes)\n\n        return new_node\n\n    def parse_decorator_node_groot(self, xml_node) -&gt; DecoratorNode:\n        tag = xml_node.tag\n        if not tag in self.registry:\n            raise KeyError(f\"Undefined decorator {tag}.\")\n\n        node_id = self.node_counts[tag]\n        node_name = tag + \"_\" + str(node_id)\n\n        self.node_counts[tag] += 1\n\n        if xml_node.attrib:\n            for key in xml_node.attrib:\n                self.current_blackboard[key] = xml_node.attrib[key]\n\n        child_node = None\n        child_xml = xml_node[0]\n        match self.node_types[child_xml.tag]:\n            case NodeType.ACTION:\n                child_node = self.parse_action_node_groot(child_xml)\n            case NodeType.CONDITION:\n                child_node = self.parse_condition_node_groot(child_xml)\n            case NodeType.CONTROL:\n                child_node = self.parse_control_node_groot(child_xml)\n            case NodeType.DECORATOR:\n                child_node = self.parse_decorator_node_groot(child_xml)\n            case NodeType.SUBTREE:\n                child_node = self.parse_subtree_node_groot(child_xml)\n\n        new_node = self.registry[tag](node_name, child_node)\n        return new_node\n\n    def parse_subtree_node_groot(self, xml_node) -&gt; TreeNode:\n        subtree_name = xml_node.attrib[\"ID\"]\n\n        # TODO is deepcopy good enough?\n        return deepcopy(self.behavior_trees[subtree_name].root)\n</code></pre>"},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory.register_neural_config","title":"<code>register_neural_config(name, cfg)</code>","text":"<p>Register a configuration object for a neural network based node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the configuration object. This should match the name used in Groot.</p> required <code>cfg</code> <p>The configuration object. At present, one of <code>CausalLMActionConfig</code>, <code>ImageLMActionConfig</code>, <code>PipelineActionConfig</code>, or <code>CompletionConditionConfig</code>.</p> required Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>def register_neural_config(self, name, cfg) -&gt; None:\n    \"\"\"\n    Register a configuration object for a neural network\n    based node.\n\n    Args:\n        name (str):\n            The name of the configuration object. This should match\n            the name used in Groot.\n        cfg:\n            The configuration object. At present, one of `CausalLMActionConfig`,\n            `ImageLMActionConfig`, `PipelineActionConfig`, or `CompletionConditionConfig`.\n    \"\"\"\n    self.neural_configs[name] = cfg\n</code></pre>"},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory.register_action_type","title":"<code>register_action_type(name, action)</code>","text":"<p>Register a new type of action node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new action node type.</p> required <code>action</code> <p>The constructor (class name) of the new node type.</p> required Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>def register_action_type(self, name, action) -&gt; None:\n    \"\"\"\n    Register a new type of action node.\n\n    Args:\n        name (str):\n            The name of the new action node type.\n        action:\n            The constructor (class name) of the new node type.\n    \"\"\"\n    self.registry[name] = action \n    self.node_counts[name] = 0\n    self.node_types[name] = NodeType.ACTION\n</code></pre>"},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory.register_condition_type","title":"<code>register_condition_type(name, condition)</code>","text":"<p>Register a new type of condition node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new condition type.</p> required <code>condition</code> <p>The constructor (class name) of the new node type.</p> required Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>def register_condition_type(self, name, condition) -&gt; None:\n    \"\"\"\n    Register a new type of condition node.\n\n    Args:\n        name (str):\n            The name of the new condition type.\n        condition:\n            The constructor (class name) of the new node type.\n    \"\"\"\n    self.registry[name] = condition\n    self.node_counts[name] = 0\n    self.node_types[name] = NodeType.CONDITION\n</code></pre>"},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory.register_decorator_type","title":"<code>register_decorator_type(name, decorator)</code>","text":"<p>Register a new type of decorator node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new decorator type.</p> required <code>decorator</code> <p>The constructor (class name) of the new node type.</p> required Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>def register_decorator_type(self, name, decorator) -&gt; None:\n    \"\"\"\n    Register a new type of decorator node.\n\n    Args:\n        name (str):\n            The name of the new decorator type.\n        decorator:\n            The constructor (class name) of the new node type.\n    \"\"\"\n    self.registry[name] = decorator\n    self.node_counts[name] = 0\n    self.node_types[name] = NodeType.DECORATOR\n</code></pre>"},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory.register_simple_action","title":"<code>register_simple_action(name, action_function)</code>","text":"<p>Register a new simple action. Allows the specification of an action and a callback in one step.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new simple action node type.</p> required <code>action_function</code> <code>Callable</code> <p>A callback to execute each time this node is ticked.</p> required Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>def register_simple_action(self, name, action_function) -&gt; None:\n    \"\"\"\n    Register a new simple action. Allows the specification of an\n    action and a callback in one step.\n\n    Args:\n        name (str):\n            The name of the new simple action node type.\n        action_function (Callable):\n            A callback to execute each time this node is ticked.\n    \"\"\"\n    self.registry[name] = SimpleAction\n    self.functors[name] = action_function\n    self.node_counts[name] = 0\n    self.node_types[name] = NodeType.ACTION\n</code></pre>"},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory.register_simple_condition","title":"<code>register_simple_condition(name, condition_function)</code>","text":"<p>Register a new simple condition. Allows the specification of a condition and a callback in one step.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the simple condition node type.</p> required <code>condition_function</code> <code>Callable</code> <p>A callback to execute each time this node is ticked.</p> required Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>def register_simple_condition(self, name, condition_function) -&gt; None:\n    \"\"\"\n    Register a new simple condition. Allows the specification of\n    a condition and a callback in one step.\n\n    Args:\n        name (str):\n            The name of the simple condition node type.\n        condition_function (Callable):\n            A callback to execute each time this node is ticked.\n    \"\"\"\n    self.registry[name] = SimpleCondition\n    self.functors[name] = condition_function\n    self.node_counts[name] = 0\n    self.node_types[name] = NodeType.CONDITION\n</code></pre>"},{"location":"api/behavior_tree_factory/#dendron.behavior_tree_factory.BehaviorTreeFactory.create_from_groot","title":"<code>create_from_groot(xml_filename)</code>","text":"<p>Create a <code>BehaviorTree</code> instance from an XML file generated by the  open-source Groot2 program.</p> <p>Parameters:</p> Name Type Description Default <code>xml_filename</code> <code>`str`</code> <p>The name of the file containing the XML.</p> required <p>Returns:</p> Type Description <code>BehaviorTree</code> <p><code>BehaviorTree</code>: A behavior tree that instantiates the structure </p> <code>BehaviorTree</code> <p>described in the XML file.</p> Source code in <code>src/dendron/behavior_tree_factory.py</code> <pre><code>def create_from_groot(self, xml_filename : str) -&gt; BehaviorTree:\n    \"\"\"\n    Create a `BehaviorTree` instance from an XML file generated by the \n    open-source Groot2 program.\n\n    Args:\n        xml_filename (`str`):\n            The name of the file containing the XML.\n\n    Returns:\n        `BehaviorTree`: A behavior tree that instantiates the structure \n        described in the XML file.\n    \"\"\"\n    self.current_blackboard = Blackboard()\n\n    xml_tree = ET.parse(xml_filename)\n    xml_root = xml_tree.getroot()\n\n    if not \"BTCPP_format\" in xml_root.attrib:\n        raise RuntimeError(\"XML missing BTCPP_format\")\n    if xml_root.attrib[\"BTCPP_format\"] != \"4\":\n        raise RuntimeError(\"BTCPP_format must be 4\")\n\n    has_main_tree = \"main_tree_to_execute\" in xml_root.attrib\n    main_tree_name = None\n    if has_main_tree:\n        main_tree_name = xml_root.attrib[\"main_tree_to_execute\"]\n\n    tree_nodes_xml = None\n    behavior_tree_xml = []\n    main_tree = None\n    for child in xml_root:\n        if child.tag == \"TreeNodesModel\":\n            tree_nodes_xml = child\n        elif child.tag == \"BehaviorTree\":\n            if \"ID\" in child.attrib and child.attrib[\"ID\"] == main_tree_name:\n                main_tree = child\n            else:\n                behavior_tree_xml.append(child)\n\n    # load TreeNodesModel\n    for child in tree_nodes_xml:\n        match child.tag:\n            case \"Action\":\n                self.node_types[child.attrib[\"ID\"]] = NodeType.ACTION\n            case \"Condition\":\n                self.node_types[child.attrib[\"ID\"]] = NodeType.CONDITION\n            case \"Control\":\n                self.node_types[child.attrib[\"ID\"]] = NodeType.CONTROL\n            case \"Decorator\":\n                self.node_types[child.attrib[\"ID\"]] = NodeType.DECORATOR\n\n    if not has_main_tree and len(behavior_tree_xml) &gt; 1:\n        raise RuntimeError(\"Multiple behavior trees but no main tree.\")\n\n    if main_tree is None and len(behavior_tree_xml) == 1:\n        main_tree = behavior_tree_xml[0]\n\n    # load each behavior tree\n    ## convert the other trees\n    parse_order = get_parse_order(xml_root)\n    for tree_name in parse_order:\n        if tree_name == main_tree_name:\n            continue\n        tree = None\n        for child in xml_root:\n            if child.tag != \"BehaviorTree\":\n                continue\n            child_name = child.attrib[\"ID\"]\n            if child_name != tree_name:\n                continue\n            else:\n                tree = self.parse_behavior_tree_groot(child_name, child)\n                self.behavior_trees[tree_name] = tree\n\n    # parse the main tree last\n    main_tree = self.parse_behavior_tree_groot(main_tree.attrib[\"ID\"], main_tree)\n    self.behavior_trees[main_tree_name] = main_tree\n\n    return main_tree\n</code></pre>"},{"location":"api/blackboard/","title":"Blackboard","text":""},{"location":"api/blackboard/#dendron.blackboard.Blackboard","title":"<code>dendron.blackboard.Blackboard</code>","text":"<p>A blackboard for a Behavior Tree. Implements a key-value mapping that is accessible by all of the nodes in a behavior tree.</p> Source code in <code>src/dendron/blackboard.py</code> <pre><code>class Blackboard:\n    \"\"\"\n    A blackboard for a Behavior Tree. Implements a key-value mapping\n    that is accessible by all of the nodes in a behavior tree.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self.entry_mapping = {}\n        self.value_mapping = {}\n        self.print_len = 16\n\n    def set_print_len(self, new_len : int) -&gt; None:\n        \"\"\"\n        Set the width of the columns for printing this blackboard.\n\n        Args:\n            new_len (`int`):\n                The new column width for printing.\n        \"\"\"\n        if new_len &lt;= 0:\n            raise ValueError(\"print length must be positive\")\n        self.print_len = new_len\n        for key, entry in self.entry_mapping.items():\n            entry.print_len = new_len \n\n    def register_entry(self, entry : BlackboardEntryMetadata) -&gt; None:\n        \"\"\"\n        Register a new metadata entry for this blackboard. Primarily\n        useful for specfying a type constructor to use with values that\n        go with a certain key.\n\n        Args:\n            entry (`dendron.blackboard.BlackboardEntryMetadata`):\n                The entry to register.\n        \"\"\"\n        self.entry_mapping[entry.key] = entry\n\n    def get_entry(self, key : Any) -&gt; Any:\n        \"\"\"\n        Return the value associated with the given key.\n\n        Args:\n            key (`Any`):\n                Key to query on. Usually a `str`.\n        \"\"\"\n        return self.entry_mapping[key]\n\n    def set_entry(self, key : Any, description : Optional[str] = None, type_constructor : Optional[Type] = None) -&gt; None:\n        \"\"\"\n        Set the metadata for a particular key in anticipation of future \n        values. \n\n        Args:\n            key (`Any`):\n                Key to query on. Usually a `str`.\n            description (`Optional[str`]):\n                An optional human-readable description of the key-value pair.\n            type_constructor (`Type`):\n                An optional type constructor to convert data upon reading.\n        \"\"\"\n        if not key in self.entry_mapping.keys():\n            raise KeyError(f\"{new_entry.key} not in blackboard.\")\n        old_entry = self.entry_mapping[key]\n        new_entry = deepcopy(old_entry)\n        if description is not None:\n            new_entry.description = description\n        if type_constructor is not None:\n            new_entry.type_constructor = type_constructor\n        self.entry_mapping[key] = new_entry\n\n    def __getitem__(self, key : Any) -&gt; Any:\n        \"\"\"\n        Get the value associated with the given key.\n\n        Args:\n            key (`Any`):\n                The key we want the value for.\n\n        Returns:\n            `Any` : The value in the blackboard corresponding to `key`.\n        \"\"\"\n        if not key in self.entry_mapping.keys():\n            raise KeyError(f\"Entry {key} not in blackboard.\")\n        target_type = self.entry_mapping[key].type_constructor\n        temp_value = self.value_mapping[key]\n        if type(temp_value) != target_type:\n            return target_type(temp_value)\n        else:\n            return self.value_mapping[key]\n\n    def get(self, key : Any) -&gt; Any:\n        \"\"\"\n        Get the value associated with the given key.\n\n        Args:\n            key (`Any`):\n                The key we want the value for.\n\n        Returns:\n            `Any` : The value in the blackboard corresponding to `key`.\n        \"\"\"\n        return self.__getitem__(key)\n\n    def __delitem__(self, key : Any) -&gt; None:\n        \"\"\"\n        Delete an entry from the blackboard.\n\n        Args:\n            key (`Any`):\n                The key we want to remove from the blackboard. \n        \"\"\"\n        del self.value_mapping[key]\n        del self.entry_mapping[key]\n\n    def __setitem__(self, key : Any, value : Any) -&gt; None:\n        \"\"\"\n        Add a key-value pair to the blackboard. If `key` is not already\n        in the \n\n        Args:\n            key (`Any`):\n                Key to query on. Usually a `str`.\n            value (`Any`):\n                The value that `key` maps to.\n        \"\"\"\n        if key not in self.entry_mapping.keys():\n            new_entry = BlackboardEntryMetadata(key, \"Autogenerated entry\", type(value))\n            self.register_entry(new_entry)\n        self.value_mapping[key] = value \n\n    def set(self, key : Any, value : Any) -&gt; None:\n        \"\"\"\n        Add a key-value pair to the blackboard. Wrapper around \n        __setitem__.\n        \"\"\"\n        self.__setitem__(key, value)\n\n    def __iter__(self) -&gt; Iterator:\n        \"\"\"\n        Get an iterator over key-value pairs.\n\n        Returns:\n            `Iterator`: The iterator over the value dict.\n        \"\"\"\n        return iter(self.value_mapping)\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Get the number of key-value pairs in the blackboard.\n\n        Returns:\n            `int`: The number of key-value pairs.\n        \"\"\"\n        return len(self.value_mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Get a tabular representation of this blackboard in a `str`.\n\n        Returns:\n            `str`: A string that prints as a table of keys and values.\n        \"\"\"\n        key_header_field = f\"{'Key':{self.print_len}.{self.print_len}}\"\n        desc_header_field = f\"{'Description':{self.print_len}.{self.print_len}}\"\n        type_header_field = f\"{'Type':{self.print_len}.{self.print_len}}\"\n        value_header_field = f\"{'Value':{self.print_len}.{self.print_len}}\"\n        bb_str = f\"{key_header_field} | {desc_header_field} | {type_header_field} | {value_header_field} |\\n\"\n        bb_str += f\"{'=' * (self.print_len * 4 + 11)}\\n\"\n        for key, value in self.value_mapping.items():\n            entry = self.entry_mapping[key]\n            value_string = str(value)\n            value_field = f\"{value_string:{self.print_len}.{self.print_len}}\"\n            bb_str += f\"{str(entry)} | {value_field} | \\n\"\n\n        return bb_str \n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.__delitem__","title":"<code>__delitem__(key)</code>","text":"<p>Delete an entry from the blackboard.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>`Any`</code> <p>The key we want to remove from the blackboard.</p> required Source code in <code>src/dendron/blackboard.py</code> <pre><code>def __delitem__(self, key : Any) -&gt; None:\n    \"\"\"\n    Delete an entry from the blackboard.\n\n    Args:\n        key (`Any`):\n            The key we want to remove from the blackboard. \n    \"\"\"\n    del self.value_mapping[key]\n    del self.entry_mapping[key]\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the value associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>`Any`</code> <p>The key we want the value for.</p> required <p>Returns:</p> Type Description <code>Any</code> <p><code>Any</code> : The value in the blackboard corresponding to <code>key</code>.</p> Source code in <code>src/dendron/blackboard.py</code> <pre><code>def __getitem__(self, key : Any) -&gt; Any:\n    \"\"\"\n    Get the value associated with the given key.\n\n    Args:\n        key (`Any`):\n            The key we want the value for.\n\n    Returns:\n        `Any` : The value in the blackboard corresponding to `key`.\n    \"\"\"\n    if not key in self.entry_mapping.keys():\n        raise KeyError(f\"Entry {key} not in blackboard.\")\n    target_type = self.entry_mapping[key].type_constructor\n    temp_value = self.value_mapping[key]\n    if type(temp_value) != target_type:\n        return target_type(temp_value)\n    else:\n        return self.value_mapping[key]\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.__iter__","title":"<code>__iter__()</code>","text":"<p>Get an iterator over key-value pairs.</p> <p>Returns:</p> Type Description <code>Iterator</code> <p><code>Iterator</code>: The iterator over the value dict.</p> Source code in <code>src/dendron/blackboard.py</code> <pre><code>def __iter__(self) -&gt; Iterator:\n    \"\"\"\n    Get an iterator over key-value pairs.\n\n    Returns:\n        `Iterator`: The iterator over the value dict.\n    \"\"\"\n    return iter(self.value_mapping)\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.__len__","title":"<code>__len__()</code>","text":"<p>Get the number of key-value pairs in the blackboard.</p> <p>Returns:</p> Type Description <code>int</code> <p><code>int</code>: The number of key-value pairs.</p> Source code in <code>src/dendron/blackboard.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Get the number of key-value pairs in the blackboard.\n\n    Returns:\n        `int`: The number of key-value pairs.\n    \"\"\"\n    return len(self.value_mapping)\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Add a key-value pair to the blackboard. If <code>key</code> is not already in the </p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>`Any`</code> <p>Key to query on. Usually a <code>str</code>.</p> required <code>value</code> <code>`Any`</code> <p>The value that <code>key</code> maps to.</p> required Source code in <code>src/dendron/blackboard.py</code> <pre><code>def __setitem__(self, key : Any, value : Any) -&gt; None:\n    \"\"\"\n    Add a key-value pair to the blackboard. If `key` is not already\n    in the \n\n    Args:\n        key (`Any`):\n            Key to query on. Usually a `str`.\n        value (`Any`):\n            The value that `key` maps to.\n    \"\"\"\n    if key not in self.entry_mapping.keys():\n        new_entry = BlackboardEntryMetadata(key, \"Autogenerated entry\", type(value))\n        self.register_entry(new_entry)\n    self.value_mapping[key] = value \n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.__str__","title":"<code>__str__()</code>","text":"<p>Get a tabular representation of this blackboard in a <code>str</code>.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>str</code>: A string that prints as a table of keys and values.</p> Source code in <code>src/dendron/blackboard.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Get a tabular representation of this blackboard in a `str`.\n\n    Returns:\n        `str`: A string that prints as a table of keys and values.\n    \"\"\"\n    key_header_field = f\"{'Key':{self.print_len}.{self.print_len}}\"\n    desc_header_field = f\"{'Description':{self.print_len}.{self.print_len}}\"\n    type_header_field = f\"{'Type':{self.print_len}.{self.print_len}}\"\n    value_header_field = f\"{'Value':{self.print_len}.{self.print_len}}\"\n    bb_str = f\"{key_header_field} | {desc_header_field} | {type_header_field} | {value_header_field} |\\n\"\n    bb_str += f\"{'=' * (self.print_len * 4 + 11)}\\n\"\n    for key, value in self.value_mapping.items():\n        entry = self.entry_mapping[key]\n        value_string = str(value)\n        value_field = f\"{value_string:{self.print_len}.{self.print_len}}\"\n        bb_str += f\"{str(entry)} | {value_field} | \\n\"\n\n    return bb_str \n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.get","title":"<code>get(key)</code>","text":"<p>Get the value associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>`Any`</code> <p>The key we want the value for.</p> required <p>Returns:</p> Type Description <code>Any</code> <p><code>Any</code> : The value in the blackboard corresponding to <code>key</code>.</p> Source code in <code>src/dendron/blackboard.py</code> <pre><code>def get(self, key : Any) -&gt; Any:\n    \"\"\"\n    Get the value associated with the given key.\n\n    Args:\n        key (`Any`):\n            The key we want the value for.\n\n    Returns:\n        `Any` : The value in the blackboard corresponding to `key`.\n    \"\"\"\n    return self.__getitem__(key)\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.get_entry","title":"<code>get_entry(key)</code>","text":"<p>Return the value associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>`Any`</code> <p>Key to query on. Usually a <code>str</code>.</p> required Source code in <code>src/dendron/blackboard.py</code> <pre><code>def get_entry(self, key : Any) -&gt; Any:\n    \"\"\"\n    Return the value associated with the given key.\n\n    Args:\n        key (`Any`):\n            Key to query on. Usually a `str`.\n    \"\"\"\n    return self.entry_mapping[key]\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.register_entry","title":"<code>register_entry(entry)</code>","text":"<p>Register a new metadata entry for this blackboard. Primarily useful for specfying a type constructor to use with values that go with a certain key.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>`dendron.blackboard.BlackboardEntryMetadata`</code> <p>The entry to register.</p> required Source code in <code>src/dendron/blackboard.py</code> <pre><code>def register_entry(self, entry : BlackboardEntryMetadata) -&gt; None:\n    \"\"\"\n    Register a new metadata entry for this blackboard. Primarily\n    useful for specfying a type constructor to use with values that\n    go with a certain key.\n\n    Args:\n        entry (`dendron.blackboard.BlackboardEntryMetadata`):\n            The entry to register.\n    \"\"\"\n    self.entry_mapping[entry.key] = entry\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.set","title":"<code>set(key, value)</code>","text":"<p>Add a key-value pair to the blackboard. Wrapper around  setitem.</p> Source code in <code>src/dendron/blackboard.py</code> <pre><code>def set(self, key : Any, value : Any) -&gt; None:\n    \"\"\"\n    Add a key-value pair to the blackboard. Wrapper around \n    __setitem__.\n    \"\"\"\n    self.__setitem__(key, value)\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.set_entry","title":"<code>set_entry(key, description=None, type_constructor=None)</code>","text":"<p>Set the metadata for a particular key in anticipation of future  values. </p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>`Any`</code> <p>Key to query on. Usually a <code>str</code>.</p> required <code>description</code> <code>`Optional[str`]</code> <p>An optional human-readable description of the key-value pair.</p> <code>None</code> <code>type_constructor</code> <code>`Type`</code> <p>An optional type constructor to convert data upon reading.</p> <code>None</code> Source code in <code>src/dendron/blackboard.py</code> <pre><code>def set_entry(self, key : Any, description : Optional[str] = None, type_constructor : Optional[Type] = None) -&gt; None:\n    \"\"\"\n    Set the metadata for a particular key in anticipation of future \n    values. \n\n    Args:\n        key (`Any`):\n            Key to query on. Usually a `str`.\n        description (`Optional[str`]):\n            An optional human-readable description of the key-value pair.\n        type_constructor (`Type`):\n            An optional type constructor to convert data upon reading.\n    \"\"\"\n    if not key in self.entry_mapping.keys():\n        raise KeyError(f\"{new_entry.key} not in blackboard.\")\n    old_entry = self.entry_mapping[key]\n    new_entry = deepcopy(old_entry)\n    if description is not None:\n        new_entry.description = description\n    if type_constructor is not None:\n        new_entry.type_constructor = type_constructor\n    self.entry_mapping[key] = new_entry\n</code></pre>"},{"location":"api/blackboard/#dendron.blackboard.Blackboard.set_print_len","title":"<code>set_print_len(new_len)</code>","text":"<p>Set the width of the columns for printing this blackboard.</p> <p>Parameters:</p> Name Type Description Default <code>new_len</code> <code>`int`</code> <p>The new column width for printing.</p> required Source code in <code>src/dendron/blackboard.py</code> <pre><code>def set_print_len(self, new_len : int) -&gt; None:\n    \"\"\"\n    Set the width of the columns for printing this blackboard.\n\n    Args:\n        new_len (`int`):\n            The new column width for printing.\n    \"\"\"\n    if new_len &lt;= 0:\n        raise ValueError(\"print length must be positive\")\n    self.print_len = new_len\n    for key, entry in self.entry_mapping.items():\n        entry.print_len = new_len \n</code></pre>"},{"location":"api/condition_node/","title":"ConditionNode","text":""},{"location":"api/condition_node/#dendron.condition_node.ConditionNode","title":"<code>dendron.condition_node.ConditionNode</code>","text":"<p>             Bases: <code>TreeNode</code></p> <p>A condition node is a node that always must return either <code>SUCCESS</code>  or <code>FAILURE</code> - it can never be left in a <code>RUNNING</code> state. Such nodes are intended to model boolean conditions (hence the name). </p> <p><code>ConditionNode</code>s are one of the two kinds of leaf nodes in a Behavior Tree - the other being the <code>ActionNode</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required Source code in <code>src/dendron/condition_node.py</code> <pre><code>class ConditionNode(TreeNode):\n    \"\"\"\n    A condition node is a node that always *must* return either `SUCCESS` \n    or `FAILURE` - it can never be left in a `RUNNING` state. Such nodes\n    are intended to model boolean conditions (hence the name). \n\n    `ConditionNode`s are one of the two kinds of leaf nodes in a Behavior\n    Tree - the other being the `ActionNode`.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n    \"\"\"\n\n    def __init__(self, name) -&gt; None:\n        super().__init__(name)\n\n    def set_logger(self, new_logger) -&gt; None:\n        \"\"\"\n        Set the logger for this node.\n        \"\"\"\n        self.logger = new_logger\n\n    def set_log_level(self, new_level) -&gt; None:\n        \"\"\"\n        Set the log level for this node.\n        \"\"\"\n        self.log_level = new_level\n\n    def node_type(self) -&gt; NodeType:\n        \"\"\"\n        Get the type of this node.\n\n        Returns:\n            `NodeType`: The type (`CONDITION`).\n        \"\"\"\n        return NodeType.CONDITION\n\n    def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n        \"\"\"\n        Search for a node by its name.\n\n        Args:\n            name (`str`):\n                The name of the node we are looking for.\n\n        Returns:\n            `Optional[TreeNode]`: Either a node with the given name,\n            or None.\n        \"\"\"\n        if self.name == name:\n            return self\n        else:\n            return None\n\n    def pretty_repr(self, depth = 0) -&gt; str:\n        \"\"\"\n        Return a string representation of this node at the given depth.\n\n        Args:\n            depth (`int`):\n                The depth of this node in a surrounding tree.\n\n        Returns:\n            `str`: The indented string representation.\n        \"\"\"\n        tabs = '\\t'*depth\n        repr = f\"{tabs}Condition {self.name}\"\n        return repr\n</code></pre>"},{"location":"api/condition_node/#dendron.condition_node.ConditionNode.get_node_by_name","title":"<code>get_node_by_name(name)</code>","text":"<p>Search for a node by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The name of the node we are looking for.</p> required <p>Returns:</p> Type Description <code>Optional[TreeNode]</code> <p><code>Optional[TreeNode]</code>: Either a node with the given name,</p> <code>Optional[TreeNode]</code> <p>or None.</p> Source code in <code>src/dendron/condition_node.py</code> <pre><code>def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n    \"\"\"\n    Search for a node by its name.\n\n    Args:\n        name (`str`):\n            The name of the node we are looking for.\n\n    Returns:\n        `Optional[TreeNode]`: Either a node with the given name,\n        or None.\n    \"\"\"\n    if self.name == name:\n        return self\n    else:\n        return None\n</code></pre>"},{"location":"api/condition_node/#dendron.condition_node.ConditionNode.node_type","title":"<code>node_type()</code>","text":"<p>Get the type of this node.</p> <p>Returns:</p> Type Description <code>NodeType</code> <p><code>NodeType</code>: The type (<code>CONDITION</code>).</p> Source code in <code>src/dendron/condition_node.py</code> <pre><code>def node_type(self) -&gt; NodeType:\n    \"\"\"\n    Get the type of this node.\n\n    Returns:\n        `NodeType`: The type (`CONDITION`).\n    \"\"\"\n    return NodeType.CONDITION\n</code></pre>"},{"location":"api/condition_node/#dendron.condition_node.ConditionNode.pretty_repr","title":"<code>pretty_repr(depth=0)</code>","text":"<p>Return a string representation of this node at the given depth.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>`int`</code> <p>The depth of this node in a surrounding tree.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p><code>str</code>: The indented string representation.</p> Source code in <code>src/dendron/condition_node.py</code> <pre><code>def pretty_repr(self, depth = 0) -&gt; str:\n    \"\"\"\n    Return a string representation of this node at the given depth.\n\n    Args:\n        depth (`int`):\n            The depth of this node in a surrounding tree.\n\n    Returns:\n        `str`: The indented string representation.\n    \"\"\"\n    tabs = '\\t'*depth\n    repr = f\"{tabs}Condition {self.name}\"\n    return repr\n</code></pre>"},{"location":"api/condition_node/#dendron.condition_node.ConditionNode.set_log_level","title":"<code>set_log_level(new_level)</code>","text":"<p>Set the log level for this node.</p> Source code in <code>src/dendron/condition_node.py</code> <pre><code>def set_log_level(self, new_level) -&gt; None:\n    \"\"\"\n    Set the log level for this node.\n    \"\"\"\n    self.log_level = new_level\n</code></pre>"},{"location":"api/condition_node/#dendron.condition_node.ConditionNode.set_logger","title":"<code>set_logger(new_logger)</code>","text":"<p>Set the logger for this node.</p> Source code in <code>src/dendron/condition_node.py</code> <pre><code>def set_logger(self, new_logger) -&gt; None:\n    \"\"\"\n    Set the logger for this node.\n    \"\"\"\n    self.logger = new_logger\n</code></pre>"},{"location":"api/control_node/","title":"ControlNode","text":""},{"location":"api/control_node/#dendron.control_node.ControlNode","title":"<code>dendron.control_node.ControlNode</code>","text":"<p>             Bases: <code>TreeNode</code></p> <p>Base class for a control node.</p> <p>A control node maintains a list of children that it ticks under some conditions. The node tracks the state of its children as  they tick, and decides whether or not to continue based on its  internal logic.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this control node.</p> required <code>children</code> <code>`List[TreeNode]`</code> <p>An optional initial list of children.</p> <code>None</code> Source code in <code>src/dendron/control_node.py</code> <pre><code>class ControlNode(TreeNode):\n    \"\"\"\n    Base class for a control node.\n\n    A control node maintains a list of children that it ticks under\n    some conditions. The node tracks the state of its children as \n    they tick, and decides whether or not to continue based on its \n    internal logic.\n\n    Args:\n        name (`str`):\n            The given name of this control node.\n        children (`List[TreeNode]`):\n            An optional initial list of children.\n    \"\"\"\n\n    def __init__(self, name : str, children : List[TreeNode] = None) -&gt; None:\n        super().__init__(name)\n        self.children : List[TreeNode] = children \n\n    def set_tree(self, tree : BehaviorTree) -&gt; None:\n        \"\"\"\n        Set the tree of this node, and then have each of the children\n        set their tree similarly.\n\n        Args:\n            tree (`dendron.behavior_tree.BehaviorTree`):\n                The tree that will contain this node.\n        \"\"\"\n        self.tree = tree\n        for c in self.children:\n            c.set_tree(tree)\n\n    def set_logger(self, new_logger) -&gt; None:\n        \"\"\"\n        Set the logger for this node, and then forward the logger to the\n        children.\n\n        Args:\n            new_logger (`logging.Logger`):\n                The Logger to use.\n        \"\"\"\n        self.logger = new_logger\n        for c in self.children:\n            c.set_logger(new_logger)\n\n    def set_log_level(self, new_level) -&gt; None:\n        \"\"\"\n        Set the log level for this node, then forward that level for the\n        children to use.\n        \"\"\"\n        self.log_level = new_level\n        for c in self.children:\n            c.set_log_level(new_level)\n\n    def add_child(self, child : TreeNode) -&gt; None:\n        \"\"\"\n        Add a new child node to the end of the list.\n\n        Args:\n            child (`dendron.tree_node.TreeNode`):\n                The new child node.\n        \"\"\"\n        self.children.append(child)\n\n    def add_children(self, children : List[TreeNode]) -&gt; None:\n        \"\"\"\n        Add a list of children to the end of the list.\n\n        Args:\n            children (`List[TreeNode]`):\n                The list of `TreeNode`s to add. \n        \"\"\"\n        self.children.extend(children)\n\n    def set_blackboard(self, bb : Blackboard) -&gt; None:\n        \"\"\"\n        Set the blackboard for this node, and then forward to the\n        children.\n\n        Args:\n            bb (`dendron.blackboard.Blackboard`):\n                The new blackboard to use.\n        \"\"\"\n        self.blackboard = bb\n        for child in self.children:\n            child.set_blackboard(bb)\n\n    def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n        \"\"\"\n        Search for a node by its name.\n\n        Args:\n            name (`str`):\n                The name of the node we are looking for.\n\n        Returns:\n            `Optional[TreeNode]`: Either a node with the given name,\n            or None.\n        \"\"\"\n        if self.name == name:\n            return self\n        else:\n            for child in self.children:\n                node = child.get_node_by_name(name)\n                if node != None:\n                    return node\n            return None\n\n    def children_count(self) -&gt; int:\n        \"\"\"\n        Get the current number of children.\n\n        Returns:\n            `int`: The length of the children list.\n        \"\"\"\n        return len(self.children)\n\n    def children(self) -&gt; List[TreeNode]:\n        \"\"\"\n        Get the list of children.\n\n        Returns:\n            `List[TreeNode]`: The `self.children` list.\n        \"\"\"\n        return self.children\n\n    def child(self, index : int) -&gt; TreeNode:\n        \"\"\"\n        Get the child that is at position `index` in the list. Does\n        not perform bounds checking.\n\n        Args:\n            index (`int`):\n                The index of the child we want.\n\n        Returns:\n            `TreeNode`: The child at the desired index.\n        \"\"\"\n        return self.children[index]\n\n    def node_type(self) -&gt; NodeType:\n        \"\"\"\n        Return this node's `NodeType`.\n\n        Returns:\n            `NodeType`: The type (`CONTROL`).\n        \"\"\"\n        return NodeType.CONTROL\n\n    def halt_node(self) -&gt; None:\n        \"\"\"\n        Reset the children and then reset this node.\n        \"\"\"\n        self.reset_children()\n        self.reset_status()\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Instruct each child to reset.\n        \"\"\"\n        for child in self.children:\n            child.reset()\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.add_child","title":"<code>add_child(child)</code>","text":"<p>Add a new child node to the end of the list.</p> <p>Parameters:</p> Name Type Description Default <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>The new child node.</p> required Source code in <code>src/dendron/control_node.py</code> <pre><code>def add_child(self, child : TreeNode) -&gt; None:\n    \"\"\"\n    Add a new child node to the end of the list.\n\n    Args:\n        child (`dendron.tree_node.TreeNode`):\n            The new child node.\n    \"\"\"\n    self.children.append(child)\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.add_children","title":"<code>add_children(children)</code>","text":"<p>Add a list of children to the end of the list.</p> <p>Parameters:</p> Name Type Description Default <code>children</code> <code>`List[TreeNode]`</code> <p>The list of <code>TreeNode</code>s to add.</p> required Source code in <code>src/dendron/control_node.py</code> <pre><code>def add_children(self, children : List[TreeNode]) -&gt; None:\n    \"\"\"\n    Add a list of children to the end of the list.\n\n    Args:\n        children (`List[TreeNode]`):\n            The list of `TreeNode`s to add. \n    \"\"\"\n    self.children.extend(children)\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.child","title":"<code>child(index)</code>","text":"<p>Get the child that is at position <code>index</code> in the list. Does not perform bounds checking.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>`int`</code> <p>The index of the child we want.</p> required <p>Returns:</p> Type Description <code>TreeNode</code> <p><code>TreeNode</code>: The child at the desired index.</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def child(self, index : int) -&gt; TreeNode:\n    \"\"\"\n    Get the child that is at position `index` in the list. Does\n    not perform bounds checking.\n\n    Args:\n        index (`int`):\n            The index of the child we want.\n\n    Returns:\n        `TreeNode`: The child at the desired index.\n    \"\"\"\n    return self.children[index]\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.children","title":"<code>children()</code>","text":"<p>Get the list of children.</p> <p>Returns:</p> Type Description <code>List[TreeNode]</code> <p><code>List[TreeNode]</code>: The <code>self.children</code> list.</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def children(self) -&gt; List[TreeNode]:\n    \"\"\"\n    Get the list of children.\n\n    Returns:\n        `List[TreeNode]`: The `self.children` list.\n    \"\"\"\n    return self.children\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.children_count","title":"<code>children_count()</code>","text":"<p>Get the current number of children.</p> <p>Returns:</p> Type Description <code>int</code> <p><code>int</code>: The length of the children list.</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def children_count(self) -&gt; int:\n    \"\"\"\n    Get the current number of children.\n\n    Returns:\n        `int`: The length of the children list.\n    \"\"\"\n    return len(self.children)\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.get_node_by_name","title":"<code>get_node_by_name(name)</code>","text":"<p>Search for a node by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The name of the node we are looking for.</p> required <p>Returns:</p> Type Description <code>Optional[TreeNode]</code> <p><code>Optional[TreeNode]</code>: Either a node with the given name,</p> <code>Optional[TreeNode]</code> <p>or None.</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n    \"\"\"\n    Search for a node by its name.\n\n    Args:\n        name (`str`):\n            The name of the node we are looking for.\n\n    Returns:\n        `Optional[TreeNode]`: Either a node with the given name,\n        or None.\n    \"\"\"\n    if self.name == name:\n        return self\n    else:\n        for child in self.children:\n            node = child.get_node_by_name(name)\n            if node != None:\n                return node\n        return None\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.halt_node","title":"<code>halt_node()</code>","text":"<p>Reset the children and then reset this node.</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def halt_node(self) -&gt; None:\n    \"\"\"\n    Reset the children and then reset this node.\n    \"\"\"\n    self.reset_children()\n    self.reset_status()\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.node_type","title":"<code>node_type()</code>","text":"<p>Return this node's <code>NodeType</code>.</p> <p>Returns:</p> Type Description <code>NodeType</code> <p><code>NodeType</code>: The type (<code>CONTROL</code>).</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def node_type(self) -&gt; NodeType:\n    \"\"\"\n    Return this node's `NodeType`.\n\n    Returns:\n        `NodeType`: The type (`CONTROL`).\n    \"\"\"\n    return NodeType.CONTROL\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.reset","title":"<code>reset()</code>","text":"<p>Instruct each child to reset.</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Instruct each child to reset.\n    \"\"\"\n    for child in self.children:\n        child.reset()\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.set_blackboard","title":"<code>set_blackboard(bb)</code>","text":"<p>Set the blackboard for this node, and then forward to the children.</p> <p>Parameters:</p> Name Type Description Default <code>bb</code> <code>`dendron.blackboard.Blackboard`</code> <p>The new blackboard to use.</p> required Source code in <code>src/dendron/control_node.py</code> <pre><code>def set_blackboard(self, bb : Blackboard) -&gt; None:\n    \"\"\"\n    Set the blackboard for this node, and then forward to the\n    children.\n\n    Args:\n        bb (`dendron.blackboard.Blackboard`):\n            The new blackboard to use.\n    \"\"\"\n    self.blackboard = bb\n    for child in self.children:\n        child.set_blackboard(bb)\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.set_log_level","title":"<code>set_log_level(new_level)</code>","text":"<p>Set the log level for this node, then forward that level for the children to use.</p> Source code in <code>src/dendron/control_node.py</code> <pre><code>def set_log_level(self, new_level) -&gt; None:\n    \"\"\"\n    Set the log level for this node, then forward that level for the\n    children to use.\n    \"\"\"\n    self.log_level = new_level\n    for c in self.children:\n        c.set_log_level(new_level)\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.set_logger","title":"<code>set_logger(new_logger)</code>","text":"<p>Set the logger for this node, and then forward the logger to the children.</p> <p>Parameters:</p> Name Type Description Default <code>new_logger</code> <code>`logging.Logger`</code> <p>The Logger to use.</p> required Source code in <code>src/dendron/control_node.py</code> <pre><code>def set_logger(self, new_logger) -&gt; None:\n    \"\"\"\n    Set the logger for this node, and then forward the logger to the\n    children.\n\n    Args:\n        new_logger (`logging.Logger`):\n            The Logger to use.\n    \"\"\"\n    self.logger = new_logger\n    for c in self.children:\n        c.set_logger(new_logger)\n</code></pre>"},{"location":"api/control_node/#dendron.control_node.ControlNode.set_tree","title":"<code>set_tree(tree)</code>","text":"<p>Set the tree of this node, and then have each of the children set their tree similarly.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>`dendron.behavior_tree.BehaviorTree`</code> <p>The tree that will contain this node.</p> required Source code in <code>src/dendron/control_node.py</code> <pre><code>def set_tree(self, tree : BehaviorTree) -&gt; None:\n    \"\"\"\n    Set the tree of this node, and then have each of the children\n    set their tree similarly.\n\n    Args:\n        tree (`dendron.behavior_tree.BehaviorTree`):\n            The tree that will contain this node.\n    \"\"\"\n    self.tree = tree\n    for c in self.children:\n        c.set_tree(tree)\n</code></pre>"},{"location":"api/decorator_node/","title":"DecoratorNode","text":""},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode","title":"<code>dendron.decorator_node.DecoratorNode</code>","text":"<p>             Bases: <code>TreeNode</code></p> <p>A decorator is a \"wrapper\" around a single node. The purpose of  the decorator is to modify or support the action of its child in some way.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>An optional child node. If not specified, the child must be  set before this node's <code>tick()</code> function is first called.</p> <code>None</code> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>class DecoratorNode(TreeNode):\n    \"\"\"\n    A decorator is a \"wrapper\" around a single node. The purpose of \n    the decorator is to modify or support the action of its child in\n    some way.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            An optional child node. If not specified, the child must be \n            set before this node's `tick()` function is first called.\n    \"\"\"\n\n    def __init__(self, name, child : TreeNode = None) -&gt; None:\n        super().__init__(name)\n        self.child_node : TreeNode = child\n\n    def set_logger(self, new_logger) -&gt; None:\n        \"\"\"\n        Set the logger for this node, and then forward the logger to the \n        child node.\n        \"\"\"\n        self.logger = new_logger\n        self.child_node.set_logger(new_logger)\n\n    def set_log_level(self, new_level) -&gt; None:\n        \"\"\"\n        Set the log level for this node, and then forward that level to \n        the child node.\n        \"\"\"\n        self.log_level = new_level\n        self.child_node.set_log_level(new_level)\n\n    def node_type(self) -&gt; NodeType:\n        \"\"\"\n        Return this node's type.\n        \"\"\"\n        return NodeType.DECORATOR \n\n    def set_child(self, child : TreeNode) -&gt; None:\n        \"\"\"\n        Set the child of this node to a new `TreeNode`.\n\n        Args:\n            child (`dendron.tree_node.TreeNode`):\n                The new child of this decorator.\n        \"\"\"\n        self.child_node = child\n\n    def get_child(self) -&gt; TreeNode:\n        \"\"\"\n        Get the child of this decorator.\n\n        Returns:\n            `TreeNode`: The child of this node.\n        \"\"\"\n        return self.child_node\n\n    def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n        \"\"\"\n        Search for a node by its name.\n\n        Args:\n            name (`str`):\n                The name of the node we are looking for.\n\n        Returns:\n            `Optional[TreeNode]`: Either a node with the given name,\n            or None.\n        \"\"\"\n        if self.name == name:\n            return self\n        else:\n            return self.child_node.get_node_by_name(name)\n\n    def halt_child(self) -&gt; None:\n        \"\"\"\n        Instruct the child node to halt.\n        \"\"\"\n        self.child_node.halt_node()\n\n    def set_tree(self, tree : BehaviorTree) -&gt; None:\n        \"\"\"\n        Set the tree of this node, and then forward the tree to the child\n        to have it set its tree.\n\n        Args:\n            tree (`dendron.behavior_tree.BehaviorTree`):\n                The tree that contains this node.\n        \"\"\"\n        self.tree = tree\n        self.child_node.set_tree(tree)\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Set the status of this node to IDLE and instruct the child node to\n        reset.\n        \"\"\"\n        self.node_status = NodeStatus.IDLE\n        self.child_node.reset()\n\n    def pretty_repr(self, depth = 0) -&gt; str:\n        \"\"\"\n        Return a string representation of this node at the given depth.\n\n        Args:\n            depth (`int`):\n                The depth of this node in a surrounding tree.\n\n        Returns:\n            `str`: The indented string representation.\n        \"\"\"\n        tabs = '\\t'*depth\n        repr = f\"{tabs}Decorator {self.name}\\n{self.child_node.pretty_repr(depth+1)}\"\n        return repr\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.get_child","title":"<code>get_child()</code>","text":"<p>Get the child of this decorator.</p> <p>Returns:</p> Type Description <code>TreeNode</code> <p><code>TreeNode</code>: The child of this node.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def get_child(self) -&gt; TreeNode:\n    \"\"\"\n    Get the child of this decorator.\n\n    Returns:\n        `TreeNode`: The child of this node.\n    \"\"\"\n    return self.child_node\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.get_node_by_name","title":"<code>get_node_by_name(name)</code>","text":"<p>Search for a node by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The name of the node we are looking for.</p> required <p>Returns:</p> Type Description <code>Optional[TreeNode]</code> <p><code>Optional[TreeNode]</code>: Either a node with the given name,</p> <code>Optional[TreeNode]</code> <p>or None.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def get_node_by_name(self, name : str) -&gt; Optional[TreeNode]:\n    \"\"\"\n    Search for a node by its name.\n\n    Args:\n        name (`str`):\n            The name of the node we are looking for.\n\n    Returns:\n        `Optional[TreeNode]`: Either a node with the given name,\n        or None.\n    \"\"\"\n    if self.name == name:\n        return self\n    else:\n        return self.child_node.get_node_by_name(name)\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.halt_child","title":"<code>halt_child()</code>","text":"<p>Instruct the child node to halt.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def halt_child(self) -&gt; None:\n    \"\"\"\n    Instruct the child node to halt.\n    \"\"\"\n    self.child_node.halt_node()\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.node_type","title":"<code>node_type()</code>","text":"<p>Return this node's type.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def node_type(self) -&gt; NodeType:\n    \"\"\"\n    Return this node's type.\n    \"\"\"\n    return NodeType.DECORATOR \n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.pretty_repr","title":"<code>pretty_repr(depth=0)</code>","text":"<p>Return a string representation of this node at the given depth.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>`int`</code> <p>The depth of this node in a surrounding tree.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p><code>str</code>: The indented string representation.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def pretty_repr(self, depth = 0) -&gt; str:\n    \"\"\"\n    Return a string representation of this node at the given depth.\n\n    Args:\n        depth (`int`):\n            The depth of this node in a surrounding tree.\n\n    Returns:\n        `str`: The indented string representation.\n    \"\"\"\n    tabs = '\\t'*depth\n    repr = f\"{tabs}Decorator {self.name}\\n{self.child_node.pretty_repr(depth+1)}\"\n    return repr\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.reset","title":"<code>reset()</code>","text":"<p>Set the status of this node to IDLE and instruct the child node to reset.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Set the status of this node to IDLE and instruct the child node to\n    reset.\n    \"\"\"\n    self.node_status = NodeStatus.IDLE\n    self.child_node.reset()\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.set_child","title":"<code>set_child(child)</code>","text":"<p>Set the child of this node to a new <code>TreeNode</code>.</p> <p>Parameters:</p> Name Type Description Default <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>The new child of this decorator.</p> required Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def set_child(self, child : TreeNode) -&gt; None:\n    \"\"\"\n    Set the child of this node to a new `TreeNode`.\n\n    Args:\n        child (`dendron.tree_node.TreeNode`):\n            The new child of this decorator.\n    \"\"\"\n    self.child_node = child\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.set_log_level","title":"<code>set_log_level(new_level)</code>","text":"<p>Set the log level for this node, and then forward that level to  the child node.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def set_log_level(self, new_level) -&gt; None:\n    \"\"\"\n    Set the log level for this node, and then forward that level to \n    the child node.\n    \"\"\"\n    self.log_level = new_level\n    self.child_node.set_log_level(new_level)\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.set_logger","title":"<code>set_logger(new_logger)</code>","text":"<p>Set the logger for this node, and then forward the logger to the  child node.</p> Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def set_logger(self, new_logger) -&gt; None:\n    \"\"\"\n    Set the logger for this node, and then forward the logger to the \n    child node.\n    \"\"\"\n    self.logger = new_logger\n    self.child_node.set_logger(new_logger)\n</code></pre>"},{"location":"api/decorator_node/#dendron.decorator_node.DecoratorNode.set_tree","title":"<code>set_tree(tree)</code>","text":"<p>Set the tree of this node, and then forward the tree to the child to have it set its tree.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>`dendron.behavior_tree.BehaviorTree`</code> <p>The tree that contains this node.</p> required Source code in <code>src/dendron/decorator_node.py</code> <pre><code>def set_tree(self, tree : BehaviorTree) -&gt; None:\n    \"\"\"\n    Set the tree of this node, and then forward the tree to the child\n    to have it set its tree.\n\n    Args:\n        tree (`dendron.behavior_tree.BehaviorTree`):\n            The tree that contains this node.\n    \"\"\"\n    self.tree = tree\n    self.child_node.set_tree(tree)\n</code></pre>"},{"location":"api/tree_node/","title":"TreeNode","text":""},{"location":"api/tree_node/#dendron.tree_node.TreeNode","title":"<code>dendron.tree_node.TreeNode</code>","text":"<p>Base class for a node in a behavior tree.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The name to give to this node.</p> required Source code in <code>src/dendron/tree_node.py</code> <pre><code>class TreeNode:\n    \"\"\"\n    Base class for a node in a behavior tree.\n\n    Args:\n        name (`str`):\n            The name to give to this node. \n    \"\"\"\n\n    def __init__(self, name : str) -&gt; None:\n        self.name = name\n        self.blackboard = None\n        self.status = NodeStatus.IDLE\n\n        self.pre_tick_fns = []\n        self.post_tick_fns = []\n\n        self.logger = None\n        self.log_level = None\n\n        self.tree = None\n\n    def set_tree(self, tree : BehaviorTree) -&gt; None:\n        \"\"\"\n        Set the tree that contains this node.\n\n        Args:\n            tree (`dendron.behavior_tree.BehaviorTree`):\n                The new tree this node is a part of.\n        \"\"\"\n        self.tree = tree\n\n    def set_logger(self, new_logger) -&gt; None:\n        raise NotImplementedError(\"set_logger should be defined in subclass.\")\n\n    def set_log_level(self, new_level) -&gt; None:\n        raise NotImplementedError(\"set_log_level should be defined in subclass.\")\n\n    def _get_level_str(self, new_level) -&gt; str:\n        if self.logger is not None:\n            level_str = \"None\"  \n            match self.logger.level:    \n                case logging.DEBUG: \n                    level_str = \"debug\" \n                case logging.INFO:  \n                    level_str = \"info\"  \n                case logging.WARNING:   \n                    level_str = \"warning\"\n                case logging.ERROR: \n                    level_str = \"error\" \n                case logging.CRITICAL:  \n                    level_str = \"critical\"\n            return level_str\n\n    def execute_tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Performs pre-tick operations, calls the Node's tick() method, and \n        then performs post-tick operations. If logging is enabled, then this \n        is where log functions are called.\n\n        Returns:\n            `dendron.basic_types.NodeStatus`: The status returned by the inner \n            call to tick().\n        \"\"\"\n        if self.logger is not None:\n            log_fn = getattr(self.logger, self._get_level_str(self.log_level))\n            log_fn(f\"{self.name} - pre_tick\")\n\n        for f in self.pre_tick_fns:\n            f()\n\n        self.status = self.tick()\n\n        for f in self.post_tick_fns:\n            f()\n\n        if self.logger is not None:\n            log_fn = getattr(self.logger, self._get_level_str(self.log_level))\n            log_fn(f\"{self.name} - post_tick {self.status}\")\n\n        return self.status\n\n    def set_description(self, desc) -&gt; None:\n        \"\"\"\n        A textual description intended to help with automated\n        policy construction.\n\n        Args:\n            desc (`str`):\n                The textual description of this node's functionality.\n        \"\"\"\n        self.description = desc\n\n    def halt_node(self) -&gt; None:\n        raise NotImplementedError(\"Halt behavior is specified in subclass.\")\n\n    def set_blackboard(self, bb : Blackboard) -&gt; None:\n        \"\"\"\n        Set the blackboard to be used by this TreeNode.\n\n        Args:\n            bb (`dendron.blackboard.Blackboard`):\n                The new blackboard.\n        \"\"\"\n        self.blackboard = bb\n\n    def is_halted(self) -&gt; bool:\n        \"\"\"\n        Query whether this node is in a halted state.\n\n        Returns:\n            `bool`: True iff the status is IDLE.\n        \"\"\"\n        return self.status == NodeStatus.IDLE\n\n    def get_status(self) -&gt; NodeStatus:\n        \"\"\"\n        Get the current status of this node.\n\n        Returns:\n            `dendron.basic_types.NodeStatus`: The node status.\n        \"\"\"\n        return self.status \n\n    def set_status(self, new_status : NodeStatus) -&gt; None:\n        \"\"\"\n        Set the node status to a new value.\n\n        Args:\n            new_status (`dendron.basic_types.NodeStatus`):\n                The new NodeStatus.\n        \"\"\"\n        self.status = new_status\n\n    def name(self) -&gt; str:\n        \"\"\"\n        Get this node's human-readable name.\n\n        Returns:\n            `str`: The given name of this node.\n        \"\"\"\n        return self.name\n\n    def node_type(self) -&gt; NodeType:\n        raise NotImplementedError(\"Type is specified in subclass.\")\n\n    # the problem with this is that Self is only supported in 3.11+, which \n    # doesn't work with some libraries and packages.\n    #def get_node_by_name(self, name : str) -&gt; Optional[Self]:\n\n    def get_node_by_name(self, name: str):\n        \"\"\"\n        Search for a node by its name.\n\n        Args:\n            name (`str`):\n                The name of the node we are looking for.\n\n        Returns:\n            `Optional[TreeNode]`: Either a node with the given name,\n            or None.\n        \"\"\"\n        raise NotImplementedError(\"get_node_by_name should be implemented in a subclass.\")\n\n    def add_pre_tick(self, f : Callable) -&gt; None:\n        \"\"\"\n        Specify a function-like object to be called before the `tick()` \n        function. The argument is added to a list of such functions.        \n\n        Args:\n            f (`Callable`): \n                The function to call before `tick()`.\n        \"\"\"\n        self.pre_tick_fns.append(types.MethodType(f, self))\n\n    def add_post_tick(self, f : Callable) -&gt; None:\n        \"\"\"\n        Specify a function-like object to be called after the `tick()`\n        function. The argument is added to a list of such functions.\n\n        Args:\n            f (`Callable`):\n                The function to call after `tick()`.\n        \"\"\"\n        self.post_tick_fns.append(types.MethodType(f, self))\n\n    def tick(self) -&gt; NodeStatus:\n        raise NotImplementedError(\"Tick should be implemented in a subclass.\")\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Set the status of this node to IDLE.\n        \"\"\"\n        self.status = NodeStatus.IDLE\n\n    def pretty_repr(self, depth = 0) -&gt; str:\n        \"\"\"\n        Return a string representation of this node at the given depth.\n\n        Args:\n            depth (`int`):\n                The depth of this node in a surrounding tree.\n\n        Returns:\n            `str`: The indented string representation.\n        \"\"\"\n        raise NotImplementedError(\"Pretty printing should be implemented in a subclass.\")\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.add_post_tick","title":"<code>add_post_tick(f)</code>","text":"<p>Specify a function-like object to be called after the <code>tick()</code> function. The argument is added to a list of such functions.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>`Callable`</code> <p>The function to call after <code>tick()</code>.</p> required Source code in <code>src/dendron/tree_node.py</code> <pre><code>def add_post_tick(self, f : Callable) -&gt; None:\n    \"\"\"\n    Specify a function-like object to be called after the `tick()`\n    function. The argument is added to a list of such functions.\n\n    Args:\n        f (`Callable`):\n            The function to call after `tick()`.\n    \"\"\"\n    self.post_tick_fns.append(types.MethodType(f, self))\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.add_pre_tick","title":"<code>add_pre_tick(f)</code>","text":"<p>Specify a function-like object to be called before the <code>tick()</code>  function. The argument is added to a list of such functions.        </p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>`Callable`</code> <p>The function to call before <code>tick()</code>.</p> required Source code in <code>src/dendron/tree_node.py</code> <pre><code>def add_pre_tick(self, f : Callable) -&gt; None:\n    \"\"\"\n    Specify a function-like object to be called before the `tick()` \n    function. The argument is added to a list of such functions.        \n\n    Args:\n        f (`Callable`): \n            The function to call before `tick()`.\n    \"\"\"\n    self.pre_tick_fns.append(types.MethodType(f, self))\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.execute_tick","title":"<code>execute_tick()</code>","text":"<p>Performs pre-tick operations, calls the Node's tick() method, and  then performs post-tick operations. If logging is enabled, then this  is where log functions are called.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>dendron.basic_types.NodeStatus</code>: The status returned by the inner </p> <code>NodeStatus</code> <p>call to tick().</p> Source code in <code>src/dendron/tree_node.py</code> <pre><code>def execute_tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Performs pre-tick operations, calls the Node's tick() method, and \n    then performs post-tick operations. If logging is enabled, then this \n    is where log functions are called.\n\n    Returns:\n        `dendron.basic_types.NodeStatus`: The status returned by the inner \n        call to tick().\n    \"\"\"\n    if self.logger is not None:\n        log_fn = getattr(self.logger, self._get_level_str(self.log_level))\n        log_fn(f\"{self.name} - pre_tick\")\n\n    for f in self.pre_tick_fns:\n        f()\n\n    self.status = self.tick()\n\n    for f in self.post_tick_fns:\n        f()\n\n    if self.logger is not None:\n        log_fn = getattr(self.logger, self._get_level_str(self.log_level))\n        log_fn(f\"{self.name} - post_tick {self.status}\")\n\n    return self.status\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.get_node_by_name","title":"<code>get_node_by_name(name)</code>","text":"<p>Search for a node by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The name of the node we are looking for.</p> required <p>Returns:</p> Type Description <p><code>Optional[TreeNode]</code>: Either a node with the given name,</p> <p>or None.</p> Source code in <code>src/dendron/tree_node.py</code> <pre><code>def get_node_by_name(self, name: str):\n    \"\"\"\n    Search for a node by its name.\n\n    Args:\n        name (`str`):\n            The name of the node we are looking for.\n\n    Returns:\n        `Optional[TreeNode]`: Either a node with the given name,\n        or None.\n    \"\"\"\n    raise NotImplementedError(\"get_node_by_name should be implemented in a subclass.\")\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.get_status","title":"<code>get_status()</code>","text":"<p>Get the current status of this node.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>dendron.basic_types.NodeStatus</code>: The node status.</p> Source code in <code>src/dendron/tree_node.py</code> <pre><code>def get_status(self) -&gt; NodeStatus:\n    \"\"\"\n    Get the current status of this node.\n\n    Returns:\n        `dendron.basic_types.NodeStatus`: The node status.\n    \"\"\"\n    return self.status \n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.is_halted","title":"<code>is_halted()</code>","text":"<p>Query whether this node is in a halted state.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>bool</code>: True iff the status is IDLE.</p> Source code in <code>src/dendron/tree_node.py</code> <pre><code>def is_halted(self) -&gt; bool:\n    \"\"\"\n    Query whether this node is in a halted state.\n\n    Returns:\n        `bool`: True iff the status is IDLE.\n    \"\"\"\n    return self.status == NodeStatus.IDLE\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.name","title":"<code>name()</code>","text":"<p>Get this node's human-readable name.</p> <p>Returns:</p> Type Description <code>str</code> <p><code>str</code>: The given name of this node.</p> Source code in <code>src/dendron/tree_node.py</code> <pre><code>def name(self) -&gt; str:\n    \"\"\"\n    Get this node's human-readable name.\n\n    Returns:\n        `str`: The given name of this node.\n    \"\"\"\n    return self.name\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.pretty_repr","title":"<code>pretty_repr(depth=0)</code>","text":"<p>Return a string representation of this node at the given depth.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>`int`</code> <p>The depth of this node in a surrounding tree.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p><code>str</code>: The indented string representation.</p> Source code in <code>src/dendron/tree_node.py</code> <pre><code>def pretty_repr(self, depth = 0) -&gt; str:\n    \"\"\"\n    Return a string representation of this node at the given depth.\n\n    Args:\n        depth (`int`):\n            The depth of this node in a surrounding tree.\n\n    Returns:\n        `str`: The indented string representation.\n    \"\"\"\n    raise NotImplementedError(\"Pretty printing should be implemented in a subclass.\")\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.reset","title":"<code>reset()</code>","text":"<p>Set the status of this node to IDLE.</p> Source code in <code>src/dendron/tree_node.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Set the status of this node to IDLE.\n    \"\"\"\n    self.status = NodeStatus.IDLE\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.set_blackboard","title":"<code>set_blackboard(bb)</code>","text":"<p>Set the blackboard to be used by this TreeNode.</p> <p>Parameters:</p> Name Type Description Default <code>bb</code> <code>`dendron.blackboard.Blackboard`</code> <p>The new blackboard.</p> required Source code in <code>src/dendron/tree_node.py</code> <pre><code>def set_blackboard(self, bb : Blackboard) -&gt; None:\n    \"\"\"\n    Set the blackboard to be used by this TreeNode.\n\n    Args:\n        bb (`dendron.blackboard.Blackboard`):\n            The new blackboard.\n    \"\"\"\n    self.blackboard = bb\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.set_description","title":"<code>set_description(desc)</code>","text":"<p>A textual description intended to help with automated policy construction.</p> <p>Parameters:</p> Name Type Description Default <code>desc</code> <code>`str`</code> <p>The textual description of this node's functionality.</p> required Source code in <code>src/dendron/tree_node.py</code> <pre><code>def set_description(self, desc) -&gt; None:\n    \"\"\"\n    A textual description intended to help with automated\n    policy construction.\n\n    Args:\n        desc (`str`):\n            The textual description of this node's functionality.\n    \"\"\"\n    self.description = desc\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.set_status","title":"<code>set_status(new_status)</code>","text":"<p>Set the node status to a new value.</p> <p>Parameters:</p> Name Type Description Default <code>new_status</code> <code>`dendron.basic_types.NodeStatus`</code> <p>The new NodeStatus.</p> required Source code in <code>src/dendron/tree_node.py</code> <pre><code>def set_status(self, new_status : NodeStatus) -&gt; None:\n    \"\"\"\n    Set the node status to a new value.\n\n    Args:\n        new_status (`dendron.basic_types.NodeStatus`):\n            The new NodeStatus.\n    \"\"\"\n    self.status = new_status\n</code></pre>"},{"location":"api/tree_node/#dendron.tree_node.TreeNode.set_tree","title":"<code>set_tree(tree)</code>","text":"<p>Set the tree that contains this node.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>`dendron.behavior_tree.BehaviorTree`</code> <p>The new tree this node is a part of.</p> required Source code in <code>src/dendron/tree_node.py</code> <pre><code>def set_tree(self, tree : BehaviorTree) -&gt; None:\n    \"\"\"\n    Set the tree that contains this node.\n\n    Args:\n        tree (`dendron.behavior_tree.BehaviorTree`):\n            The new tree this node is a part of.\n    \"\"\"\n    self.tree = tree\n</code></pre>"},{"location":"api/actions/always_failure/","title":"AlwaysFailure","text":""},{"location":"api/actions/always_failure/#dendron.actions.always_failure.AlwaysFailure","title":"<code>dendron.actions.always_failure.AlwaysFailure</code>","text":"<p>             Bases: <code>ActionNode</code></p> <p>An action node that always returns <code>FAILURE</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required Source code in <code>src/dendron/actions/always_failure.py</code> <pre><code>class AlwaysFailure(ActionNode):\n    \"\"\"\n    An action node that always returns `FAILURE`.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n    \"\"\"\n    def __init__(self, name : str) -&gt; None:\n        super().__init__(name)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Always return `FAILURE`.\n        \"\"\"\n        return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/always_failure/#dendron.actions.always_failure.AlwaysFailure.tick","title":"<code>tick()</code>","text":"<p>Always return <code>FAILURE</code>.</p> Source code in <code>src/dendron/actions/always_failure.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Always return `FAILURE`.\n    \"\"\"\n    return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/always_success/","title":"AlwaysSuccess","text":""},{"location":"api/actions/always_success/#dendron.actions.always_success.AlwaysSuccess","title":"<code>dendron.actions.always_success.AlwaysSuccess</code>","text":"<p>             Bases: <code>ActionNode</code></p> <p>An action node that always returns <code>SUCCESS</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required Source code in <code>src/dendron/actions/always_success.py</code> <pre><code>class AlwaysSuccess(ActionNode):\n    \"\"\"\n    An action node that always returns `SUCCESS`.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n    \"\"\"\n    def __init__(self, name : str) -&gt; None:\n        super().__init__(name)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Always return `SUCCESS`.\n        \"\"\"\n        return NodeStatus.SUCCESS\n</code></pre>"},{"location":"api/actions/always_success/#dendron.actions.always_success.AlwaysSuccess.tick","title":"<code>tick()</code>","text":"<p>Always return <code>SUCCESS</code>.</p> Source code in <code>src/dendron/actions/always_success.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Always return `SUCCESS`.\n    \"\"\"\n    return NodeStatus.SUCCESS\n</code></pre>"},{"location":"api/actions/async_action/","title":"AsyncAction","text":""},{"location":"api/actions/async_action/#dendron.actions.async_action.AsyncAction","title":"<code>dendron.actions.async_action.AsyncAction</code>","text":"<p>             Bases: <code>ActionNode</code></p> <p>An action node that operates asynchronously. </p> <p>Once ticked, the node enters a <code>RUNNING</code> state, which it remains in until the node's <code>Callable</code> returns with a status. That status is what gets returned by the tick function the next  time it is called.</p> <p>Internally, this node maintains a future to store the eventual result of the asynchronous computation.</p> <p>Asynchronous execution is handled by the node's tree's executor, which means this node cannot run without an enclosing tree.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>cb</code> <code>`Callable`</code> <p>The callable object that will be executed asynchronously.</p> required Source code in <code>src/dendron/actions/async_action.py</code> <pre><code>class AsyncAction(ActionNode):\n    \"\"\"\n    An action node that operates asynchronously. \n\n    Once ticked, the node enters a `RUNNING` state, which it\n    remains in until the node's `Callable` returns with a status.\n    That status is what gets returned by the tick function the next \n    time it is called.\n\n    Internally, this node maintains a future to store the eventual\n    result of the asynchronous computation.\n\n    Asynchronous execution is handled by the node's tree's executor,\n    which means this node cannot run without an enclosing tree.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        cb (`Callable`):\n            The callable object that will be executed asynchronously.\n    \"\"\"\n\n    def __init__(self, name : str, cb : Callable) -&gt; None:\n        super().__init__(name)\n\n        self.cb = cb\n        self.fut = None        \n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Set the status of this node to `IDLE`, and clear out the node's\n        future.\n        \"\"\"\n        self.status = NodeStatus.IDLE\n        self.fut = None\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Asynchronously execute this node's callback.\n\n        Returns:\n            `NodeStatus`: The status contained in the node's future, or\n            `RUNNING` if the node is not yet done.\n        \"\"\"\n        if self.fut is None:\n            self.fut = self.tree.executor.submit(self.cb)\n\n        self.fut.add_done_callback(lambda f: self.set_status(f.result()))\n\n        if self.fut.done():\n            old_status = self.status\n            self.reset()\n            return old_status\n        else:\n            return NodeStatus.RUNNING\n</code></pre>"},{"location":"api/actions/async_action/#dendron.actions.async_action.AsyncAction.reset","title":"<code>reset()</code>","text":"<p>Set the status of this node to <code>IDLE</code>, and clear out the node's future.</p> Source code in <code>src/dendron/actions/async_action.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Set the status of this node to `IDLE`, and clear out the node's\n    future.\n    \"\"\"\n    self.status = NodeStatus.IDLE\n    self.fut = None\n</code></pre>"},{"location":"api/actions/async_action/#dendron.actions.async_action.AsyncAction.tick","title":"<code>tick()</code>","text":"<p>Asynchronously execute this node's callback.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>NodeStatus</code>: The status contained in the node's future, or</p> <code>NodeStatus</code> <p><code>RUNNING</code> if the node is not yet done.</p> Source code in <code>src/dendron/actions/async_action.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Asynchronously execute this node's callback.\n\n    Returns:\n        `NodeStatus`: The status contained in the node's future, or\n        `RUNNING` if the node is not yet done.\n    \"\"\"\n    if self.fut is None:\n        self.fut = self.tree.executor.submit(self.cb)\n\n    self.fut.add_done_callback(lambda f: self.set_status(f.result()))\n\n    if self.fut.done():\n        old_status = self.status\n        self.reset()\n        return old_status\n    else:\n        return NodeStatus.RUNNING\n</code></pre>"},{"location":"api/actions/causal_lm_action/","title":"CausalLMAction","text":""},{"location":"api/actions/causal_lm_action/#dendron.actions.causal_lm_action.CausalLMActionConfig","title":"<code>dendron.actions.causal_lm_action.CausalLMActionConfig</code>  <code>dataclass</code>","text":"<p>Configuration for a CausalLMAction.</p> <p>The options in this object control what Hugging Face model is used, how the node interacts with the blackboard, and what decoding strategy is used. If you want a refresher on decoding strategies, check out  this blog post: https://huggingface.co/blog/how-to-generate.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model to use. This should be a valid name corresponding to a Hugging Face model name (including the user name).</p> required <code>auto_load</code> <code>Optional[bool]</code> <p>An optional boolean indicating whether or not to automatically  load model either from disk or the Hugging Face hub. If <code>False</code>, the user is responsible for ensuring that a model is loaded before the first <code>tick()</code> is triggered. Defaults to <code>True</code>.</p> <code>True</code> <code>input_key</code> <code>Optional[str]</code> <p>The blackboard key to use for writing and reading the prompt that  this node will consume. Defaults to \"in\".</p> <code>'in'</code> <code>output_key</code> <code>Optional[str]</code> <p>The blackboard key to use for writing and reading the text generated by this node. Defaults to \"out\".</p> <code>'out'</code> <code>device</code> <code>Optional[str]</code> <p>The device that should be used with the model. Examples include \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".</p> <code>'auto'</code> <code>load_in_8bit</code> <code>Optional[bool]</code> <p>Optional boolean indicating whether or not to use eight-bit quantization from bitsandbytes. When available, will typically decrease memory usage and increase inference speed. Defaults to <code>False</code>.</p> <code>False</code> <code>load_in_4bit</code> <code>Optional[bool]</code> <p>Optional boolean indicating whether or not to use four-bit quantization from bitsandbytes. When available, will typically decrease memory usage and increase inference speed. If you observe degraded performance, try eight-bit quanitization instead. Defaults to <code>False</code>.</p> <code>False</code> <code>max_new_tokens</code> <code>Optional[int]</code> <p>A limit on the number of new tokens to generate. You will usually want to set this yourself based on your application. Defaults to 16.</p> <code>16</code> <code>do_sample</code> <code>Optional[bool]</code> <p>Optional boolean to control decoding strategy. If set to true, allows use of non-default generation strategy. Defaults to <code>False</code>.</p> <code>False</code> <code>top_p</code> <code>Optional[float]</code> <p>Optional float to control use of nucleus sampling. If the value is strictly between 0 and 1, nucleus sampling is activated.</p> <code>1.0</code> <code>torch_dtype</code> <code>dtype</code> <p>The dtype to use for torch tensors. Defaults to <code>torch.float16</code>. You may need to change this depending on your quantization choices.</p> <code>float16</code> <code>use_flash_attn_2</code> <code>Optional[bool]</code> <p>Optional bool controlling whether or not to use Flash Attention 2. Defaults to <code>False</code> in case you haven't installed flash attention. Substantially speeds up inference.</p> <code>False</code> Source code in <code>src/dendron/actions/causal_lm_action.py</code> <pre><code>@dataclass\nclass CausalLMActionConfig:\n    \"\"\"\n    Configuration for a CausalLMAction.\n\n    The options in this object control what Hugging Face model is used,\n    how the node interacts with the blackboard, and what decoding strategy\n    is used. If you want a refresher on decoding strategies, check out \n    this blog post: https://huggingface.co/blog/how-to-generate.\n\n    Args:\n        model_name (str):\n            The name of the model to use. This should be a valid name\n            corresponding to a Hugging Face model name (including the user\n            name).\n        auto_load (Optional[bool]):\n            An optional boolean indicating whether or not to automatically \n            load model either from disk or the Hugging Face hub. If `False`,\n            the user is responsible for ensuring that a model is loaded\n            before the first `tick()` is triggered. Defaults to `True`.\n        input_key (Optional[str]):\n            The blackboard key to use for writing and reading the prompt that \n            this node will consume. Defaults to \"in\".\n        output_key (Optional[str]):\n            The blackboard key to use for writing and reading the text generated\n            by this node. Defaults to \"out\".\n        device (Optional[str]):\n            The device that should be used with the model. Examples include\n            \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".\n        load_in_8bit (Optional[bool]):\n            Optional boolean indicating whether or not to use eight-bit quantization\n            from bitsandbytes. When available, will typically decrease memory usage\n            and increase inference speed. Defaults to `False`.\n        load_in_4bit (Optional[bool]):\n            Optional boolean indicating whether or not to use four-bit quantization\n            from bitsandbytes. When available, will typically decrease memory usage\n            and increase inference speed. If you observe degraded performance, try\n            eight-bit quanitization instead. Defaults to `False`.\n        max_new_tokens (Optional[int]):\n            A limit on the number of new tokens to generate. You will usually want\n            to set this yourself based on your application. Defaults to 16.\n        do_sample (Optional[bool]):\n            Optional boolean to control decoding strategy. If set to true, allows use\n            of non-default generation strategy. Defaults to `False`.\n        top_p (Optional[float]):\n            Optional float to control use of nucleus sampling. If the value is strictly\n            between 0 and 1, nucleus sampling is activated.\n        torch_dtype (torch.dtype):\n            The dtype to use for torch tensors. Defaults to `torch.float16`. You may\n            need to change this depending on your quantization choices.\n        use_flash_attn_2 (Optional[bool]):\n            Optional bool controlling whether or not to use Flash Attention 2. Defaults\n            to `False` in case you haven't installed flash attention. Substantially\n            speeds up inference. \n    \"\"\"\n    model_name : str\n    auto_load : Optional[bool] = field(\n        default = True\n    )\n    input_key : Optional[str] = field(\n        default = \"in\"\n    )\n    output_key : Optional[str] = field(\n        default = \"out\"\n    )\n    device : Optional[str] = field(\n        default = \"auto\"\n    )\n    load_in_8bit : Optional[bool] = field(\n        default = False\n    )\n    load_in_4bit : Optional[bool] = field(\n        default = False\n    )\n    max_new_tokens : Optional[int] = field(\n        default = 16\n    )\n    do_sample : Optional[bool] = field(\n        default = False\n    )\n    top_p : Optional[float] = field(\n        default = 1.0\n    )\n    torch_dtype : Optional[torch.dtype] = field(\n        default=torch.float16\n    )\n    use_flash_attn_2 : Optional[bool] = field(\n        default = False\n    )\n</code></pre>"},{"location":"api/actions/causal_lm_action/#dendron.actions.causal_lm_action.CausalLMAction","title":"<code>dendron.actions.causal_lm_action.CausalLMAction</code>","text":"<p>             Bases: <code>ActionNode</code></p> <p>An action node that uses a causal language model to generate some text based on a prompt contained in the node's  blackboard.</p> <p>This node is based on the Hugging Face transformers library, and will download the model that you specify by name. This can take a long  time and/or use a lot of storage, depending on the model you name.</p> <p>There are enough configuration options for this type of node that the options have all been placed in a dataclass config object. See  the documentation for that object to learn about the many options available to you.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The given name of this node.</p> required <code>cfg</code> <code>CausalLMActionConfig</code> <p>The configuration object for this model.</p> required Source code in <code>src/dendron/actions/causal_lm_action.py</code> <pre><code>class CausalLMAction(ActionNode):\n    \"\"\"\n    An action node that uses a causal language model to generate\n    some text based on a prompt contained in the node's \n    blackboard.\n\n    This node is based on the Hugging Face transformers library, and will\n    download the model that you specify by name. This can take a long \n    time and/or use a lot of storage, depending on the model you name.\n\n    There are enough configuration options for this type of node that\n    the options have all been placed in a dataclass config object. See \n    the documentation for that object to learn about the many options\n    available to you.\n\n    Args:\n        name (str):\n            The given name of this node.\n        cfg (CausalLMActionConfig):\n            The configuration object for this model.\n    \"\"\"\n    def __init__(self, name : str, cfg : CausalLMActionConfig) -&gt; None:\n        super().__init__(name)\n\n        self.input_key = cfg.input_key\n        self.output_key = cfg.output_key\n        self.device = cfg.device\n\n        self.max_new_tokens = cfg.max_new_tokens\n        self.do_sample = cfg.do_sample\n        self.top_p = cfg.top_p\n\n        self.torch_dtype = cfg.torch_dtype\n\n        self.bnb_cfg = BitsAndBytesConfig()\n\n        match cfg.load_in_4bit, cfg.load_in_8bit:\n            case True, True:\n                self.bnb_cfg.load_in_4bit = True\n                self.bnb_cfg.bnb_4bit_compute_dtype = cfg.torch_dtype\n            case True, False:\n                self.bnb_cfg.load_in_4bit = True\n                self.bnb_cfg.bnb_4bit_compute_dtype = cfg.torch_dtype\n            case False, True:\n                self.bnb_cfg.load_in_8bit = True\n            case False, False:\n                pass\n\n        if cfg.use_flash_attn_2:\n            self.attn_implementation = \"flash_attention_2\"\n        else:\n            self.attn_implementation = \"sdpa\"\n\n        if cfg.auto_load:\n            self.model = AutoModelForCausalLM.from_pretrained(\n                cfg.model_name,\n                low_cpu_mem_usage=True,\n                attn_implementation=self.attn_implementation,\n                quantization_config = self.bnb_cfg\n            )\n\n            self.model.eval()\n            self.tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n            if self.tokenizer.pad_token is None:\n                self.tokenizer.pad_token = self.tokenizer.eos_token\n\n        else:\n            self.model = None\n            self.tokenizer = None\n\n        self.input_processor = None\n        self.output_processor = None\n\n    def set_model(self, new_model) -&gt; None:\n        \"\"\"\n        Set a new model to use for generating text.\n        \"\"\"\n        self.model = new_model\n        self.model.eval()\n        self.tokenizer = AutoTokenizer.from_pretrained(new_model.name_or_path)\n\n    def set_input_processor(self, f : Callable) -&gt; None:\n        \"\"\"\n        Set the input processor to use during `tick()`s. \n\n        An input processor is applied to the prompt text stored in the \n        blackboard, and can be used to preprocess the prompt. The \n        processor function should be a map from `str` to `str`. During a \n        `tick()`, the output of this function will be what is tokenized \n        and sent to the model for generation.\n\n        Args:\n            f (Callable):\n                The input processor function to use. Should be a callable\n                object that maps (self, Any) to str.\n        \"\"\"\n        self.input_processor = types.MethodType(f, self)\n\n    def set_output_processor(self, f : Callable) -&gt; None:\n        \"\"\"\n        Set the output processor to use during `tick()`s.\n\n        An output processor is applied to the text generated by the model,\n        before that text is written to the output slot of the blackboard.\n        The function should be a map from `str` to `str`.\n\n        A typical example of an output processor would be a function that\n        removes the prompt from the text returned by a model, so that only\n        the newly generated text is written to the blackboard.\n\n        Args:\n            f (Callable):\n                The output processor function. Should be a callable object\n                that maps from (self, str) to Any.\n        \"\"\"\n        self.output_processor = types.MethodType(f, self)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Execute a tick, consisting of the following steps:\n\n        - Retrieve a prompt from the node's blackboard, using the input_key.\n        - Apply the input processor, if one exists.\n        - Tokenize the prompt text.\n        - Generate new tokens based on the prompt.\n        - Decode the model output into a text string.\n        - Apply the output processor, if one exists,\n        - Write the result back to the blackboard, using the output_key.\n\n        If any of the above fail, the exception text is printed and the node\n        returns a status of `FAILURE`. Otherwise the node returns `SUCCESS`. If\n        you want to use a language model to make decisions, consider looking at\n        the `CompletionConditionNode`.\n        \"\"\"\n        try:\n            input_text = self.blackboard[self.input_key]\n\n            if self.input_processor:\n                input_text = self.input_processor(input_text)\n\n            input_ids = self.tokenizer(input_text, return_tensors=\"pt\").to(self.model.device)\n\n            generated_ids = self.model.generate(**input_ids, max_new_tokens=self.max_new_tokens, pad_token_id=self.tokenizer.pad_token_id, do_sample=self.do_sample, top_p=self.top_p)\n\n            output_text = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\n            if self.output_processor:\n                output_text = self.output_processor(output_text)\n\n            self.blackboard[self.output_key] = output_text\n\n            return NodeStatus.SUCCESS\n        except Exception as ex:\n            print(f\"Exception in node {self.name}:\")\n            print(traceback.format_exc())\n\n            return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/causal_lm_action/#dendron.actions.causal_lm_action.CausalLMAction.set_model","title":"<code>set_model(new_model)</code>","text":"<p>Set a new model to use for generating text.</p> Source code in <code>src/dendron/actions/causal_lm_action.py</code> <pre><code>def set_model(self, new_model) -&gt; None:\n    \"\"\"\n    Set a new model to use for generating text.\n    \"\"\"\n    self.model = new_model\n    self.model.eval()\n    self.tokenizer = AutoTokenizer.from_pretrained(new_model.name_or_path)\n</code></pre>"},{"location":"api/actions/causal_lm_action/#dendron.actions.causal_lm_action.CausalLMAction.set_input_processor","title":"<code>set_input_processor(f)</code>","text":"<p>Set the input processor to use during <code>tick()</code>s. </p> <p>An input processor is applied to the prompt text stored in the  blackboard, and can be used to preprocess the prompt. The  processor function should be a map from <code>str</code> to <code>str</code>. During a  <code>tick()</code>, the output of this function will be what is tokenized  and sent to the model for generation.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>Callable</code> <p>The input processor function to use. Should be a callable object that maps (self, Any) to str.</p> required Source code in <code>src/dendron/actions/causal_lm_action.py</code> <pre><code>def set_input_processor(self, f : Callable) -&gt; None:\n    \"\"\"\n    Set the input processor to use during `tick()`s. \n\n    An input processor is applied to the prompt text stored in the \n    blackboard, and can be used to preprocess the prompt. The \n    processor function should be a map from `str` to `str`. During a \n    `tick()`, the output of this function will be what is tokenized \n    and sent to the model for generation.\n\n    Args:\n        f (Callable):\n            The input processor function to use. Should be a callable\n            object that maps (self, Any) to str.\n    \"\"\"\n    self.input_processor = types.MethodType(f, self)\n</code></pre>"},{"location":"api/actions/causal_lm_action/#dendron.actions.causal_lm_action.CausalLMAction.set_output_processor","title":"<code>set_output_processor(f)</code>","text":"<p>Set the output processor to use during <code>tick()</code>s.</p> <p>An output processor is applied to the text generated by the model, before that text is written to the output slot of the blackboard. The function should be a map from <code>str</code> to <code>str</code>.</p> <p>A typical example of an output processor would be a function that removes the prompt from the text returned by a model, so that only the newly generated text is written to the blackboard.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>Callable</code> <p>The output processor function. Should be a callable object that maps from (self, str) to Any.</p> required Source code in <code>src/dendron/actions/causal_lm_action.py</code> <pre><code>def set_output_processor(self, f : Callable) -&gt; None:\n    \"\"\"\n    Set the output processor to use during `tick()`s.\n\n    An output processor is applied to the text generated by the model,\n    before that text is written to the output slot of the blackboard.\n    The function should be a map from `str` to `str`.\n\n    A typical example of an output processor would be a function that\n    removes the prompt from the text returned by a model, so that only\n    the newly generated text is written to the blackboard.\n\n    Args:\n        f (Callable):\n            The output processor function. Should be a callable object\n            that maps from (self, str) to Any.\n    \"\"\"\n    self.output_processor = types.MethodType(f, self)\n</code></pre>"},{"location":"api/actions/causal_lm_action/#dendron.actions.causal_lm_action.CausalLMAction.tick","title":"<code>tick()</code>","text":"<p>Execute a tick, consisting of the following steps:</p> <ul> <li>Retrieve a prompt from the node's blackboard, using the input_key.</li> <li>Apply the input processor, if one exists.</li> <li>Tokenize the prompt text.</li> <li>Generate new tokens based on the prompt.</li> <li>Decode the model output into a text string.</li> <li>Apply the output processor, if one exists,</li> <li>Write the result back to the blackboard, using the output_key.</li> </ul> <p>If any of the above fail, the exception text is printed and the node returns a status of <code>FAILURE</code>. Otherwise the node returns <code>SUCCESS</code>. If you want to use a language model to make decisions, consider looking at the <code>CompletionConditionNode</code>.</p> Source code in <code>src/dendron/actions/causal_lm_action.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Execute a tick, consisting of the following steps:\n\n    - Retrieve a prompt from the node's blackboard, using the input_key.\n    - Apply the input processor, if one exists.\n    - Tokenize the prompt text.\n    - Generate new tokens based on the prompt.\n    - Decode the model output into a text string.\n    - Apply the output processor, if one exists,\n    - Write the result back to the blackboard, using the output_key.\n\n    If any of the above fail, the exception text is printed and the node\n    returns a status of `FAILURE`. Otherwise the node returns `SUCCESS`. If\n    you want to use a language model to make decisions, consider looking at\n    the `CompletionConditionNode`.\n    \"\"\"\n    try:\n        input_text = self.blackboard[self.input_key]\n\n        if self.input_processor:\n            input_text = self.input_processor(input_text)\n\n        input_ids = self.tokenizer(input_text, return_tensors=\"pt\").to(self.model.device)\n\n        generated_ids = self.model.generate(**input_ids, max_new_tokens=self.max_new_tokens, pad_token_id=self.tokenizer.pad_token_id, do_sample=self.do_sample, top_p=self.top_p)\n\n        output_text = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\n        if self.output_processor:\n            output_text = self.output_processor(output_text)\n\n        self.blackboard[self.output_key] = output_text\n\n        return NodeStatus.SUCCESS\n    except Exception as ex:\n        print(f\"Exception in node {self.name}:\")\n        print(traceback.format_exc())\n\n        return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/image_lm_action/","title":"ImageLMAction","text":""},{"location":"api/actions/image_lm_action/#dendron.actions.image_lm_action.ImageLMActionConfig","title":"<code>dendron.actions.image_lm_action.ImageLMActionConfig</code>  <code>dataclass</code>","text":"<p>Configuration for an ImageLMAction.</p> <p>The options in this object control what Hugging Face model is used, how the node interacts with the blackboard, and what decoding strategy is used. If you want a refresher on decoding strategies, check out  this blog post: https://huggingface.co/blog/how-to-generate.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>`str`</code> <p>The name of the model to use. This should be a valid name corresponding to a Hugging Face model name (including the user name).</p> required <code>auto_load</code> <code>`Optional[bool]`</code> <p>An optional boolean indicating whether or not to automatically  load model either from disk or the Hugging Face hub. If <code>False</code>, the user is responsible for ensuring that a model is loaded before the first <code>tick()</code> is triggered. Defaults to <code>True</code>.</p> <code>True</code> <code>text_input_key</code> <code>`Optional[str]`</code> <p>The blackboard key to use for writing and reading the text prompt  that this node will consume. Defaults to \"text_in\".</p> <code>'text_in'</code> <code>image_input_key</code> <code>`Optional[str]`</code> <p>The blackboard key to use for writing and reading the image prompt that this node will consume. Defaults to \"image_in\".</p> <code>'image_in'</code> <code>output_key</code> <code>`Optional[str]`</code> <p>The blackboard key to use for writing and reading the text generated by this node. Defaults to \"out\".</p> <code>'out'</code> <code>device</code> <code>`Optional[str]`</code> <p>The device that should be used with the model. Examples include \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".</p> <code>'auto'</code> <code>load_in_8bit</code> <code>`Optional[bool]`</code> <p>Optional boolean indicating whether or not to use eight-bit quantization from bitsandbytes. When available, will typically decrease memory usage and increase inference speed. Defaults to <code>False</code>.</p> <code>False</code> <code>load_in_4bit</code> <code>`Optional[bool]`</code> <p>Optional boolean indicating whether or not to use four-bit quantization from bitsandbytes. When available, will typically decrease memory usage and increase inference speed. If you observe degraded performance, try eight-bit quanitization instead. Defaults to <code>False</code>.</p> <code>False</code> <code>max_new_tokens</code> <code>`Optional[int]`</code> <p>A limit on the number of new tokens to generate. You will usually want to set this yourself based on your application. Defaults to 16.</p> <code>16</code> <code>do_sample</code> <code>`Optional[bool]`</code> <p>Optional boolean to control decoding strategy. If set to true, allows use of non-default generation strategy. Defaults to <code>False</code>.</p> <code>False</code> <code>top_p</code> <code>`Optional[float]`</code> <p>Optional float to control use of nucleus sampling. If the value is strictly between 0 and 1, nucleus sampling is activated.</p> <code>1.0</code> <code>torch_dtype</code> <code>`torch.dtype`</code> <p>The dtype to use for torch tensors. Defaults to <code>torch.float16</code>. You may need to change this depending on your quantization choices.</p> <code>float16</code> <code>use_flash_attn_2</code> <code>`Optional[bool]`</code> <p>Optional bool controlling whether or not to use Flash Attention 2. Defaults to <code>False</code> in case you haven't installed flash attention. Substantially speeds up inference.</p> <code>False</code> Source code in <code>src/dendron/actions/image_lm_action.py</code> <pre><code>@dataclass\nclass ImageLMActionConfig:\n    \"\"\"\n    Configuration for an ImageLMAction.\n\n    The options in this object control what Hugging Face model is used,\n    how the node interacts with the blackboard, and what decoding strategy\n    is used. If you want a refresher on decoding strategies, check out \n    this blog post: https://huggingface.co/blog/how-to-generate.\n\n    Args:\n        model_name (`str`):\n            The name of the model to use. This should be a valid name\n            corresponding to a Hugging Face model name (including the user\n            name).\n        auto_load (`Optional[bool]`):\n            An optional boolean indicating whether or not to automatically \n            load model either from disk or the Hugging Face hub. If `False`,\n            the user is responsible for ensuring that a model is loaded\n            before the first `tick()` is triggered. Defaults to `True`.\n        text_input_key (`Optional[str]`):\n            The blackboard key to use for writing and reading the text prompt \n            that this node will consume. Defaults to \"text_in\".\n        image_input_key (`Optional[str]`):\n            The blackboard key to use for writing and reading the image prompt\n            that this node will consume. Defaults to \"image_in\".\n        output_key (`Optional[str]`):\n            The blackboard key to use for writing and reading the text generated\n            by this node. Defaults to \"out\".\n        device (`Optional[str]`):\n            The device that should be used with the model. Examples include\n            \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".\n        load_in_8bit (`Optional[bool]`):\n            Optional boolean indicating whether or not to use eight-bit quantization\n            from bitsandbytes. When available, will typically decrease memory usage\n            and increase inference speed. Defaults to `False`.\n        load_in_4bit (`Optional[bool]`):\n            Optional boolean indicating whether or not to use four-bit quantization\n            from bitsandbytes. When available, will typically decrease memory usage\n            and increase inference speed. If you observe degraded performance, try\n            eight-bit quanitization instead. Defaults to `False`.\n        max_new_tokens (`Optional[int]`):\n            A limit on the number of new tokens to generate. You will usually want\n            to set this yourself based on your application. Defaults to 16.\n        do_sample (`Optional[bool]`):\n            Optional boolean to control decoding strategy. If set to true, allows use\n            of non-default generation strategy. Defaults to `False`.\n        top_p (`Optional[float]`):\n            Optional float to control use of nucleus sampling. If the value is strictly\n            between 0 and 1, nucleus sampling is activated.\n        torch_dtype (`torch.dtype`):\n            The dtype to use for torch tensors. Defaults to `torch.float16`. You may\n            need to change this depending on your quantization choices.\n        use_flash_attn_2 (`Optional[bool]`):\n            Optional bool controlling whether or not to use Flash Attention 2. Defaults\n            to `False` in case you haven't installed flash attention. Substantially\n            speeds up inference. \n    \"\"\"\n    model_name : str\n    auto_load : Optional[bool] = field(\n        default = True\n    )\n    text_input_key : Optional[str] = field(\n        default = \"text_in\"\n    )\n    image_input_key : Optional[str] = field(\n        default = \"image_in\"\n    )\n    output_key : Optional[str] = field(\n        default = \"out\"\n    )\n    device : Optional[str] = field(\n        default = \"auto\"\n    )\n    load_in_8bit : Optional[bool] = field(\n        default = False\n    )\n    load_in_4bit : Optional[bool] = field(\n        default = False\n    )\n    max_new_tokens : Optional[int] = field(\n        default = 16\n    )\n    do_sample : Optional[bool] = field(\n        default = False\n    )\n    top_p : Optional[float] = field(\n        default = 1.0\n    )\n    torch_dtype : Optional[torch.dtype] = field(\n        default = torch.float16\n    )\n    use_flash_attn_2 : Optional[bool] = field(\n        default = False\n    )\n</code></pre>"},{"location":"api/actions/image_lm_action/#dendron.actions.image_lm_action.ImageLMAction","title":"<code>dendron.actions.image_lm_action.ImageLMAction</code>","text":"<p>             Bases: <code>ActionNode</code></p> <p>An action node that uses a vision-language model to generate some text based on an image prompt and a text prompt contained in the  model's blackboard.</p> <p>This node is based on the Hugging Face transformers library, and will download the model that you specify by name. This can take a long  time and/or use a lot of storage, depending on the model you name.</p> <p>There are enough configuration options for this type of node that the options have all been placed in a dataclass config object. See  the documentation for that object to learn about the many options available to you.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>`ImageLMActionConfig`</code> <p>The configuration object for this model.</p> required Source code in <code>src/dendron/actions/image_lm_action.py</code> <pre><code>class ImageLMAction(ActionNode):\n    \"\"\"\n    An action node that uses a vision-language model to generate some\n    text based on an image prompt and a text prompt contained in the \n    model's blackboard.\n\n    This node is based on the Hugging Face transformers library, and will\n    download the model that you specify by name. This can take a long \n    time and/or use a lot of storage, depending on the model you name.\n\n    There are enough configuration options for this type of node that\n    the options have all been placed in a dataclass config object. See \n    the documentation for that object to learn about the many options\n    available to you.\n\n    Args:\n        cfg (`ImageLMActionConfig`):\n            The configuration object for this model.\n    \"\"\"\n    def __init__(self, name : str, cfg : ImageLMActionConfig) -&gt; None:\n        super().__init__(name)\n\n        self.supported_model_map = {\n            \"llava\" : LlavaForConditionalGeneration,\n            \"vipllava\" : VipLlavaForConditionalGeneration\n        }\n\n        self.text_input_key = cfg.text_input_key\n        self.image_input_key = cfg.image_input_key\n        self.output_key = cfg.output_key\n        self.device = cfg.device\n\n        self.max_new_tokens = cfg.max_new_tokens\n        self.do_sample = cfg.do_sample\n        self.top_p = cfg.top_p\n\n        self.torch_dtype = cfg.torch_dtype\n\n        self.bnb_cfg = BitsAndBytesConfig()\n\n        match cfg.load_in_4bit, cfg.load_in_8bit:\n            case True, True:\n                self.bnb_cfg.load_in_4bit = True\n                self.bnb_cfg.bnb_4bit_compute_dtype = cfg.torch_dtype\n            case True, False:\n                self.bnb_cfg.load_in_4bit = True\n                self.bnb_cfg.bnb_4bit_compute_dtype = cfg.torch_dtype\n            case False, True:\n                self.bnb_cfg.load_in_8bit = True\n            case False, False:\n                pass\n\n        if cfg.use_flash_attn_2:\n            self.attn_implementation = \"flash_attention_2\"\n        else:\n            self.attn_implementation = \"sdpa\"\n\n        if cfg.auto_load:\n            hf_config = AutoConfig.from_pretrained(cfg.model_name)\n            model_type = hf_config.model_type\n\n            try:\n                ClassRef = self.supported_model_map[model_type]\n                self.model = ClassRef.from_pretrained(\n                    cfg.model_name,\n                    low_cpu_mem_usage=True,\n                    attn_implementation=self.attn_implementation,\n                    quantization_config=self.bnb_cfg\n                )\n                self.model.eval()\n            except Exception as e:\n                print(f\"Failed to create model of type {model_type}\")\n                self.model = None\n\n            self.processor = AutoProcessor.from_pretrained(cfg.model_name)\n        else:\n            self.model = None\n            self.processor = None\n\n        self.input_processor = None\n        self.output_processor = None\n\n    def set_model(self, new_model) -&gt; None:\n        \"\"\"\n        Set a new model to use for generating text.\n        \"\"\"\n        self.model = new_model\n        self.model.eval()\n        self.processor = AutoProcessor.from_pretrained(new_model.name_or_path)\n\n    def set_input_processor(self, f : Callable) -&gt; None:\n        \"\"\"\n        Set the input processor to use during `tick()`s. \n\n        An input processor is applied to the prompt image and the prompt text \n        stored in the blackboard, and can be used to preprocess the prompt. \n        The processor function should be a map from `str` to `str`. During \n        a `tick()`, the output of this function will be what is tokenized \n        and sent to the model for generation.\n\n        Args:\n            f (`Callable`):\n                The input processor function to use. Should be a callable\n                object that maps (image,string) pairs to (image,string) \n                pairs.\n        \"\"\"        \n        self.input_processor = types.MethodType(f, self)\n\n    def set_output_processor(self, f : Callable) -&gt; None:\n        \"\"\"\n        Set the output processor to use during `tick()`s.\n\n        An output processor is applied to the text generated by the model,\n        before that text is written to the output slot of the blackboard.\n        The function should be a map from `str` to `str`.\n\n        A typical example of an output processor would be a function that\n        removes the prompt from the text returned by a model, so that only\n        the newly generated text is written to the blackboard.\n\n        Args:\n            f (`Callable`):\n                The output processor function. Should be a callable object\n                that maps strings to strings.\n        \"\"\"\n        self.output_processor = types.MethodType(f, self)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Execute a tick, consisting of the following steps:\n\n        - Retrieve the text prompt and image prompt for the node's blackboard.\n        - Apply the input processor, if one exists,\n        - Process the input text and image into ids for the model.\n        - Generate new tokens based on the processed prompt.\n        - Decode the model output into a text string.\n        - Apply the output processor, if one exists.\n        - Write the output text to the blackboard.\n\n        If any of the above fail, the exception text is printed and the node\n        returns a status of `FAILURE`. Otherwise the node returns `SUCCESS`.\n        \"\"\"\n        try:\n            input_text = self.blackboard[self.text_input_key]\n            input_image = self.blackboard[self.image_input_key]\n\n            if self.input_processor:\n                input_text, input_image = self.input_processor(input_text, input_image)\n\n            input_ids = self.processor(text=input_text, images=input_image, return_tensors=\"pt\").to(self.model.device, self.torch_dtype)\n            generated_ids = self.model.generate(**input_ids, max_new_tokens=self.max_new_tokens, do_sample=self.do_sample, top_p=self.top_p)\n            output_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\n            if self.output_processor:\n                output_text = self.output_processor(output_text)\n\n            self.blackboard[self.output_key] = output_text\n\n            return NodeStatus.SUCCESS\n        except Exception as ex:\n            print(f\"Exception in node {self.name}:\")\n            print(traceback.format_exc())\n\n            return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/image_lm_action/#dendron.actions.image_lm_action.ImageLMAction.set_model","title":"<code>set_model(new_model)</code>","text":"<p>Set a new model to use for generating text.</p> Source code in <code>src/dendron/actions/image_lm_action.py</code> <pre><code>def set_model(self, new_model) -&gt; None:\n    \"\"\"\n    Set a new model to use for generating text.\n    \"\"\"\n    self.model = new_model\n    self.model.eval()\n    self.processor = AutoProcessor.from_pretrained(new_model.name_or_path)\n</code></pre>"},{"location":"api/actions/image_lm_action/#dendron.actions.image_lm_action.ImageLMAction.set_input_processor","title":"<code>set_input_processor(f)</code>","text":"<p>Set the input processor to use during <code>tick()</code>s. </p> <p>An input processor is applied to the prompt image and the prompt text  stored in the blackboard, and can be used to preprocess the prompt.  The processor function should be a map from <code>str</code> to <code>str</code>. During  a <code>tick()</code>, the output of this function will be what is tokenized  and sent to the model for generation.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>`Callable`</code> <p>The input processor function to use. Should be a callable object that maps (image,string) pairs to (image,string)  pairs.</p> required Source code in <code>src/dendron/actions/image_lm_action.py</code> <pre><code>def set_input_processor(self, f : Callable) -&gt; None:\n    \"\"\"\n    Set the input processor to use during `tick()`s. \n\n    An input processor is applied to the prompt image and the prompt text \n    stored in the blackboard, and can be used to preprocess the prompt. \n    The processor function should be a map from `str` to `str`. During \n    a `tick()`, the output of this function will be what is tokenized \n    and sent to the model for generation.\n\n    Args:\n        f (`Callable`):\n            The input processor function to use. Should be a callable\n            object that maps (image,string) pairs to (image,string) \n            pairs.\n    \"\"\"        \n    self.input_processor = types.MethodType(f, self)\n</code></pre>"},{"location":"api/actions/image_lm_action/#dendron.actions.image_lm_action.ImageLMAction.set_output_processor","title":"<code>set_output_processor(f)</code>","text":"<p>Set the output processor to use during <code>tick()</code>s.</p> <p>An output processor is applied to the text generated by the model, before that text is written to the output slot of the blackboard. The function should be a map from <code>str</code> to <code>str</code>.</p> <p>A typical example of an output processor would be a function that removes the prompt from the text returned by a model, so that only the newly generated text is written to the blackboard.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>`Callable`</code> <p>The output processor function. Should be a callable object that maps strings to strings.</p> required Source code in <code>src/dendron/actions/image_lm_action.py</code> <pre><code>def set_output_processor(self, f : Callable) -&gt; None:\n    \"\"\"\n    Set the output processor to use during `tick()`s.\n\n    An output processor is applied to the text generated by the model,\n    before that text is written to the output slot of the blackboard.\n    The function should be a map from `str` to `str`.\n\n    A typical example of an output processor would be a function that\n    removes the prompt from the text returned by a model, so that only\n    the newly generated text is written to the blackboard.\n\n    Args:\n        f (`Callable`):\n            The output processor function. Should be a callable object\n            that maps strings to strings.\n    \"\"\"\n    self.output_processor = types.MethodType(f, self)\n</code></pre>"},{"location":"api/actions/image_lm_action/#dendron.actions.image_lm_action.ImageLMAction.tick","title":"<code>tick()</code>","text":"<p>Execute a tick, consisting of the following steps:</p> <ul> <li>Retrieve the text prompt and image prompt for the node's blackboard.</li> <li>Apply the input processor, if one exists,</li> <li>Process the input text and image into ids for the model.</li> <li>Generate new tokens based on the processed prompt.</li> <li>Decode the model output into a text string.</li> <li>Apply the output processor, if one exists.</li> <li>Write the output text to the blackboard.</li> </ul> <p>If any of the above fail, the exception text is printed and the node returns a status of <code>FAILURE</code>. Otherwise the node returns <code>SUCCESS</code>.</p> Source code in <code>src/dendron/actions/image_lm_action.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Execute a tick, consisting of the following steps:\n\n    - Retrieve the text prompt and image prompt for the node's blackboard.\n    - Apply the input processor, if one exists,\n    - Process the input text and image into ids for the model.\n    - Generate new tokens based on the processed prompt.\n    - Decode the model output into a text string.\n    - Apply the output processor, if one exists.\n    - Write the output text to the blackboard.\n\n    If any of the above fail, the exception text is printed and the node\n    returns a status of `FAILURE`. Otherwise the node returns `SUCCESS`.\n    \"\"\"\n    try:\n        input_text = self.blackboard[self.text_input_key]\n        input_image = self.blackboard[self.image_input_key]\n\n        if self.input_processor:\n            input_text, input_image = self.input_processor(input_text, input_image)\n\n        input_ids = self.processor(text=input_text, images=input_image, return_tensors=\"pt\").to(self.model.device, self.torch_dtype)\n        generated_ids = self.model.generate(**input_ids, max_new_tokens=self.max_new_tokens, do_sample=self.do_sample, top_p=self.top_p)\n        output_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\n        if self.output_processor:\n            output_text = self.output_processor(output_text)\n\n        self.blackboard[self.output_key] = output_text\n\n        return NodeStatus.SUCCESS\n    except Exception as ex:\n        print(f\"Exception in node {self.name}:\")\n        print(traceback.format_exc())\n\n        return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/pipeline_action/","title":"PipelineAction","text":""},{"location":"api/actions/pipeline_action/#dendron.actions.pipeline_action.PipelineActionConfig","title":"<code>dendron.actions.pipeline_action.PipelineActionConfig</code>  <code>dataclass</code>","text":"<p>Configuration for a PipelineAction.</p> <p>The options in this object control what Hugging Face task and model are used and how the node interacts with the blackboard.</p> <p>Parameters:</p> Name Type Description Default <code>task_name</code> <code>`str`</code> <p>The name of the Hugging Facetask to use. This should be a valid HF task name. For an overview of the tasks that HF supports, see https://huggingface.co/tasks.</p> required <code>model</code> <code>`Optional[str]`</code> <p>Optional name of a model to use. This should be a valid name corresponding to a Hugging Face model name (including the user name). Defaults to None, in which case the default model for the pipeline task will be used.</p> <code>None</code> <code>input_key</code> <code>`Optional[str]`</code> <p>The blackboard key to use for writing and reading the prompt that  this node will consume. Defaults to \"in\".</p> <code>'in'</code> <code>output_key</code> <code>`Optional[str]`</code> <p>The blackboard key to use for writing and reading the text generated by this node. Defaults to \"out\".</p> <code>'out'</code> <code>device</code> <code>`Optional[str]`</code> <p>The device that should be used with the model. Examples include \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".</p> <code>'auto'</code> Source code in <code>src/dendron/actions/pipeline_action.py</code> <pre><code>@dataclass\nclass PipelineActionConfig:\n    \"\"\"\n    Configuration for a PipelineAction.\n\n    The options in this object control what Hugging Face task and model\n    are used and how the node interacts with the blackboard.\n\n    Args:\n        task_name (`str`):\n            The name of the Hugging Facetask to use. This should be a\n            valid HF task name. For an overview of the tasks that HF\n            supports, see https://huggingface.co/tasks.\n        model (`Optional[str]`):\n            Optional name of a model to use. This should be a valid\n            name corresponding to a Hugging Face model name (including\n            the user name). Defaults to None, in which case the default\n            model for the pipeline task will be used.\n        input_key (`Optional[str]`):\n            The blackboard key to use for writing and reading the prompt that \n            this node will consume. Defaults to \"in\".\n        output_key (`Optional[str]`):\n            The blackboard key to use for writing and reading the text generated\n            by this node. Defaults to \"out\".\n        device (`Optional[str]`):\n            The device that should be used with the model. Examples include\n            \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".\n    \"\"\"\n    task_name : str\n    model : Optional[str] = field(\n        default = None\n    )\n    input_key : Optional[str] = field(\n        default = \"in\"\n    )\n    output_key : Optional[str] = field(\n        default = \"out\"\n    )\n    device : Optional[str] = field(\n        default = \"auto\"\n    )\n</code></pre>"},{"location":"api/actions/pipeline_action/#dendron.actions.pipeline_action.PipelineAction","title":"<code>dendron.actions.pipeline_action.PipelineAction</code>","text":"<p>             Bases: <code>ActionNode</code></p> <p>An action node that uses a Hugging Face transformers pipeline object to execute a behavior. This enables easy access to functionality such as sentiment classification that is wrapped in a Pipeline. This is  also useful for quick prototyping with HF defaults.</p> <p>This node is based on the Hugging Face transformers library, and will download the model that you specify by name. This can take a long  time and/or use a lot of storage, depending on the model you name.</p> <p>There are enough configuration options for this type of node that the options have all been placed in a dataclass config object. See  the documentation for that object to learn about the many options available to you.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>cfg</code> <code>`PipelineActionConfig`</code> <p>The configuration object for this model.</p> required Source code in <code>src/dendron/actions/pipeline_action.py</code> <pre><code>class PipelineAction(ActionNode):\n    \"\"\"\n    An action node that uses a Hugging Face transformers pipeline object\n    to execute a behavior. This enables easy access to functionality such\n    as sentiment classification that is wrapped in a Pipeline. This is \n    also useful for quick prototyping with HF defaults.\n\n    This node is based on the Hugging Face transformers library, and will\n    download the model that you specify by name. This can take a long \n    time and/or use a lot of storage, depending on the model you name.\n\n    There are enough configuration options for this type of node that\n    the options have all been placed in a dataclass config object. See \n    the documentation for that object to learn about the many options\n    available to you.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        cfg (`PipelineActionConfig`):\n            The configuration object for this model.\n    \"\"\"\n    def __init__(self, name : str, cfg : PipelineActionConfig) -&gt; None:\n        super().__init__(name)\n\n        self.task_name = cfg.task_name\n\n        self.input_key = cfg.input_key\n        self.output_key = cfg.output_key\n\n        self.device = cfg.device\n\n        if cfg.model:\n            self.pipeline = pipeline(cfg.task_name, model=cfg.model, device_map=self.device)\n        else:\n            self.pipeline = pipeline(cfg.task_name, device_map=self.device)\n\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Execute a tick, consisting of the following steps:\n\n        - Retrieve a prompt from the node's blackboard.\n        - Apply the pipeline object to the input text.\n        - Write the output to the blackboard.\n\n        If any of the above fail, then the node returns a status of\n        `FAILURE`. Otherwise the node returns a status of `SUCCESS`.\n        \"\"\"\n        try:\n            input_text = self.blackboard[self.input_key]\n            output = self.pipeline(input_text)\n            self.blackboard[self.output_key] = output\n            return NodeStatus.SUCCESS            \n        except:\n            return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/pipeline_action/#dendron.actions.pipeline_action.PipelineAction.tick","title":"<code>tick()</code>","text":"<p>Execute a tick, consisting of the following steps:</p> <ul> <li>Retrieve a prompt from the node's blackboard.</li> <li>Apply the pipeline object to the input text.</li> <li>Write the output to the blackboard.</li> </ul> <p>If any of the above fail, then the node returns a status of <code>FAILURE</code>. Otherwise the node returns a status of <code>SUCCESS</code>.</p> Source code in <code>src/dendron/actions/pipeline_action.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Execute a tick, consisting of the following steps:\n\n    - Retrieve a prompt from the node's blackboard.\n    - Apply the pipeline object to the input text.\n    - Write the output to the blackboard.\n\n    If any of the above fail, then the node returns a status of\n    `FAILURE`. Otherwise the node returns a status of `SUCCESS`.\n    \"\"\"\n    try:\n        input_text = self.blackboard[self.input_key]\n        output = self.pipeline(input_text)\n        self.blackboard[self.output_key] = output\n        return NodeStatus.SUCCESS            \n    except:\n        return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/actions/simple_action/","title":"SimpleAction","text":""},{"location":"api/actions/simple_action/#dendron.actions.simple_action.SimpleAction","title":"<code>dendron.actions.simple_action.SimpleAction</code>","text":"<p>             Bases: <code>ActionNode</code></p> <p>A simple action node is initialized with a callback that is  called every time this node <code>tick()</code>s. The callback should be a function that that returns a <code>NodeStatus</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>callback</code> <code>`Callable`</code> <p>The callback to be executed upon every <code>tick()</code>.</p> required Source code in <code>src/dendron/actions/simple_action.py</code> <pre><code>class SimpleAction(ActionNode):\n    \"\"\"\n    A simple action node is initialized with a callback that is \n    called every time this node `tick()`s. The callback should\n    be a function that that returns a `NodeStatus`.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        callback (`Callable`):\n            The callback to be executed upon every `tick()`.\n    \"\"\"\n    def __init__(self, name : str, callback : Callable) -&gt; None:\n        super().__init__(name)\n        self.callback = callback\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Call the callback function and return its status as the\n        node status.\n        \"\"\"\n        return self.callback() \n</code></pre>"},{"location":"api/actions/simple_action/#dendron.actions.simple_action.SimpleAction.tick","title":"<code>tick()</code>","text":"<p>Call the callback function and return its status as the node status.</p> Source code in <code>src/dendron/actions/simple_action.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Call the callback function and return its status as the\n    node status.\n    \"\"\"\n    return self.callback() \n</code></pre>"},{"location":"api/conditions/completion_condition/","title":"CompletionCondition","text":""},{"location":"api/conditions/completion_condition/#dendron.conditions.completion_condition.CompletionConditionConfig","title":"<code>dendron.conditions.completion_condition.CompletionConditionConfig</code>  <code>dataclass</code>","text":"<p>Configuration for a CompletionConditionNode.</p> <p>The options in this object control what Hugging Face model is used and how the node interacts with the blackboard.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>`str`</code> <p>The name of the model to use. This should be a valid name corresponding to a Hugging Face model name (including the user name).</p> required <code>completions_key</code> <code>`Optional[str]`</code> <p>The blackboard key to read and write the completions to evaluate upon a <code>tick()</code> call. The value stored here should be a list of strings, each string representing one completion. Defaults to \"completions_in\".</p> <code>'completions_in'</code> <code>logprobs_out_key</code> <code>`Optional[str]`</code> <p>The blackboard key to write a dictionary containing the output  log probabilities.</p> <code>'probs_out'</code> <code>success_fn_key</code> <code>`Optional[str]`</code> <p>The blackboard key to read and write the success predicate that determines the status that is ultimately returned upon a <code>tick()</code> call. The predicate should accept a completion string as input  and return a <code>NodeStatus</code>. Defaults to \"success_fn\".</p> <code>'success_fn'</code> <code>auto_load</code> <code>`Optional[bool]`</code> <p>An optional boolean indicating whether or not to automatically  load model either from disk or the Hugging Face hub. If <code>False</code>, the user is responsible for ensuring that a model is loaded before the first <code>tick()</code> is triggered. Defaults to <code>True</code>.</p> <code>True</code> <code>input_key</code> <code>`Optional[str]`</code> <p>The blackboard key to use for writing and reading the prefix that  this node will consume. Defaults to \"in\".</p> <code>'in'</code> <code>device</code> <code>`Optional[str]`</code> <p>The device that should be used with the model. Examples include \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".</p> <code>'auto'</code> <code>load_in_8bit</code> <code>`Optional[bool]`</code> <p>Optional boolean indicating whether or not to use eight-bit quantization from bitsandbytes. When available, will typically decrease memory usage and increase inference speed. Defaults to <code>False</code>.</p> <code>False</code> <code>load_in_4bit</code> <code>`Optional[bool]`</code> <p>Optional boolean indicating whether or not to use four-bit quantization from bitsandbytes. When available, will typically decrease memory usage and increase inference speed. If you observe degraded performance, try eight-bit quanitization instead. Defaults to <code>False</code>.</p> <code>False</code> <code>torch_dtype</code> <code>`torch.dtype`</code> <p>The dtype to use for torch tensors. Defaults to <code>torch.float16</code>. You may need to change this depending on your quantization choices.</p> <code>float16</code> <code>use_flash_attn_2</code> <code>`Optional[bool]`</code> <p>Optional bool controlling whether or not to use Flash Attention 2. Defaults to <code>False</code> in case you haven't installed flash attention. Substantially speeds up inference.</p> <code>False</code> Source code in <code>src/dendron/conditions/completion_condition.py</code> <pre><code>@dataclass\nclass CompletionConditionConfig:\n    \"\"\"\n    Configuration for a CompletionConditionNode.\n\n    The options in this object control what Hugging Face model is used\n    and how the node interacts with the blackboard.\n\n    Args:\n        model_name (`str`):\n            The name of the model to use. This should be a valid name\n            corresponding to a Hugging Face model name (including the user\n            name).\n        completions_key (`Optional[str]`):\n            The blackboard key to read and write the completions to evaluate\n            upon a `tick()` call. The value stored here should be a list of\n            strings, each string representing one completion. Defaults to\n            \"completions_in\".\n        logprobs_out_key (`Optional[str]`):\n            The blackboard key to write a dictionary containing the output \n            log probabilities.\n        success_fn_key (`Optional[str]`):\n            The blackboard key to read and write the success predicate that\n            determines the status that is ultimately returned upon a `tick()`\n            call. The predicate should accept a completion string as input \n            and return a `NodeStatus`. Defaults to \"success_fn\".\n        auto_load (`Optional[bool]`):\n            An optional boolean indicating whether or not to automatically \n            load model either from disk or the Hugging Face hub. If `False`,\n            the user is responsible for ensuring that a model is loaded\n            before the first `tick()` is triggered. Defaults to `True`.\n        input_key (`Optional[str]`):\n            The blackboard key to use for writing and reading the prefix that \n            this node will consume. Defaults to \"in\".\n        device (`Optional[str]`):\n            The device that should be used with the model. Examples include\n            \"cpu\", \"cuda\", and \"auto\". Defaults to \"auto\".\n        load_in_8bit (`Optional[bool]`):\n            Optional boolean indicating whether or not to use eight-bit quantization\n            from bitsandbytes. When available, will typically decrease memory usage\n            and increase inference speed. Defaults to `False`.\n        load_in_4bit (`Optional[bool]`):\n            Optional boolean indicating whether or not to use four-bit quantization\n            from bitsandbytes. When available, will typically decrease memory usage\n            and increase inference speed. If you observe degraded performance, try\n            eight-bit quanitization instead. Defaults to `False`.\n        torch_dtype (`torch.dtype`):\n            The dtype to use for torch tensors. Defaults to `torch.float16`. You may\n            need to change this depending on your quantization choices.\n        use_flash_attn_2 (`Optional[bool]`):\n            Optional bool controlling whether or not to use Flash Attention 2. Defaults\n            to `False` in case you haven't installed flash attention. Substantially\n            speeds up inference. \n    \"\"\"\n    model_name : str\n    completions_key : Optional[str] = field(\n        default = \"completions_in\"\n    )\n    logprobs_out_key : Optional[str] = field (\n        default = \"probs_out\"\n    )\n    success_fn_key : Optional[str] = field(\n        default = \"success_fn\"\n    )\n    auto_load : Optional[bool] = field(\n        default = True\n    )\n    input_key : Optional[str] = field(\n        default = \"in\"\n    )\n    device : Optional[str] = field(\n        default = \"auto\"\n    )\n    load_in_8bit : Optional[bool] = field(\n        default = False\n    )\n    load_in_4bit : Optional[bool] = field(\n        default = False\n    )\n    torch_dtype : Optional[torch.dtype] = field(\n        default = torch.float16\n    )\n    use_flash_attn_2 : Optional[bool] = field(\n        default = False\n    )\n</code></pre>"},{"location":"api/conditions/completion_condition/#dendron.conditions.completion_condition.CompletionCondition","title":"<code>dendron.conditions.completion_condition.CompletionCondition</code>","text":"<p>             Bases: <code>ConditionNode</code></p> <p>A completion condition node uses a causal language model to evaluate the relative likelihood of several different completions of a prompt, returning <code>SUCCESS</code> or <code>FAILURE</code> using a user-provided function that selects a status based on the most likely completion.</p> <p>This node tends to run quickly and gives useful answers, but if you use this node you should be aware of the perils of \"surface form competition\", documented in the paper by Holtzman et al. (see  https://arxiv.org/abs/2104.08315).</p> <p>This node is based on the Hugging Face transformers library, and will download the model that you specify by name. This can take a long  time and/or use a lot of storage, depending on the model you name.</p> <p>There are enough configuration options for this type of node that the options have all been placed in a dataclass config object. See  the documentation for that object to learn about the many options available to you.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>cfg</code> <code>`CompletionConditionNodeConfig`</code> <p>The configuration object for this model.</p> required Source code in <code>src/dendron/conditions/completion_condition.py</code> <pre><code>class CompletionCondition(ConditionNode):\n    \"\"\"\n    A completion condition node uses a causal language model to evaluate\n    the relative likelihood of several different completions of a prompt,\n    returning `SUCCESS` or `FAILURE` using a user-provided function that\n    selects a status based on the most likely completion.\n\n    This node tends to run quickly and gives useful answers, but if you\n    use this node you should be aware of the perils of \"surface form\n    competition\", documented in the paper by Holtzman et al. (see \n    https://arxiv.org/abs/2104.08315).\n\n    This node is based on the Hugging Face transformers library, and will\n    download the model that you specify by name. This can take a long \n    time and/or use a lot of storage, depending on the model you name.\n\n    There are enough configuration options for this type of node that\n    the options have all been placed in a dataclass config object. See \n    the documentation for that object to learn about the many options\n    available to you.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        cfg (`CompletionConditionNodeConfig`):\n            The configuration object for this model.\n    \"\"\"\n    def __init__(self, name : str, cfg : CompletionConditionConfig) -&gt; None:\n        super().__init__(name)\n        self.input_key = cfg.input_key\n        self.device = cfg.device\n\n        self.torch_dtype = cfg.torch_dtype\n        self.completions_key = cfg.completions_key\n        self.success_fn_key = cfg.success_fn_key\n\n        self.logprobs_out_key = cfg.logprobs_out_key\n\n        self.bnb_cfg = BitsAndBytesConfig()\n\n        match cfg.load_in_4bit, cfg.load_in_8bit:\n            case True, True:\n                self.bnb_cfg.load_in_4bit = True\n                self.bnb_cfg.bnb_4bit_compute_dtype = cfg.torch_dtype\n            case True, False:\n                self.bnb_cfg.load_in_4bit = True\n                self.bnb_cfg.bnb_4bit_compute_dtype = cfg.torch_dtype\n            case False, True:\n                self.bnb_cfg.load_in_8bit = True\n            case False, False:\n                pass\n\n        if cfg.use_flash_attn_2:\n            self.attn_implementation = \"flash_attention_2\"\n        else:\n            self.attn_implementation = \"sdpa\"\n\n        if cfg.auto_load:\n            self.model = AutoModelForCausalLM.from_pretrained(\n                cfg.model_name,\n                low_cpu_mem_usage=True,\n                attn_implementation=self.attn_implementation,\n                quantization_config=self.bnb_cfg\n            )\n\n            self.model.eval()\n            self.tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n\n            if self.tokenizer.pad_token is None:\n                self.tokenizer.pad_token = self.tokenizer.eos_token\n        else:\n            self.model = None\n            self.tokenizer = None\n            self.completions = []\n\n    def set_model(self, new_model) -&gt; None:\n        \"\"\"\n        Set a new model to use for generating text.\n        \"\"\"\n        self.model = new_model\n        self.model.eval()\n        self.tokenizer = AutoTokenizer.from_pretrained(new_model.name_or_path)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Execute a tick, consisting of the following steps:\n\n        - Retrieve the input prefix from the blackboard.\n        - Retrieve the list of completion options from the blackboard.\n        - Retrieve the success predicate from the blackboard.\n        - Tokenize all of the possible completions, padding as needed.\n        - Evaluate the model on the tokenized batch of completions.\n        - Compute the \"log probabilities\" of each completion.\n        - Apply the success predicate to the completion with the highest\n          log probability.\n        - Return the status computed by the success predicate.\n\n        If any of the above fail, the exception text is printed and the node\n        returns a status of `FAILURE`. Otherwise the node returns `SUCCESS`.\n        \"\"\"\n        try:\n            input_prefix = self.blackboard[self.input_key]\n            completions = self.blackboard[self.completions_key]\n            success_fn = self.blackboard[self.success_fn_key]\n\n            log_probs = np.zeros(len(completions))\n            texts = [input_prefix + s for s in completions]\n\n            # Based on discussion/code at: https://discuss.huggingface.co/t/announcement-generation-get-probabilities-for-generated-output/30075/17\n            input_ids = self.tokenizer(texts, padding=True, return_tensors=\"pt\").input_ids\n            outputs = self.model(input_ids)\n            probs = torch.log_softmax(outputs.logits, dim=-1).detach()\n\n            probs = probs[:, :-1, :]\n            input_ids = input_ids[:, 1:]\n            gen_probs = torch.gather(probs, 2, input_ids[:, :, None]).squeeze(-1)\n\n            for i, (input_sentence, input_probs) in enumerate(zip(input_ids, gen_probs)):\n                for token, p in zip(input_sentence, input_probs):\n                    if token not in self.tokenizer.all_special_ids:\n                        log_probs[i] += p.item()\n\n            self.blackboard[self.logprobs_out_key] = {completions[i] : log_probs[i] for i in range(len(log_probs))}\n\n            best_completion = completions[log_probs.argmax()]\n\n            return success_fn(best_completion)\n\n        except Exception as ex:\n            print(f\"Exception in node {self.name}:\")\n            print(traceback.format_exc())\n            return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/conditions/completion_condition/#dendron.conditions.completion_condition.CompletionCondition.set_model","title":"<code>set_model(new_model)</code>","text":"<p>Set a new model to use for generating text.</p> Source code in <code>src/dendron/conditions/completion_condition.py</code> <pre><code>def set_model(self, new_model) -&gt; None:\n    \"\"\"\n    Set a new model to use for generating text.\n    \"\"\"\n    self.model = new_model\n    self.model.eval()\n    self.tokenizer = AutoTokenizer.from_pretrained(new_model.name_or_path)\n</code></pre>"},{"location":"api/conditions/completion_condition/#dendron.conditions.completion_condition.CompletionCondition.tick","title":"<code>tick()</code>","text":"<p>Execute a tick, consisting of the following steps:</p> <ul> <li>Retrieve the input prefix from the blackboard.</li> <li>Retrieve the list of completion options from the blackboard.</li> <li>Retrieve the success predicate from the blackboard.</li> <li>Tokenize all of the possible completions, padding as needed.</li> <li>Evaluate the model on the tokenized batch of completions.</li> <li>Compute the \"log probabilities\" of each completion.</li> <li>Apply the success predicate to the completion with the highest   log probability.</li> <li>Return the status computed by the success predicate.</li> </ul> <p>If any of the above fail, the exception text is printed and the node returns a status of <code>FAILURE</code>. Otherwise the node returns <code>SUCCESS</code>.</p> Source code in <code>src/dendron/conditions/completion_condition.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Execute a tick, consisting of the following steps:\n\n    - Retrieve the input prefix from the blackboard.\n    - Retrieve the list of completion options from the blackboard.\n    - Retrieve the success predicate from the blackboard.\n    - Tokenize all of the possible completions, padding as needed.\n    - Evaluate the model on the tokenized batch of completions.\n    - Compute the \"log probabilities\" of each completion.\n    - Apply the success predicate to the completion with the highest\n      log probability.\n    - Return the status computed by the success predicate.\n\n    If any of the above fail, the exception text is printed and the node\n    returns a status of `FAILURE`. Otherwise the node returns `SUCCESS`.\n    \"\"\"\n    try:\n        input_prefix = self.blackboard[self.input_key]\n        completions = self.blackboard[self.completions_key]\n        success_fn = self.blackboard[self.success_fn_key]\n\n        log_probs = np.zeros(len(completions))\n        texts = [input_prefix + s for s in completions]\n\n        # Based on discussion/code at: https://discuss.huggingface.co/t/announcement-generation-get-probabilities-for-generated-output/30075/17\n        input_ids = self.tokenizer(texts, padding=True, return_tensors=\"pt\").input_ids\n        outputs = self.model(input_ids)\n        probs = torch.log_softmax(outputs.logits, dim=-1).detach()\n\n        probs = probs[:, :-1, :]\n        input_ids = input_ids[:, 1:]\n        gen_probs = torch.gather(probs, 2, input_ids[:, :, None]).squeeze(-1)\n\n        for i, (input_sentence, input_probs) in enumerate(zip(input_ids, gen_probs)):\n            for token, p in zip(input_sentence, input_probs):\n                if token not in self.tokenizer.all_special_ids:\n                    log_probs[i] += p.item()\n\n        self.blackboard[self.logprobs_out_key] = {completions[i] : log_probs[i] for i in range(len(log_probs))}\n\n        best_completion = completions[log_probs.argmax()]\n\n        return success_fn(best_completion)\n\n    except Exception as ex:\n        print(f\"Exception in node {self.name}:\")\n        print(traceback.format_exc())\n        return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/conditions/simple_condition/","title":"SimpleCondition","text":""},{"location":"api/conditions/simple_condition/#dendron.conditions.simple_condition.SimpleCondition","title":"<code>dendron.conditions.simple_condition.SimpleCondition</code>","text":"<p>             Bases: <code>ConditionNode</code></p> <p>A simple condition node is initialized with a callback that is called every time this node <code>tick()</code>s. The callback should be a function that returns a <code>NodeStatus</code>. Additionally, as a  condition node the callback should never return a status of  <code>RUNNING</code>. It is up to the caller to ensure that this invariant holds.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>callback</code> <code>`Callable`</code> <p>The callback to be executed upon every <code>tick()</code>.</p> required Source code in <code>src/dendron/conditions/simple_condition.py</code> <pre><code>class SimpleCondition(ConditionNode):\n    \"\"\"\n    A simple condition node is initialized with a callback that is\n    called every time this node `tick()`s. The callback should be\n    a function that returns a `NodeStatus`. Additionally, as a \n    condition node the callback should never return a status of \n    `RUNNING`. It is up to the caller to ensure that this invariant\n    holds.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        callback (`Callable`):\n            The callback to be executed upon every `tick()`.\n    \"\"\"\n    def __init__(self, name : str, callback : Callable) -&gt; None:\n        super().__init__(name)\n        self.callback = callback\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Call the callback function and return its status as the \n        node status.\n        \"\"\"\n        return self.callback()\n</code></pre>"},{"location":"api/conditions/simple_condition/#dendron.conditions.simple_condition.SimpleCondition.tick","title":"<code>tick()</code>","text":"<p>Call the callback function and return its status as the  node status.</p> Source code in <code>src/dendron/conditions/simple_condition.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Call the callback function and return its status as the \n    node status.\n    \"\"\"\n    return self.callback()\n</code></pre>"},{"location":"api/controls/fallback/","title":"Fallback","text":""},{"location":"api/controls/fallback/#dendron.controls.fallback.Fallback","title":"<code>dendron.controls.fallback.Fallback</code>","text":"<p>             Bases: <code>ControlNode</code></p> <p>A Fallback node is a control node that ticks its children in  sequence, until a child returns <code>SUCCESS</code>, at which point it returns success. If all children return <code>FAILURE</code>, then the Fallback node returns <code>FAILURE</code>. The intuition is that the Fallback node is trying different options until it finds one that works.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>children</code> <code>`List[TreeNode]`</code> <p>A list of <code>TreeNode</code>s to initialize the children of this node. Will be ticked in the order they are given.</p> <code>[]</code> Source code in <code>src/dendron/controls/fallback.py</code> <pre><code>class Fallback(ControlNode):\n    \"\"\"\n    A Fallback node is a control node that ticks its children in \n    sequence, until a child returns `SUCCESS`, at which point it\n    returns success. If all children return `FAILURE`, then the\n    Fallback node returns `FAILURE`. The intuition is that the\n    Fallback node is trying different options until it finds one\n    that works.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        children (`List[TreeNode]`):\n            A list of `TreeNode`s to initialize the children of this\n            node. Will be ticked in the order they are given.            \n    \"\"\"\n\n    def __init__(self, name, children : List[TreeNode] = []) -&gt; None:\n        super().__init__(name, children)\n\n        self.current_child_idx = 0\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Set the current child index to 0 and instruct all children\n        to reset.\n        \"\"\"\n        self.current_child_idx = 0\n        for child in self.children:\n            child.reset()\n\n    def halt_node(self) -&gt; None:\n        \"\"\"\n        Set the current child index to 0 and instruct all children\n        to halt via the parent class `halt()`.\n        \"\"\"\n        self.current_child_idx = 0\n        ControlNode.halt(self)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Successively `tick()` each child node until one returns a\n        status of `SUCCESS`. If all children fail, return `FAILURE`.\n\n        Returns:\n            `NodeStatus`: `SUCCESS` if at least one child succeeds,\n            `FAILURE` otherwise. May return `RUNNING` or `SKIPPED`\n            depending on children's behavior.\n        \"\"\"\n        n_children = self.children_count()\n        self.set_status(NodeStatus.RUNNING)\n\n        while(self.current_child_idx &lt; n_children):\n            current_child = self.children[self.current_child_idx]\n\n            child_status = current_child.execute_tick()\n\n            match child_status:\n                case NodeStatus.RUNNING:\n                    return NodeStatus.RUNNING\n                case NodeStatus.FAILURE:\n                    self.current_child_idx += 1\n                case NodeStatus.SUCCESS:\n                    self.reset()\n                    self.current_child_idx = 0\n                    return child_status\n                case NodeStatus.SKIPPED:\n                    self.current_child_idx += 1\n                case NodeStatus.IDLE:\n                    raise RuntimeError(\"Child can't return IDLE\")\n\n        if self.current_child_idx == n_children:\n            self.reset()\n\n        return NodeStatus.FAILURE\n\n    def pretty_repr(self, depth = 0) -&gt; str:\n        \"\"\"\n        Return a string representation of this node at the given depth.\n\n        Args:\n            depth (`int`):\n                The depth of this node in a surrounding tree.\n\n        Returns:\n            `str`: The indented string representation.\n        \"\"\"\n        tabs = '\\t'*depth\n        repr = f\"{tabs}Fallback {self.name}\"\n        for child in self.children:\n            child_repr = child.pretty_repr(depth+1)\n            repr += f\"\\n{child_repr}\"\n        repr += \"\\n\"\n        return repr\n</code></pre>"},{"location":"api/controls/fallback/#dendron.controls.fallback.Fallback.halt_node","title":"<code>halt_node()</code>","text":"<p>Set the current child index to 0 and instruct all children to halt via the parent class <code>halt()</code>.</p> Source code in <code>src/dendron/controls/fallback.py</code> <pre><code>def halt_node(self) -&gt; None:\n    \"\"\"\n    Set the current child index to 0 and instruct all children\n    to halt via the parent class `halt()`.\n    \"\"\"\n    self.current_child_idx = 0\n    ControlNode.halt(self)\n</code></pre>"},{"location":"api/controls/fallback/#dendron.controls.fallback.Fallback.pretty_repr","title":"<code>pretty_repr(depth=0)</code>","text":"<p>Return a string representation of this node at the given depth.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>`int`</code> <p>The depth of this node in a surrounding tree.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p><code>str</code>: The indented string representation.</p> Source code in <code>src/dendron/controls/fallback.py</code> <pre><code>def pretty_repr(self, depth = 0) -&gt; str:\n    \"\"\"\n    Return a string representation of this node at the given depth.\n\n    Args:\n        depth (`int`):\n            The depth of this node in a surrounding tree.\n\n    Returns:\n        `str`: The indented string representation.\n    \"\"\"\n    tabs = '\\t'*depth\n    repr = f\"{tabs}Fallback {self.name}\"\n    for child in self.children:\n        child_repr = child.pretty_repr(depth+1)\n        repr += f\"\\n{child_repr}\"\n    repr += \"\\n\"\n    return repr\n</code></pre>"},{"location":"api/controls/fallback/#dendron.controls.fallback.Fallback.reset","title":"<code>reset()</code>","text":"<p>Set the current child index to 0 and instruct all children to reset.</p> Source code in <code>src/dendron/controls/fallback.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Set the current child index to 0 and instruct all children\n    to reset.\n    \"\"\"\n    self.current_child_idx = 0\n    for child in self.children:\n        child.reset()\n</code></pre>"},{"location":"api/controls/fallback/#dendron.controls.fallback.Fallback.tick","title":"<code>tick()</code>","text":"<p>Successively <code>tick()</code> each child node until one returns a status of <code>SUCCESS</code>. If all children fail, return <code>FAILURE</code>.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>NodeStatus</code>: <code>SUCCESS</code> if at least one child succeeds,</p> <code>NodeStatus</code> <p><code>FAILURE</code> otherwise. May return <code>RUNNING</code> or <code>SKIPPED</code></p> <code>NodeStatus</code> <p>depending on children's behavior.</p> Source code in <code>src/dendron/controls/fallback.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Successively `tick()` each child node until one returns a\n    status of `SUCCESS`. If all children fail, return `FAILURE`.\n\n    Returns:\n        `NodeStatus`: `SUCCESS` if at least one child succeeds,\n        `FAILURE` otherwise. May return `RUNNING` or `SKIPPED`\n        depending on children's behavior.\n    \"\"\"\n    n_children = self.children_count()\n    self.set_status(NodeStatus.RUNNING)\n\n    while(self.current_child_idx &lt; n_children):\n        current_child = self.children[self.current_child_idx]\n\n        child_status = current_child.execute_tick()\n\n        match child_status:\n            case NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n            case NodeStatus.FAILURE:\n                self.current_child_idx += 1\n            case NodeStatus.SUCCESS:\n                self.reset()\n                self.current_child_idx = 0\n                return child_status\n            case NodeStatus.SKIPPED:\n                self.current_child_idx += 1\n            case NodeStatus.IDLE:\n                raise RuntimeError(\"Child can't return IDLE\")\n\n    if self.current_child_idx == n_children:\n        self.reset()\n\n    return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/controls/sequence/","title":"Sequence","text":""},{"location":"api/controls/sequence/#dendron.controls.sequence.Sequence","title":"<code>dendron.controls.sequence.Sequence</code>","text":"<p>             Bases: <code>ControlNode</code></p> <p>A Sequence node is a control node that ticks its children in sequence, until a child returns <code>FAILURE</code>, at which point it returns <code>FAILURE</code>. If all children succeed, then the Sequence node returns <code>SUCCESS</code>. </p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>children</code> <code>`List[TreeNode]`</code> <p>A list of <code>TreeNode</code>s to initialize the children of this node. Will be ticked in the order they are given.</p> <code>[]</code> Source code in <code>src/dendron/controls/sequence.py</code> <pre><code>class Sequence(ControlNode):\n    \"\"\"\n    A Sequence node is a control node that ticks its children in\n    sequence, until a child returns `FAILURE`, at which point it\n    returns `FAILURE`. If all children succeed, then the Sequence\n    node returns `SUCCESS`. \n\n    Args:\n        name (`str`):\n            The given name of this node.\n        children (`List[TreeNode]`):\n            A list of `TreeNode`s to initialize the children of this\n            node. Will be ticked in the order they are given.\n    \"\"\"\n\n    def __init__(self, name, children : List[TreeNode] = []) -&gt; None:\n        super().__init__(name, children)\n\n        self.current_child_idx = 0\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Set the current child index to 0 and instruct all children\n        to reset.\n        \"\"\"\n        self.current_child_idx = 0\n        for child in self.children:\n            child.reset()\n\n    def halt_node(self) -&gt; None:\n        \"\"\"\n        Set the current child index to 0 and instruct all children\n        to halt via the parent class `halt()`.\n        \"\"\"\n        self.current_child_idx = 0\n        ControlNode.halt(self)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Successively `tick()` each child node until one returns a \n        status of `FAILURE`. If all children succeed, return \n        `SUCCESS`.\n\n        Returns:\n            `NodeStatus`: `FAILURE` if at least one child fails,\n            `SUCCESS` otherwise. May return `RUNNING` or `SKIPPED`\n            depending on children's behavior.\n        \"\"\"\n        n_children = self.children_count()\n        self.set_status(NodeStatus.RUNNING)\n\n        while(self.current_child_idx &lt; n_children):\n            current_child = self.children[self.current_child_idx]\n\n            child_status = current_child.execute_tick()\n\n            match child_status:\n                case NodeStatus.RUNNING:\n                    return NodeStatus.RUNNING\n                case NodeStatus.FAILURE:\n                    self.reset()\n                    self.current_child_idx = 0\n                    return child_status\n                case NodeStatus.SUCCESS:\n                    self.current_child_idx += 1\n                case NodeStatus.SKIPPED:\n                    self.current_child_idx += 1\n                case NodeStatus.IDLE:\n                    raise RuntimeError(\"Child can't return IDLE\")\n\n        if self.current_child_idx == n_children:\n            self.reset()\n\n        return NodeStatus.SUCCESS\n\n    def pretty_repr(self, depth = 0) -&gt; str:\n        \"\"\"\n        Return a string representation of this node at the given depth.\n\n        Args:\n            depth (`int`):\n                The depth of this node in a surrounding tree.\n\n        Returns:\n            `str`: The indented string representation.\n        \"\"\"\n        tabs = '\\t'*depth\n        repr = f\"{tabs}Sequence {self.name}\"\n        for child in self.children:\n            child_repr = child.pretty_repr(depth+1)\n            repr += f\"\\n{child_repr}\"\n        repr += \"\\n\"\n        return repr\n</code></pre>"},{"location":"api/controls/sequence/#dendron.controls.sequence.Sequence.halt_node","title":"<code>halt_node()</code>","text":"<p>Set the current child index to 0 and instruct all children to halt via the parent class <code>halt()</code>.</p> Source code in <code>src/dendron/controls/sequence.py</code> <pre><code>def halt_node(self) -&gt; None:\n    \"\"\"\n    Set the current child index to 0 and instruct all children\n    to halt via the parent class `halt()`.\n    \"\"\"\n    self.current_child_idx = 0\n    ControlNode.halt(self)\n</code></pre>"},{"location":"api/controls/sequence/#dendron.controls.sequence.Sequence.reset","title":"<code>reset()</code>","text":"<p>Set the current child index to 0 and instruct all children to reset.</p> Source code in <code>src/dendron/controls/sequence.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Set the current child index to 0 and instruct all children\n    to reset.\n    \"\"\"\n    self.current_child_idx = 0\n    for child in self.children:\n        child.reset()\n</code></pre>"},{"location":"api/controls/sequence/#dendron.controls.sequence.Sequence.tick","title":"<code>tick()</code>","text":"<p>Successively <code>tick()</code> each child node until one returns a  status of <code>FAILURE</code>. If all children succeed, return  <code>SUCCESS</code>.</p> <p>Returns:</p> Type Description <code>NodeStatus</code> <p><code>NodeStatus</code>: <code>FAILURE</code> if at least one child fails,</p> <code>NodeStatus</code> <p><code>SUCCESS</code> otherwise. May return <code>RUNNING</code> or <code>SKIPPED</code></p> <code>NodeStatus</code> <p>depending on children's behavior.</p> Source code in <code>src/dendron/controls/sequence.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Successively `tick()` each child node until one returns a \n    status of `FAILURE`. If all children succeed, return \n    `SUCCESS`.\n\n    Returns:\n        `NodeStatus`: `FAILURE` if at least one child fails,\n        `SUCCESS` otherwise. May return `RUNNING` or `SKIPPED`\n        depending on children's behavior.\n    \"\"\"\n    n_children = self.children_count()\n    self.set_status(NodeStatus.RUNNING)\n\n    while(self.current_child_idx &lt; n_children):\n        current_child = self.children[self.current_child_idx]\n\n        child_status = current_child.execute_tick()\n\n        match child_status:\n            case NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n            case NodeStatus.FAILURE:\n                self.reset()\n                self.current_child_idx = 0\n                return child_status\n            case NodeStatus.SUCCESS:\n                self.current_child_idx += 1\n            case NodeStatus.SKIPPED:\n                self.current_child_idx += 1\n            case NodeStatus.IDLE:\n                raise RuntimeError(\"Child can't return IDLE\")\n\n    if self.current_child_idx == n_children:\n        self.reset()\n\n    return NodeStatus.SUCCESS\n</code></pre>"},{"location":"api/decorators/blackboard_history/","title":"BlackboardHistory","text":""},{"location":"api/decorators/blackboard_history/#dendron.decorators.blackboard_history.BlackboardHistory","title":"<code>dendron.decorators.blackboard_history.BlackboardHistory</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>The Blackboard history node keeps track of a blackboard entry  related to a child node. Every time this node is ticked, it  examines the blackboard and records the value stored at the <code>child_key</code> before <code>tick()</code>ing the child.</p> <p>The history is itself stored in the blackboard, by default at the key \"{child_node.name}/{child_key}/history\".</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>The child node whose blackboard history we want to track.</p> required <code>child_key</code> <code>`str`</code> <p>The blackboard key we want to record values for.</p> <code>'in'</code> Source code in <code>src/dendron/decorators/blackboard_history.py</code> <pre><code>class BlackboardHistory(DecoratorNode):\n    \"\"\"\n    The Blackboard history node keeps track of a blackboard entry \n    related to a child node. Every time this node is ticked, it \n    examines the blackboard and records the value stored at the\n    `child_key` before `tick()`ing the child.\n\n    The history is itself stored in the blackboard, by default at\n    the key \"{child_node.name}/{child_key}/history\".\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            The child node whose blackboard history we want to track.\n        child_key (`str`):\n            The blackboard key we want to record values for.\n    \"\"\"\n    def __init__(self, name, child: TreeNode, child_key : str = \"in\") -&gt; None:\n        super().__init__(name, child)\n\n        self.child_key = self.child_node.input_key\n        self.history_key = f\"{self.child_node.name}/{child_key}/history\"\n        if self.blackboard is not None:\n            self.blackboard[self.history_key] = []\n\n    def set_blackboard(self, bb : Blackboard) -&gt; None:\n        \"\"\"\n        Assign a new blackboard for history tracking.\n\n        Args:\n            bb (`dendron.blackboard.Blackboard`):\n                The new blackboard to track.\n        \"\"\"\n        self.blackboard = bb\n        self.blackboard[self.history_key] = []\n\n        self.child_node.set_blackboard(bb)\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Clear the history and instruct the child to reset.\n        \"\"\"\n        self.blackboard[self.history_key] = []\n        self.child_node.reset()\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Record the value stored in the blackboard at `child_key` and\n        then instruct the child node to execute its `tick()` function.\n        \"\"\"\n        latest = self.blackboard[self.child_key]\n        self.blackboard[self.history_key].append(latest)\n\n        status = self.child_node.execute_tick()\n\n        return status\n</code></pre>"},{"location":"api/decorators/blackboard_history/#dendron.decorators.blackboard_history.BlackboardHistory.reset","title":"<code>reset()</code>","text":"<p>Clear the history and instruct the child to reset.</p> Source code in <code>src/dendron/decorators/blackboard_history.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Clear the history and instruct the child to reset.\n    \"\"\"\n    self.blackboard[self.history_key] = []\n    self.child_node.reset()\n</code></pre>"},{"location":"api/decorators/blackboard_history/#dendron.decorators.blackboard_history.BlackboardHistory.set_blackboard","title":"<code>set_blackboard(bb)</code>","text":"<p>Assign a new blackboard for history tracking.</p> <p>Parameters:</p> Name Type Description Default <code>bb</code> <code>`dendron.blackboard.Blackboard`</code> <p>The new blackboard to track.</p> required Source code in <code>src/dendron/decorators/blackboard_history.py</code> <pre><code>def set_blackboard(self, bb : Blackboard) -&gt; None:\n    \"\"\"\n    Assign a new blackboard for history tracking.\n\n    Args:\n        bb (`dendron.blackboard.Blackboard`):\n            The new blackboard to track.\n    \"\"\"\n    self.blackboard = bb\n    self.blackboard[self.history_key] = []\n\n    self.child_node.set_blackboard(bb)\n</code></pre>"},{"location":"api/decorators/blackboard_history/#dendron.decorators.blackboard_history.BlackboardHistory.tick","title":"<code>tick()</code>","text":"<p>Record the value stored in the blackboard at <code>child_key</code> and then instruct the child node to execute its <code>tick()</code> function.</p> Source code in <code>src/dendron/decorators/blackboard_history.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Record the value stored in the blackboard at `child_key` and\n    then instruct the child node to execute its `tick()` function.\n    \"\"\"\n    latest = self.blackboard[self.child_key]\n    self.blackboard[self.history_key].append(latest)\n\n    status = self.child_node.execute_tick()\n\n    return status\n</code></pre>"},{"location":"api/decorators/force_failure/","title":"ForceFailure","text":""},{"location":"api/decorators/force_failure/#dendron.decorators.force_failure.ForceFailure","title":"<code>dendron.decorators.force_failure.ForceFailure</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>A Force Failure decorator will tick its child, and regardless of the result will return failure.</p> <p>May be useful for debugging.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>An optional child node. If <code>None</code>, the caller is responsible for setting the <code>child_node</code> member variable before <code>tick()</code> is called.</p> <code>None</code> Source code in <code>src/dendron/decorators/force_failure.py</code> <pre><code>class ForceFailure(DecoratorNode):\n    \"\"\"\n    A Force Failure decorator will tick its child, and regardless of the\n    result will return failure.\n\n    May be useful for debugging.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            An optional child node. If `None`, the caller is responsible for\n            setting the `child_node` member variable before `tick()` is\n            called.\n    \"\"\"\n    def __init__(self, name: str, child: TreeNode = None) -&gt; None:\n        super().__init__(name)\n        self.name = name\n        self.child_node = child\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Call the `tick()` method of the child and then return a status of\n        `FAILURE`.\n        \"\"\"\n        self.child_node.execute_tick()\n        return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/decorators/force_failure/#dendron.decorators.force_failure.ForceFailure.tick","title":"<code>tick()</code>","text":"<p>Call the <code>tick()</code> method of the child and then return a status of <code>FAILURE</code>.</p> Source code in <code>src/dendron/decorators/force_failure.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Call the `tick()` method of the child and then return a status of\n    `FAILURE`.\n    \"\"\"\n    self.child_node.execute_tick()\n    return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/decorators/force_success/","title":"ForceSuccess","text":""},{"location":"api/decorators/force_success/#dendron.decorators.force_success.ForceSuccess","title":"<code>dendron.decorators.force_success.ForceSuccess</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>A Force Success node calls the <code>tick()</code> method of its child, ignores the result, and always returns a status of <code>SUCCESS</code>.</p> <p>May be useful for debugging.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>An optional child node. If <code>None</code>, it is the responsibility of the caller to ensure that the <code>child_node</code> member  variable is set prior to the first <code>tick()</code> call.</p> <code>None</code> Source code in <code>src/dendron/decorators/force_success.py</code> <pre><code>class ForceSuccess(DecoratorNode):\n    \"\"\"\n    A Force Success node calls the `tick()` method of its child,\n    ignores the result, and always returns a status of `SUCCESS`.\n\n    May be useful for debugging.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            An optional child node. If `None`, it is the responsibility\n            of the caller to ensure that the `child_node` member \n            variable is set prior to the first `tick()` call.\n    \"\"\"\n    def __init__(self, name: str, child: TreeNode = None) -&gt; None:\n        super().__init__(name, child)\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Instruct the child node to execute its `tick()` method, ignore\n        the result, and return `SUCCESS`.\n        \"\"\"\n        self.child_node.execute_tick()\n        return NodeStatus.SUCCESS\n</code></pre>"},{"location":"api/decorators/force_success/#dendron.decorators.force_success.ForceSuccess.tick","title":"<code>tick()</code>","text":"<p>Instruct the child node to execute its <code>tick()</code> method, ignore the result, and return <code>SUCCESS</code>.</p> Source code in <code>src/dendron/decorators/force_success.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Instruct the child node to execute its `tick()` method, ignore\n    the result, and return `SUCCESS`.\n    \"\"\"\n    self.child_node.execute_tick()\n    return NodeStatus.SUCCESS\n</code></pre>"},{"location":"api/decorators/inverter/","title":"Inverter","text":""},{"location":"api/decorators/inverter/#dendron.decorators.inverter.Inverter","title":"<code>dendron.decorators.inverter.Inverter</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>An Inverter decorator instructs its child node to <code>tick()</code> and then returns the negation of the child's status as its own.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>Optional child node. If <code>None</code>, it is the responsibility of the caller to ensure that the <code>child_node</code> member variable is set before the first <code>tick()</code> call.</p> <code>None</code> Source code in <code>src/dendron/decorators/inverter.py</code> <pre><code>class Inverter(DecoratorNode):\n    \"\"\"\n    An Inverter decorator instructs its child node to `tick()` and\n    then returns the negation of the child's status as its own.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            Optional child node. If `None`, it is the responsibility of\n            the caller to ensure that the `child_node` member variable\n            is set before the first `tick()` call.\n    \"\"\"\n    def __init__(self, name, child : TreeNode = None) -&gt; None:\n        super().__init__(name)\n        self.name = name\n        self.child_node = child \n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Instruct the child node to execute its `tick()` function, and then \n        return `SUCCESS` if the child fails, and `FAILURE` if the child \n        succeeds. Returns `RUNNING` if the child returns `RUNNING`.\n        \"\"\"\n        self.set_status(NodeStatus.RUNNING)\n\n        child_status = self.child_node.execute_tick()\n\n        match child_status:\n            case NodeStatus.SUCCESS:\n                self.reset()\n                return NodeStatus.FAILURE\n            case NodeStatus.FAILURE:\n                self.reset()\n                return NodeStatus.SUCCESS\n            case NodeStatus.IDLE:\n                raise RuntimeError(\"Child can't return IDLE\")\n            case _:\n                return child_status\n</code></pre>"},{"location":"api/decorators/inverter/#dendron.decorators.inverter.Inverter.tick","title":"<code>tick()</code>","text":"<p>Instruct the child node to execute its <code>tick()</code> function, and then  return <code>SUCCESS</code> if the child fails, and <code>FAILURE</code> if the child  succeeds. Returns <code>RUNNING</code> if the child returns <code>RUNNING</code>.</p> Source code in <code>src/dendron/decorators/inverter.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Instruct the child node to execute its `tick()` function, and then \n    return `SUCCESS` if the child fails, and `FAILURE` if the child \n    succeeds. Returns `RUNNING` if the child returns `RUNNING`.\n    \"\"\"\n    self.set_status(NodeStatus.RUNNING)\n\n    child_status = self.child_node.execute_tick()\n\n    match child_status:\n        case NodeStatus.SUCCESS:\n            self.reset()\n            return NodeStatus.FAILURE\n        case NodeStatus.FAILURE:\n            self.reset()\n            return NodeStatus.SUCCESS\n        case NodeStatus.IDLE:\n            raise RuntimeError(\"Child can't return IDLE\")\n        case _:\n            return child_status\n</code></pre>"},{"location":"api/decorators/repeat/","title":"Repeat","text":""},{"location":"api/decorators/repeat/#dendron.decorators.repeat.Repeat","title":"<code>dendron.decorators.repeat.Repeat</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>A Repeat node ticks its child node repeatedly as long as the child continues to return <code>SUCCESS</code>. </p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>Optional child node. If <code>None</code>, it is the responsibility of the caller to ensure that the <code>child_node</code> member variable is set before the first <code>tick()</code> call.</p> required <code>n_times</code> <code>`int`</code> <p>Number of times to <code>tick()</code> the child node if it continues to return <code>SUCCESS</code>.</p> required Source code in <code>src/dendron/decorators/repeat.py</code> <pre><code>class Repeat(DecoratorNode):\n    \"\"\"\n    A Repeat node ticks its child node repeatedly as long as the child\n    continues to return `SUCCESS`. \n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            Optional child node. If `None`, it is the responsibility of the\n            caller to ensure that the `child_node` member variable is set\n            before the first `tick()` call.\n        n_times (`int`):\n            Number of times to `tick()` the child node if it continues\n            to return `SUCCESS`.\n    \"\"\"\n    def __init__(self, name : str, child : TreeNode, n_times : int) -&gt; None:\n        super().__init__(name, child)\n        self.n_times = n_times\n        self.repeat_ct = 0\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Set the repeat counter to 0 and instruct the child node to reset.\n        \"\"\"\n        self.repeat_ct = 0\n        self.child_node.reset()\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Tick the child node until either it returns `FAILURE` or the child\n        is `tick()`ed `n_times`.\n        \"\"\"\n        should_repeat = True\n\n        while should_repeat:\n            child_status = self.child_node.execute_tick()\n            match child_status:\n                case NodeStatus.SUCCESS:\n                    self.repeat_ct += 1\n                    should_repeat = self.repeat_ct &lt; self.n_times\n                case NodeStatus.FAILURE:\n                    self.repeat_ct = 0\n                    self.reset_child()\n                    return NodeStatus.FAILURE\n                case NodeStatus.RUNNING:\n                    return NodeStatus.RUNNING\n\n        self.repeat_ct = 0\n        return NodeStatus.SUCCESS # TODO handle skips?\n</code></pre>"},{"location":"api/decorators/repeat/#dendron.decorators.repeat.Repeat.reset","title":"<code>reset()</code>","text":"<p>Set the repeat counter to 0 and instruct the child node to reset.</p> Source code in <code>src/dendron/decorators/repeat.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Set the repeat counter to 0 and instruct the child node to reset.\n    \"\"\"\n    self.repeat_ct = 0\n    self.child_node.reset()\n</code></pre>"},{"location":"api/decorators/repeat/#dendron.decorators.repeat.Repeat.tick","title":"<code>tick()</code>","text":"<p>Tick the child node until either it returns <code>FAILURE</code> or the child is <code>tick()</code>ed <code>n_times</code>.</p> Source code in <code>src/dendron/decorators/repeat.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Tick the child node until either it returns `FAILURE` or the child\n    is `tick()`ed `n_times`.\n    \"\"\"\n    should_repeat = True\n\n    while should_repeat:\n        child_status = self.child_node.execute_tick()\n        match child_status:\n            case NodeStatus.SUCCESS:\n                self.repeat_ct += 1\n                should_repeat = self.repeat_ct &lt; self.n_times\n            case NodeStatus.FAILURE:\n                self.repeat_ct = 0\n                self.reset_child()\n                return NodeStatus.FAILURE\n            case NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n\n    self.repeat_ct = 0\n    return NodeStatus.SUCCESS # TODO handle skips?\n</code></pre>"},{"location":"api/decorators/retry/","title":"Retry","text":""},{"location":"api/decorators/retry/#dendron.decorators.retry.Retry","title":"<code>dendron.decorators.retry.Retry</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>A Retry node ticks its child node repeatedly as long as the child continues to return <code>FAILURE</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>Optional child node. If <code>None</code>, it is the responsibility of the caller to ensure that the <code>child_node</code> member variable is set before the first <code>tick()</code> call.</p> required <code>n_times</code> <code>`int`</code> <p>Number of times to <code>tick()</code> the child node if it continues  to return <code>FAILURE</code>.</p> required Source code in <code>src/dendron/decorators/retry.py</code> <pre><code>class Retry(DecoratorNode):\n    \"\"\"\n    A Retry node ticks its child node repeatedly as long as the child\n    continues to return `FAILURE`.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            Optional child node. If `None`, it is the responsibility of the\n            caller to ensure that the `child_node` member variable is set\n            before the first `tick()` call.\n        n_times (`int`):\n            Number of times to `tick()` the child node if it continues \n            to return `FAILURE`.\n    \"\"\"\n    def __init__(self, name: str, child: TreeNode, n_times: int) -&gt; None:\n        super().__init__(self, child)\n        self.n_times = n_times\n        self.retry_ct = 0\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Set the retry counter to 0 and instruct the child node to reset.\n        \"\"\"\n        self.retry_ct = 0\n        self.child_node.reset()\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Tick the child node until either it returns `SUCCESS` or the child \n        is `tick()`ed `n_times`.\n        \"\"\"\n        should_retry = True\n\n        while should_retry:\n            child_status = self.child_node.execute_tick()\n            match child_status:\n                case NodeStatus.SUCCESS:\n                    self.retry_ct = 0\n                    self.reset_child()\n                    return NodeStatus.SUCCESS\n                case NodeStatus.FAILURE:\n                    self.retry_ct += 1\n                    should_retry = self.retry_ct &lt; self.n_times\n                case NodeStatus.RUNNING:\n                    return NodeStatus.RUNNING\n\n        self.retry_ct = 0\n        return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/decorators/retry/#dendron.decorators.retry.Retry.reset","title":"<code>reset()</code>","text":"<p>Set the retry counter to 0 and instruct the child node to reset.</p> Source code in <code>src/dendron/decorators/retry.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Set the retry counter to 0 and instruct the child node to reset.\n    \"\"\"\n    self.retry_ct = 0\n    self.child_node.reset()\n</code></pre>"},{"location":"api/decorators/retry/#dendron.decorators.retry.Retry.tick","title":"<code>tick()</code>","text":"<p>Tick the child node until either it returns <code>SUCCESS</code> or the child  is <code>tick()</code>ed <code>n_times</code>.</p> Source code in <code>src/dendron/decorators/retry.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Tick the child node until either it returns `SUCCESS` or the child \n    is `tick()`ed `n_times`.\n    \"\"\"\n    should_retry = True\n\n    while should_retry:\n        child_status = self.child_node.execute_tick()\n        match child_status:\n            case NodeStatus.SUCCESS:\n                self.retry_ct = 0\n                self.reset_child()\n                return NodeStatus.SUCCESS\n            case NodeStatus.FAILURE:\n                self.retry_ct += 1\n                should_retry = self.retry_ct &lt; self.n_times\n            case NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n\n    self.retry_ct = 0\n    return NodeStatus.FAILURE\n</code></pre>"},{"location":"api/decorators/run_once/","title":"RunOnce","text":""},{"location":"api/decorators/run_once/#dendron.decorators.run_once.RunOnce","title":"<code>dendron.decorators.run_once.RunOnce</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>The RunOnce decorator tracks whether or not its child has been ticked. If it has, the next time it is ticked the decorator will return a status of <code>SKIPPED</code>. It will continue to return that status until it is explicitly reset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>The child node.</p> required Source code in <code>src/dendron/decorators/run_once.py</code> <pre><code>class RunOnce(DecoratorNode):\n    \"\"\"\n    The RunOnce decorator tracks whether or not its child has been\n    ticked. If it has, the next time it is ticked the decorator will\n    return a status of `SKIPPED`. It will continue to return that\n    status until it is explicitly reset.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            The child node.\n    \"\"\"\n    def __init__(self, name: str, child: TreeNode) -&gt; None:\n        super().__init__(name, child)\n        self.has_run = False\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Reset the `has_run` tracker so that the child node can be\n        `tick()`ed again.\n        \"\"\"\n        self.has_run = False\n        self.status = NodeStatus.IDLE\n        self.child_node.reset_status()\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        If the child node has been `tick()`ed already, return a status\n        of `SKIPPED` without `tick()`ing the child again. Otherwise \n        `tick()` the child node and set `has_run` to `True` so that the\n        node will not be `tick()`ed again.\n        \"\"\"\n        self.set_status(NodeStatus.RUNNING)\n        if self.has_run:\n            return NodeStatus.SKIPPED\n\n        self.has_run = True\n        child_status = self.child_node.execute_tick()\n        return child_status\n</code></pre>"},{"location":"api/decorators/run_once/#dendron.decorators.run_once.RunOnce.reset","title":"<code>reset()</code>","text":"<p>Reset the <code>has_run</code> tracker so that the child node can be <code>tick()</code>ed again.</p> Source code in <code>src/dendron/decorators/run_once.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Reset the `has_run` tracker so that the child node can be\n    `tick()`ed again.\n    \"\"\"\n    self.has_run = False\n    self.status = NodeStatus.IDLE\n    self.child_node.reset_status()\n</code></pre>"},{"location":"api/decorators/run_once/#dendron.decorators.run_once.RunOnce.tick","title":"<code>tick()</code>","text":"<p>If the child node has been <code>tick()</code>ed already, return a status of <code>SKIPPED</code> without <code>tick()</code>ing the child again. Otherwise  <code>tick()</code> the child node and set <code>has_run</code> to <code>True</code> so that the node will not be <code>tick()</code>ed again.</p> Source code in <code>src/dendron/decorators/run_once.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    If the child node has been `tick()`ed already, return a status\n    of `SKIPPED` without `tick()`ing the child again. Otherwise \n    `tick()` the child node and set `has_run` to `True` so that the\n    node will not be `tick()`ed again.\n    \"\"\"\n    self.set_status(NodeStatus.RUNNING)\n    if self.has_run:\n        return NodeStatus.SKIPPED\n\n    self.has_run = True\n    child_status = self.child_node.execute_tick()\n    return child_status\n</code></pre>"},{"location":"api/decorators/timeout/","title":"Timeout","text":""},{"location":"api/decorators/timeout/#dendron.decorators.timeout.Timeout","title":"<code>dendron.decorators.timeout.Timeout</code>","text":"<p>             Bases: <code>DecoratorNode</code></p> <p>The timeout decorator ticks its child and starts a timer. The next time it receives a tick it will check its timer against the time limit. If  the elapsed time exceeds the limit, this node returns <code>FAILURE</code>.</p> <p>This is primarily useful for nodes that are executing asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>`str`</code> <p>The given name of this node.</p> required <code>child</code> <code>`dendron.tree_node.TreeNode`</code> <p>The child of this node.</p> required <code>timelimit</code> <code>`int`</code> <p>The integer number of milliseconds to wait before returning  failure.</p> required Source code in <code>src/dendron/decorators/timeout.py</code> <pre><code>class Timeout(DecoratorNode):\n    \"\"\"\n    The timeout decorator ticks its child and starts a timer. The next time\n    it receives a tick it will check its timer against the time limit. If \n    the elapsed time exceeds the limit, this node returns `FAILURE`.\n\n    This is primarily useful for nodes that are executing asynchronously.\n\n    Args:\n        name (`str`):\n            The given name of this node.\n        child (`dendron.tree_node.TreeNode`):\n            The child of this node.\n        timelimit (`int`):\n            The integer number of *milliseconds* to wait before returning \n            failure.\n    \"\"\"\n    def __init__(self, name: str, child: TreeNode, timelimit: int) -&gt; None:\n        super().__init__(name, child)\n        self.timelimit = timelimit\n        self.timer_started = False\n        self.start_time = 0 # this is an int in millis.\n\n    def reset(self) -&gt; None:\n        \"\"\"\n        Reset the timer and instruct the child node to reset.\n        \"\"\"\n        self.timer_started = False\n        self.start_time = 0\n        self.reset_child()\n\n    def tick(self) -&gt; NodeStatus:\n        \"\"\"\n        Tick the child node, but with a time limit. If the time limit\n        is exceeded, return `FAILURE`.\n        \"\"\"\n        if not self.timer_started:\n            self.timer_started = True\n            self.set_status(NodeStatus.RUNNING)\n            self.start_time = time.time_ns()\n\n        child_status = self.child_node.execute_tick()\n\n        elapsed_ms = (time.time_ns() - self.start_time)/1e6\n        if elapsed_ms &gt; self.timelimit:\n            return NodeStatus.FAILURE\n        else:\n            return child_status\n</code></pre>"},{"location":"api/decorators/timeout/#dendron.decorators.timeout.Timeout.reset","title":"<code>reset()</code>","text":"<p>Reset the timer and instruct the child node to reset.</p> Source code in <code>src/dendron/decorators/timeout.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    Reset the timer and instruct the child node to reset.\n    \"\"\"\n    self.timer_started = False\n    self.start_time = 0\n    self.reset_child()\n</code></pre>"},{"location":"api/decorators/timeout/#dendron.decorators.timeout.Timeout.tick","title":"<code>tick()</code>","text":"<p>Tick the child node, but with a time limit. If the time limit is exceeded, return <code>FAILURE</code>.</p> Source code in <code>src/dendron/decorators/timeout.py</code> <pre><code>def tick(self) -&gt; NodeStatus:\n    \"\"\"\n    Tick the child node, but with a time limit. If the time limit\n    is exceeded, return `FAILURE`.\n    \"\"\"\n    if not self.timer_started:\n        self.timer_started = True\n        self.set_status(NodeStatus.RUNNING)\n        self.start_time = time.time_ns()\n\n    child_status = self.child_node.execute_tick()\n\n    elapsed_ms = (time.time_ns() - self.start_time)/1e6\n    if elapsed_ms &gt; self.timelimit:\n        return NodeStatus.FAILURE\n    else:\n        return child_status\n</code></pre>"}]}